{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7cdc966-ba39-4d48-b3b6-c2d0644d8992",
   "metadata": {},
   "source": [
    "# <center>OpenAI在线大模型调用及微调方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827cca93-8005-44c6-9bc7-4d9d78184a13",
   "metadata": {},
   "source": [
    "## <center>Ch.3 基于思维链的进阶提示工程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78271d5b-4f78-4bfa-b381-150f5a427b24",
   "metadata": {},
   "source": [
    "- Completions模型的涌现能力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3195a6a-9562-4e03-8c10-daec3fd3db97",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在上一小节中，我们详细介绍了关于OpenAI Completions模型的调用方法。截至目前，gpt-3系列模型（如'text-davinci-003'模型）是目前为止最强大的Completions模型，同时也是第一批拥有“涌现能力”的大语言模型，即哪怕模型未经特定任务的训练，但在适当的提示下，仍然能够解决某些特定领域的问题。例如大语言模型可以解答数学问题、辅助进行编程、甚至是进行问答等，其实都属于模型的涌现能力。而为何类似数学能力是模型的“涌现能力”，其实原因也并不复杂——作为概率模型，大语言模型甚至不知道数字代表的真实含义，模型只是在学习了无数的语料之后，发现了一些数学结论之间的潜在概率关系，才最终涌现出了数学运算或者复杂推理的能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb12897-8d2d-4ab0-be73-f792417a1546",
   "metadata": {},
   "source": [
    "> 可能很难想象，能够进行问答，其实也是大语言的涌现能力。大语言模型的训练目标目标是生成或预测文本，而不是进行问答。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580c4429-8d78-493a-99c4-e62e0b443730",
   "metadata": {},
   "source": [
    "- 大模型应用的关键技术——提示工程（Prompt engineering）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44ffbbf-69e0-4b31-8231-7513f6a4b9fe",
   "metadata": {},
   "source": [
    "&emsp;&emsp;不过需要注意的是，大模型的这种“涌现能力”其实并不稳定，在不修改模型本身参数（微调）的情况下，模型涌现能力极度依赖对模型的提示过程，即对同样一个模型，不同的提示方法将获得质量完全不同的结果。而一个完整的用户和大语言模型的交互流程，也被称为大语言模型的提示工程（Prompt engineering），根据此前的描述我们不难理解，提示工程是激发模型涌现能力（激发模型潜力）的非常关键的技术。同时，由于我们对大语言模型“涌现能力”的应用要求是远远多于简单的使用大模型进行文本创建的（毕竟哪怕是对话任务都属于大模型涌现能力的范畴），因此提示工程这一专门用于激发大语言模型涌现能力的技术就变得尤其重要。这也是为何自GPT大模型爆火之后，提示工程便成了非常热门的科研方向，同时提示工程技术也成了大模型应用工程师必不可少的技能。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0bd5e4-7b20-4cef-a1a5-c6570b4bfecc",
   "metadata": {},
   "source": [
    "> 关于微调概念入门介绍，参考课程视频《Lesson 5-2 微调入门介绍》。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36c10c6-1107-4267-a084-d0e2850a05c0",
   "metadata": {},
   "source": [
    "- 提示工程与模型微调"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5fa87a-3ba7-43b7-b41b-5d4ca3f1cd9c",
   "metadata": {},
   "source": [
    "&emsp;&emsp;从技术角度来说，提示工程其实是一个易学习门槛很低、但同时技术难度上限又很高的技术。提示工程简单的应用的话，只需要添加一些提示词后缀、或者把问题描述的更加详细即可，而复杂的提示工程，则会涉及多段嵌套提示和极具创造力的围绕中间结果的问答设计等。很遗憾的是，由于大多数非专业人士对大语言模型“浅尝辄止”的使用状态，导致市面上充斥着快餐化的“提示词模板”以及对提示工程粗浅的理解，进而误导很多技术人员觉得提示工程并不重要，而一些看起来技术难度更大、更加高大上的“微调”方法貌似会比提示工程更有效。这其实是一种非常大的误解。微调和提示工程同属对模型涌现能力的引导和优化方法，但相比微调，提示工程成本更低、使用更加灵活，且对于提升模型在小语义空间内复杂语义理解效果更好。当然，在很多时候，我们甚至需要要先设计提示工程进行文本标注，再使用这些标注的文本进行模型微调。不难发现，提示工程技术的学习和掌握，对大模型工程师而言至关重要。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d820fbdc-2160-4aae-bd12-75bf3cc67a2f",
   "metadata": {},
   "source": [
    "> 从另一个角度来看，大语言模型的“涌现能力”其实才是引爆大模型技术革命的最核心因素——正式因为大模型拥有出人意料的涌现能力，才让更多的人对大模型的潜力抱有更多的期待，才会有更多的探索以及训练更大规模语言模型的尝试。而激发大语言模型的涌现能力，则非常像是一个“掘金”的过程，而提示工程（以及微调手段）则像是目前来看最有有效的掘金的方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c241a5-843d-4535-bbe9-f26756d1ac72",
   "metadata": {},
   "source": [
    "- 提示工程技术部分内容安排"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdeda62-d2ef-4cdf-a47f-64ae5e554719",
   "metadata": {},
   "source": [
    "&emsp;&emsp;因此，在接下来的两个小节将由浅及深的为大家介绍提示工程技术。本小节我们将介绍提示工程基础类方法、思维链提示方法和一种名为LtM的提示方法，而下一小节，则将重点介绍围绕LtM的嵌套提示流程设计，并最终借助这些提示工程技术，解决一项用于测试模型组合泛化能力的指令翻译任务，该任务也是目前深度学习最为前沿的技术问题，哪怕是理论上最合适解决这类问题的序列类深度学习模型（seq-to-seq）都无法精准预测，却能够被大语言模型+提示工程技术一举轻松攻克，准确率逼近100%！通过该案例的学习，在进一步提升大语言模型提示技巧的同时，深刻理解大语言模型对于部分传统深度学习领域的“降维打击”，切身体验大语言模型+提示工程的实战威力。    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123333fb-7057-4cac-9cb5-1f51380f99e3",
   "metadata": {},
   "source": [
    "&emsp;&emsp;此外，需要注意的是，本节涉及到的内容多为近两年LLM领域的科研成果，但结论多为英文语境下的解决方案，因此，课程不仅将会围绕这些高价值科研结果进行系统梳理，并且，会更多的结合中文语境的实际情况提出中文内容逻辑推断的解决方案，本节内容所涉及到的4篇论文已随课程课件一同发放，同时在本节的末尾也整理了全部论文的链接，供大家参考。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab06744-0ed1-4870-b03e-02d69938240a",
   "metadata": {},
   "source": [
    "> 目前来看，大语言模型提示工程（微调技术也类似）最前沿的技术探索成果均集中在近1-2年的论文中，甚至下一小节介绍的LtM提示技术于2023年4月刚刚发表，因此在实际大模型技术学习过程中，紧跟前沿论文的学习将会变得非常重要。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1985134f-d41a-4a57-8726-939ee3483e8d",
   "metadata": {},
   "source": [
    "- 提示工程内容侧重点：解决复杂语义理解问题"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a814e149-8bc8-4d78-a10f-1729630c1954",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在正式介绍提示工程方法之前需要说明的是，围绕不同类型的问题，其实是有不同种类的提示工程方法的，例如创造AIGC内容的提示策略（例如批量写稿）和提升模型复杂语义能力的提示策略（例如进行更好的问答、编写SQL代码、理解具体场景的业务关系等）就是两类差别较大的提示工程方法，前者侧重于引导模型创建更加符合要求的文本，而后者则要求模型具备一定的学习和推理能力。课程中我们将重点介绍提升模型复杂语义理解能力的提示工程方法，当然，提升模型复杂语义理解能力，相信也是大多数数据技术相关从业者最急迫的需求。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dc3386-61ea-4e71-a8f9-4a69b9bdfc2f",
   "metadata": {},
   "source": [
    "> 基于GPT4的回答——大型语言模型的推理能力可以在许多方面带来好处：</br>1. **更准确的信息获取和提问回答**：如果一个模型能够更好地理解和推理出文本中的信息，那么它就能够更准确地回答问题，提供更相关和详细的信息。</br>2. **更高质量的内容生成**：具有推理能力的模型可以生成更连贯、更符合实际情况的内容，无论是在写作、摘要、翻译等任务中，都能产生更好的结果。</br>3. **更有效的决策支持**：对于某些需要理解复杂情况并进行推理的任务，如金融分析、医疗诊断等，增强的推理能力可以帮助模型提供更准确和有用的建议。</br>4. **更好的对话和交互能力**：在客户服务、个人助手或其他交互式应用中，推理能力可以使模型更好地理解用户的需求，提供更精确和有帮助的反馈。</br>5. **教育和培训**：在教育和培训中，模型可以帮助学生理解复杂的概念，解答疑问，甚至可以提供个性化的学习建议。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c8340e-4ec8-44cc-a9d9-21800840a87a",
   "metadata": {},
   "source": [
    "> 有一个和提示工程类似的概念名为提示学习（prompt learning），提示学习本身也是一种提示工程的手段，和普通的提示工程有所不同的是，提示学习我们不仅提供目标任务的提示，还让模型自我学习生成有效的提示。在训练过程中，模型将尝试生成各种不同的提示，并通过它们产生的结果来评估这些提示的有效性。最终，模型将学习到哪些提示可以生成最准确的答案。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423a38a0-666c-4f1f-b75f-b0e735212887",
   "metadata": {},
   "source": [
    "- 复杂语义理解能力的试金石——解决推理问题"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0ea8ad-38e1-4499-a837-2cfb3de95022",
   "metadata": {},
   "source": [
    "&emsp;&emsp;而如何验证模型是否具备理解复杂语义的能力？有个非常简单的方法，即观察模型是否能解决复杂逻辑推理问题。若通过模型能够在提示工程引导下，解决原始状态下无法解决的推理问题，则说明提示工程能够提升模型的推理能力，并且越有效的提示工程对模型推理能力提升幅度越大，这点能够通过设置不同复杂程度的推理问题来进行验证。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98c9555-9f37-4451-bcaa-075ef3eef2f6",
   "metadata": {},
   "source": [
    "&emsp;&emsp;这里我们先提出四个推理问题，这四个问题都超出了默认原始状态‘text-davinci-003’模型的能力范围，即‘text-davinci-003’在不进行任何有效提示的情况下，是无法回答这些问题的。当然，也正是这个原因，这四个问题可以用于验证接下来的提示工程是否有效，这四个问题及默认状态下‘text-davinci-003’回答结果如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e89a569-824c-4031-b03a-067bff9ffaca",
   "metadata": {},
   "source": [
    "> 这四个问题也是非常经典的推理问题，分别节选自近期四篇提示工程的论文，关于具体的论文内容稍后会进行介绍。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "911f6f5f-9c8a-45b3-b6d7-2c2b8efa7be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbb1860-7fab-4702-a0a1-d898282b21b3",
   "metadata": {},
   "source": [
    "推理题1："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f6ecd47-5e8e-46b0-a1da-19c87ccfeb2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'罗杰有五个网球，他又买了两盒网球，每盒有3个网球，请问他现在总共有多少个网球？'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt1 = '罗杰有五个网球，他又买了两盒网球，每盒有3个网球，请问他现在总共有多少个网球？'\n",
    "prompt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a9a022e-a871-4d74-9193-e68db6218ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response1 = openai.Completion.create(\n",
    "            model=\"text-davinci-003\",\n",
    "            prompt=prompt1,\n",
    "            max_tokens=1000,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0677c3c0-efde-49e0-88a7-251dcb6e6823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'现在罗杰总共有11个网球。'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response1[\"choices\"][0][\"text\"].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c6ad5c-bf73-45aa-abad-85e5e1290e87",
   "metadata": {},
   "source": [
    "能够发现，此时模型推理得到了正确的结果，罗杰目前总共由5+2*3=11个网球。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e853a3-113d-4dc2-b8bf-9616274d4b6a",
   "metadata": {},
   "source": [
    "推理题2："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfd45515-034f-4183-a4e6-b7578031b304",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = '食堂总共有23个苹果，如果他们用掉20个苹果，然后又买了6个苹果，请问现在食堂总共有多少个苹果？'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24a8acb6-4923-4fc8-8b6b-823c00064b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "response2 = openai.Completion.create(\n",
    "            model=\"text-davinci-003\",\n",
    "            prompt=prompt2,\n",
    "            max_tokens=1000,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78772a4e-6f49-48de-bf28-384f4908e942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'现在食堂总共有23+6=29个苹果。'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2[\"choices\"][0][\"text\"].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded1c644-2609-46bb-ac52-d598b59b85c1",
   "metadata": {},
   "source": [
    "第二个逻辑题比第一个逻辑题稍微复杂一些——复杂之处在于逻辑上稍微转了个弯，即食堂不仅增加了6个苹果，而且还消耗了20个苹果。有增有减，大模型就无法做出正确判断了。正确答案应该是目前食堂还剩23-20+6=9个苹果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19d38e2-fc47-4d78-b7e0-0c22cf741f69",
   "metadata": {},
   "source": [
    "推理题3："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "304e9c92-e774-4470-9cf5-2dbed7fb848d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'杂耍者可以杂耍16个球。其中一半的球是高尔夫球，其中一半的高尔夫球是蓝色的。请问总共有多少个蓝色高尔夫球？'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt3 = '杂耍者可以杂耍16个球。其中一半的球是高尔夫球，其中一半的高尔夫球是蓝色的。请问总共有多少个蓝色高尔夫球？'\n",
    "prompt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bdb5433f-cc20-47b7-8c89-3b770028420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response3 = openai.Completion.create(\n",
    "            model=\"text-davinci-003\",\n",
    "            prompt=prompt3,\n",
    "            max_tokens=1000,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09bedcb8-ed4b-458e-9cef-97b72e91809f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'总共有8个蓝色高尔夫球。'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response3[\"choices\"][0][\"text\"].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d3097a-e818-4801-8ad4-586d956bae7d",
   "metadata": {},
   "source": [
    "第三个逻辑题的数学计算过程并不复杂，但却设计了一个语言陷阱，即一半的一半是多少。能够发现，模型无法围绕这个问题进行准确的判断，正确答案应该是16\\*0.5\\*0.5=4个蓝色高尔夫球。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841bb55f-639b-4db7-b38d-16436c9ea6ba",
   "metadata": {},
   "source": [
    "推理题4："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "06d8a3c2-9bf8-4efd-b883-4b64329451e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'艾米需要4分钟才能爬到滑梯顶部，她花了1分钟才滑下来，水滑梯将在15分钟后关闭，请问在关闭之前她能滑多少次？'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt4 = '艾米需要4分钟才能爬到滑梯顶部，她花了1分钟才滑下来，水滑梯将在15分钟后关闭，请问在关闭之前她能滑多少次？'\n",
    "prompt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a857412e-9eb6-421c-92aa-2c00ba626010",
   "metadata": {},
   "outputs": [],
   "source": [
    "response4 = openai.Completion.create(\n",
    "            model=\"text-davinci-003\",\n",
    "            prompt=prompt4,\n",
    "            max_tokens=1000,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "be78df4a-339e-43db-87e2-97ecbc3fda09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'在关闭之前她能滑10次。'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response4[\"choices\"][0][\"text\"].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7182429f-b2a3-4ce5-93c3-33ec71b2fa9c",
   "metadata": {},
   "source": [
    "第四个逻辑题是这些逻辑题里数学计算过程最复杂的，涉及多段计算以及除法运算。正确的计算过程应该是先计算艾米一次爬上爬下总共需要5分钟，然后滑梯还有15分钟关闭，因此关闭之前能够再滑15/5=3次。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1960ac-f81c-44f6-af24-1c2f282b55a7",
   "metadata": {},
   "source": [
    "&emsp;&emsp;综上来看，'text-davinci-003'在Zero-shot的情况下，逻辑推理能力较弱，只能围绕相对简单的、只有线性运算过程的推理问题进行很好的解答，总的来看模型只正确回答了第一个问题，其他问题都答错了，模型的推理能力堪忧。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0314a6a3-d0fe-48f5-8ba3-dd213e3c88d2",
   "metadata": {},
   "source": [
    "### 1.One-shot & Few-shot提示学习法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6972b9c0-73a0-4818-aaf8-3e3c8bec46a8",
   "metadata": {},
   "source": [
    "&emsp;&emsp;首先，最为简单的提示工程的方法就是通过输入一些类似问题和问题答案，让模型参考学习，并在同一个prompt的末尾提出新的问题，依次提升模型的推理能力。这种方法也被称为One-shot或者Few-shot提示方法。One-shot和Few-shot最早由OpenAI研究团队在论文[《Language Models are Few-Shot Learners\n",
    "》](https://arxiv.org/pdf/2005.14165.pdf)中率先提出，这篇论文也是提示工程方法开山鼻祖，不仅介绍了提示工程的两大核心方法，同时也详细介绍这么做背后的具体原因。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d37b44-13eb-4d56-82ae-212e8a0fb39b",
   "metadata": {},
   "source": [
    "> 注，由于One-shot和Few-shot的区别仅在于提示词中包含的示例个数，但本质上都是先在提示词中输入示例，然后让模型仿造示例解答当前的问题，因此为了表达方面，后续课程中不再区分One-shot和Few-shot，而是统一称呼为Few-shot。这也是近两年来业内逐渐统一的称呼规范。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e9dc2a-9799-418a-a72f-7d94e3fb3538",
   "metadata": {},
   "source": [
    "&emsp;&emsp;不过就具体的应用来说，Few-shot提示方法并不复杂，我们只需要将一些类似的问题的问题+答案作为prompt的一部分进行输入即可。例如我们首先把模型能够正确回答的第一个例子作为提示词输入，查看能否顺利推理出第二个问题："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cf4ae638-59d0-4853-84ec-f5227e824f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q：“罗杰有五个网球，他又买了两盒网球，每盒有3个网球，请问他现在总共有多少个网球？”                   A：“现在罗杰总共有11个网球。”                   Q：“食堂总共有23个苹果，如果他们用掉20个苹果，然后又买了6个苹果，请问现在食堂总共有多少个苹果？”                   A：'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_Few_shot1 = 'Q：“罗杰有五个网球，他又买了两盒网球，每盒有3个网球，请问他现在总共有多少个网球？” \\\n",
    "                  A：“现在罗杰总共有11个网球。” \\\n",
    "                  Q：“食堂总共有23个苹果，如果他们用掉20个苹果，然后又买了6个苹果，请问现在食堂总共有多少个苹果？” \\\n",
    "                  A：'\n",
    "prompt_Few_shot1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a42a6d-53fb-4a43-b460-3b5c09a10875",
   "metadata": {},
   "source": [
    "> 注意这里的进行Few-shot时候提示的编写格式，当我们需要输入多段问答作为提示词时，往往以Q作为问题的开头、A作为回答的开头（这里也可以换成“问题”、“答案”），并且不同的问答对话需要换行以便于更加清晰的展示，具体方法是通过转义符+换行来完成，这样换行之后仍然还在一个字符串内。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d713274a-55a3-4402-a092-7502e348f62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_Few_shot1 = openai.Completion.create(\n",
    "                     model=\"text-davinci-003\",\n",
    "                     prompt=prompt_Few_shot1,\n",
    "                     max_tokens=1000,\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ac571a4b-2f9c-43b7-95e3-d3e7642b5927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'“现在食堂总共有9个苹果。”'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_Few_shot1[\"choices\"][0][\"text\"].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080a7c78-5f85-49ae-acc2-7bccc5115633",
   "metadata": {},
   "source": [
    "虽然无法确定模型预测过程发生了何种变化，但在学习了第一个例子之后，模型确实能够对第二个问题做出准确判断。能够发现Few-shot在提升模型逻辑推理能力方面能够起到一定作用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94086c77-6ab7-4340-a276-31f9f5fedda2",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来我们将上面两个例子的问答都作为提示词进行输入，并查看模型是否能正确回答第三个问题："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9b4d0113-c5a1-4a04-96c5-c19d41d0e3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q：“罗杰有五个网球，他又买了两盒网球，每盒有3个网球，请问他现在总共有多少个网球？”                   A：“现在罗杰总共有11个网球。”                   Q：“食堂总共有23个苹果，如果他们用掉20个苹果，然后又买了6个苹果，请问现在食堂总共有多少个苹果？”                   A：“现在食堂总共有9个苹果。”                   Q：“杂耍者可以杂耍16个球。其中一半的球是高尔夫球，其中一半的高尔夫球是蓝色的。请问总共有多少个蓝色高尔夫球？”                   A：'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_Few_shot2 = 'Q：“罗杰有五个网球，他又买了两盒网球，每盒有3个网球，请问他现在总共有多少个网球？” \\\n",
    "                  A：“现在罗杰总共有11个网球。” \\\n",
    "                  Q：“食堂总共有23个苹果，如果他们用掉20个苹果，然后又买了6个苹果，请问现在食堂总共有多少个苹果？” \\\n",
    "                  A：“现在食堂总共有9个苹果。” \\\n",
    "                  Q：“杂耍者可以杂耍16个球。其中一半的球是高尔夫球，其中一半的高尔夫球是蓝色的。请问总共有多少个蓝色高尔夫球？” \\\n",
    "                  A：'\n",
    "prompt_Few_shot2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aaf6758a-7173-4fdb-90a8-a7f8fead0be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_Few_shot2 = openai.Completion.create(\n",
    "                     model=\"text-davinci-003\",\n",
    "                     prompt=prompt_Few_shot2,\n",
    "                     max_tokens=1000,\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "86bda9ec-d8c9-4ec5-8652-32f2b0da3a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'“总共有8个蓝色高尔夫球。”'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_Few_shot2[\"choices\"][0][\"text\"].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fcf4cd-8e20-45a7-b517-31472c0c929d",
   "metadata": {},
   "source": [
    "能够发现模型对第三个问题仍然回答错误。接下来尝试把前两个问题作为提示词的一部分，让模型回答第四个问题："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8267a71f-4493-4511-8f1a-578a8c2dd4f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q：“罗杰有五个网球，他又买了两盒网球，每盒有3个网球，请问他现在总共有多少个网球？”                   A：“现在罗杰总共有11个网球。”                   Q：“食堂总共有23个苹果，如果他们用掉20个苹果，然后又买了6个苹果，请问现在食堂总共有多少个苹果？”                   A：“现在食堂总共有9个苹果。”                   Q：“艾米需要4分钟才能爬到滑梯顶部，她花了1分钟才滑下来，水滑梯将在15分钟后关闭，请问在关闭之前她能滑多少次？”                   A：'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_Few_shot3 = 'Q：“罗杰有五个网球，他又买了两盒网球，每盒有3个网球，请问他现在总共有多少个网球？” \\\n",
    "                  A：“现在罗杰总共有11个网球。” \\\n",
    "                  Q：“食堂总共有23个苹果，如果他们用掉20个苹果，然后又买了6个苹果，请问现在食堂总共有多少个苹果？” \\\n",
    "                  A：“现在食堂总共有9个苹果。” \\\n",
    "                  Q：“艾米需要4分钟才能爬到滑梯顶部，她花了1分钟才滑下来，水滑梯将在15分钟后关闭，请问在关闭之前她能滑多少次？” \\\n",
    "                  A：'\n",
    "prompt_Few_shot3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9b3238b6-246c-4474-bc2a-8f6e2835c803",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_Few_shot3 = openai.Completion.create(\n",
    "                     model=\"text-davinci-003\",\n",
    "                     prompt=prompt_Few_shot3,\n",
    "                     max_tokens=1000,\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9b531677-7435-4733-a222-f19ab987f5b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'“在关闭之前，艾米可以滑下4次水滑梯。”'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_Few_shot3[\"choices\"][0][\"text\"].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de92bbb-6935-4502-b30c-1b3493d91d08",
   "metadata": {},
   "source": [
    "第四个问题也回答错误。这说明Few-shot提示方法能够一定程度提高模型推理能力，但提升的幅度有限，对于稍微复杂些的推理问题，模型仍然无法做出准确的回答。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2a9202-1046-4a1f-b18d-dbda17880c61",
   "metadata": {},
   "source": [
    "&emsp;&emsp;不过这里需要注意的是，尽管看似Few-shot的使用方法较为简单，但实际上Few-shot有非常多的变种方法——其中一类非常重要的变种方法就是围绕提示的示例进行修改，即在示例中不仅提供问题+答案，同时还会增加一些辅助思考和判断的“提示”。因此后面的我们介绍的很多方法，尽管提示的内容各有不同，但基本都可以从Few-shot角度进行理解。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f028230c-ea05-4c2a-b1e1-88ba5c19cbbc",
   "metadata": {},
   "source": [
    "### 2.通过思维链提示法提升模型推理能力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d867b419-5ef9-49a0-a22f-0dcc013af6ad",
   "metadata": {},
   "source": [
    "#### 2.1 Zero-shot-CoT提示方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314274a0-6668-462b-87f2-66d7a979e484",
   "metadata": {},
   "source": [
    "- Zero-shot-CoT实现过程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013651f0-36be-45ba-a5e1-fcc95a5b7471",
   "metadata": {},
   "source": [
    "&emsp;&emsp;那有什么办法能够通过更好的提示来提高模型的推理能力呢？最简单的一类办法就是借助思维链（也被称为思考链，Chain of Thought，CoT）提示法来解决这个问题。在这些方法中，最为简单的思维链的实现方法是在提示词尾部追加一句“Let’s think step by step”，即可大幅提高模型推理能力。这种方法最早由东京大学和谷歌在论文[《Large Language Models are Zero-Shot Reasoners》](https://arxiv.org/pdf/2205.11916v2.pdf)中提出。由于只需要修改提示词而无需手动编写推导的成功示例（无需编写思维链样本），因此这种方法也被称为Zero-shot-CoT。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36403673-e872-4a8a-8e81-29cde7d82b2d",
   "metadata": {},
   "source": [
    "> 从论文标题能看出，改论文有叫板OpenAI论文《Language Models are Few-Shot Learners 》的嫌疑。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012eeb2e-48e7-47e6-b9c3-ae793d6ba21e",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来我们尝试借助Zero-shot-CoT解决之前的推理问题。这里需要注意，“Let’s think step by step”其实是一句“具有魔法”的语句，是一个经过很多次尝试最终总结出来的、对大模型推理能力提升效果最为显著的提示词后缀，因此在将词句翻译为中文的时候，我们也仿造原论文进行了海量的尝试和实验，最终判断将其翻译为“请一步步进行推理并得出结论”，对提升模型推理能力最为有效。这里我们尝试以“请一步步进行推理并得出结论”为提示词后缀，查看能否解决此前的推理问题："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f87acc98-6aec-40a1-ae45-775749c5ddf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'罗杰有五个网球，他又买了两盒网球，每盒有3个网球，请问他现在总共有多少个网球？请一步步进行推理并得出结论。'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_Zero_shot_CoT1 = '罗杰有五个网球，他又买了两盒网球，每盒有3个网球，请问他现在总共有多少个网球？请一步步进行推理并得出结论。'\n",
    "prompt_Zero_shot_CoT1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "247f220c-8514-48c1-95e0-ccad0181d8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_Zero_shot_CoT1 = openai.Completion.create(\n",
    "                          model=\"text-davinci-003\",\n",
    "                          prompt=prompt_Zero_shot_CoT1,\n",
    "                          max_tokens=1000,\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3a850787-4f89-4167-9460-b1e22c7ba4ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. 首先，罗杰原有五个网球。\\n\\n2. 罗杰又购买了两盒网球，每盒3个，共6个。\\n\\n3. 由此可知，罗杰现在总共有11个网球。'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_Zero_shot_CoT1[\"choices\"][0][\"text\"].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e591b06-a88a-4fe9-9740-9027b47c991f",
   "metadata": {},
   "source": [
    "第一题回答正确，接下来看第二题："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7f61ca25-e143-41ba-9e95-250712b9701f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'食堂总共有23个苹果，如果他们用掉20个苹果，然后又买了6个苹果，请问现在食堂总共有多少个苹果？请一步步进行推理并得出结论。'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_Zero_shot_CoT2 = '食堂总共有23个苹果，如果他们用掉20个苹果，然后又买了6个苹果，请问现在食堂总共有多少个苹果？请一步步进行推理并得出结论。'\n",
    "prompt_Zero_shot_CoT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "231c6d8a-649f-419b-b344-276752c1ec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_Zero_shot_CoT2 = openai.Completion.create(\n",
    "                          model=\"text-davinci-003\",\n",
    "                          prompt=prompt_Zero_shot_CoT2,\n",
    "                          max_tokens=1000,\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1cca5f9c-6ced-45be-8cf8-71ede9cf6521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'答：\\n\\n① 食堂最开始总共有23个苹果；\\n\\n② 用掉20个苹果后，剩下3个苹果；\\n\\n③ 后来又买了6个苹果；\\n\\n④ 现在食堂总共有3个苹果加上新买的6个苹果，故现在食堂总共有9个苹果。'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_Zero_shot_CoT2[\"choices\"][0][\"text\"].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de935185-fbe1-4e18-8437-a0e2912252ae",
   "metadata": {},
   "source": [
    "第二题回答正确，接下来看第三题："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "295848e5-17ed-4c37-bebc-d6849603332a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'杂耍者可以杂耍16个球。其中一半的球是高尔夫球，其中一半的高尔夫球是蓝色的。请问总共有多少个蓝色高尔夫球？请一步步进行推理并得出结论。'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_Zero_shot_CoT3 = '杂耍者可以杂耍16个球。其中一半的球是高尔夫球，其中一半的高尔夫球是蓝色的。请问总共有多少个蓝色高尔夫球？请一步步进行推理并得出结论。'\n",
    "prompt_Zero_shot_CoT3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3420dde8-89a3-432a-ab69-a6f90604a7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_Zero_shot_CoT3 = openai.Completion.create(\n",
    "                          model=\"text-davinci-003\",\n",
    "                          prompt=prompt_Zero_shot_CoT3,\n",
    "                          max_tokens=1000,\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "99527b42-0273-4e62-b9f1-8a98ae0970ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'首先，要得到总共有多少个蓝色高尔夫球，我们要知道高尔夫球的总数量。由条件可知，高尔夫球的总数量是16个球的一半，即8个。\\n\\n接下来，我们还要知道蓝色高尔夫球的数量。根据条件，1半的高尔夫球的是蓝色的，也就是说，蓝色高尔夫球的数量应该等于8个球的一半，即4个。\\n\\n因此，总共有4个蓝色高尔夫球。'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_Zero_shot_CoT3[\"choices\"][0][\"text\"].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b0c4ce-f850-4fce-a577-1440a6c7d1bb",
   "metadata": {},
   "source": [
    "第三题也回答正确，接下来看第四题："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5c09fd6c-6161-48d1-bd5f-1f12c26b4aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'艾米需要4分钟才能爬到滑梯顶部，她花了1分钟才滑下来，水滑梯将在15分钟后关闭，请问在关闭之前她能滑多少次？请一步步进行推理并得出结论。'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_Zero_shot_CoT4 = '艾米需要4分钟才能爬到滑梯顶部，她花了1分钟才滑下来，水滑梯将在15分钟后关闭，请问在关闭之前她能滑多少次？请一步步进行推理并得出结论。'\n",
    "prompt_Zero_shot_CoT4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e431f18c-46bf-449b-9d1b-4bce5beb1696",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_Zero_shot_CoT4 = openai.Completion.create(\n",
    "            model=\"text-davinci-003\",\n",
    "            prompt=prompt_Zero_shot_CoT4,\n",
    "            max_tokens=1000,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "72111d9c-a8aa-43d9-b3c7-d47c1383c1dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'步骤一：计算出剩余的时间\\n\\n剩余时间 = 15分钟 - 1分钟 = 14分钟。\\n\\n步骤二：计算她可以滑的次数\\n\\n每次滑梯需要4分钟，所以她可以滑14分钟/4分钟 = 3.5次滑梯。\\n\\n步骤三：得出结论\\n\\n因为滑梯次数只能是整数，所以她能在15分钟内滑3次滑梯。'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_Zero_shot_CoT4[\"choices\"][0][\"text\"].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573f158d-0766-4af0-8143-fd4c4c2f2c45",
   "metadata": {},
   "source": [
    "这里需要注意，尽管第四题答案正确，但推理过程并不正确，至于总共能滑3.5次云云，更是不符合逻辑。因此第四题其实仍然回答错误。不难发现，第四题的逻辑推导其实是最难的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e46ef31-9f09-4df9-956c-82c2936c97c6",
   "metadata": {},
   "source": [
    "&emsp;&emsp;综上，经过四个逻辑推导题的验证，我们发现相比Few-shot，Zero-shot-CoT确实更加有效，即能够通过更加简洁的提示来大幅提高模型推理能力。当然我们这里只列举了四个例子用于验证模型推理能力，更加严谨的、在海量推理场景中验证的Zero-shot-CoT有效性的结论，我们可以参考《Large Language Models are Zero-Shot Reasoners》论文中的相关说明。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167ee235-653c-405b-a56a-3abe6dfd8619",
   "metadata": {},
   "source": [
    "- 《Large Language Models are Zero-Shot Reasoners》重点结论解读"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3933fbd3-3c2e-48cd-9b2c-7a9b58612b9e",
   "metadata": {},
   "source": [
    "&emsp;&emsp;根据原论文描述，作者在测试Zero_shot_CoT方法时曾尝试过多组不同的提示词尾缀，并在一个机器人指令数据集上进行测试，最终发现“Let’s think step by step”效果最好，其他指令及各指令准确率排名如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba7e0ec-abf7-4655-8fbc-35ffd7824c8c",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202306271728028.png\" alt=\"3f518f011f3ea3af088b67e4512b32b\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44595b8c-08d4-4f03-905a-cc818db0313b",
   "metadata": {},
   "source": [
    "类似的，就该指令“Let’s think step by step”的中文翻译而言，“请一步步进行推理并得出结论”要远远好于“请让我们一步步进行思考”等类似的提示词语句。这一客观情况也给大模型使用者非常深刻的启发，那就是大模型的“思考过程”是黑箱模型，哪怕表意近似的提示词对模型来说实际的影响力可能会有非常大的区别，围绕提示词的开发需要进行大量的尝试，这个过程也非常类似于掘金的过程。而对于实际使用者而言，则需要平日多注重提示词的积累和尝试。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c22d9c1-5d8b-4ec1-b99f-57a583e959af",
   "metadata": {},
   "source": [
    "&emsp;&emsp;其次，论文中首次提出了利用大模型进行两阶段推理的设想，即第一个阶段先进行问题的拆分并分段解答问题（Reasoning Extraction），然后第二阶段再进行答案的汇总（Answer Extraction）。这一设想尽管没有在论文中进行大量验证，但却给之后的一种名为LEAST-TO-MOST（LtM）的提示方法给予了启发，该方法将在后文中进行介绍。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dce6e44-08b6-4640-ab1e-e5f0590b3b2e",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202306281608939.png\" alt=\"56bfaaf380a3efc0e47bc54472c7020\" style=\"zoom: 40%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f0cba0-40f4-404b-b1f2-299d67d1b86d",
   "metadata": {},
   "source": [
    "&emsp;&emsp;论文中第三个非常重要的结论，就是将Zero-shot-CoT方法和Few-shot-CoT方法进行了比较，根据论文中结论，在实际使用过程中，Zero-shot-CoT要略弱于Few-shot-CoT方法，而后者则是一种CoT方法和Few-shot方法的结合，我们稍后会进行介绍。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae124cfa-5ca4-45ef-bb94-31b3d6ea5530",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202306271733865.png\" alt=\"6087bb98316b2908cfa38fe01f1bbad\" style=\"zoom:40%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b79c5e7-0687-4378-959e-c68945fe2bd9",
   "metadata": {},
   "source": [
    "同时需要注意的是，论文明确表示，模型越大CoT效果越好，换而言之就是模型越大，CoT对模型“涌现能力”的激发效果越好。并且GPT-3在GSM8K数据集上能达到55%左右准确率，而后者则是一个非常著名的小学数学应用题组成的数据集，往往用于测试模型的推理能力。后续其他模型的推理能力比较也将用到这个数据集。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12b3e73-b68c-4166-9f26-5f6026d916f7",
   "metadata": {},
   "source": [
    "#### 2.2 Few-shot-CoT提示方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ba24b4-7aad-484c-9d1b-145f01e1b14e",
   "metadata": {},
   "source": [
    "- Few-shot-CoT实现过程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2f4410-6c48-4edc-bb23-c9d675f36581",
   "metadata": {},
   "source": [
    "&emsp;&emsp;哪怕是CoT方法，即然可以Zero-shot-CoT，自然也可以Few-shot-CoT。需要注意的是，Zero-shot-CoT是零样本提示的情况下通过修改提示词后缀激发模型的思维链，而Few-shot-CoT则是通过通过编写思维链样本作为提示词，让模型学会思维链的推导方式，从而更好的完成推导任务。该方法最早由谷歌大脑团队在论文[《Chain-of-Thought Prompting Elicits Reasoning in Large Language Models》](https://arxiv.org/pdf/2201.11903.pdf)中首次提出，也是在这篇论文中思维链的概念被首次提出，因此该论文可以说是思维链的开山鼻祖之作。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af90e8ba-d1fc-4a3d-8eba-9a0e00fb39ff",
   "metadata": {},
   "source": [
    "> 这里需要注意，从诞生时间上来说，Few-shot-CoT诞生时间要早于Zero-shot-CoT，课程中是按照先易后难的顺序编排的内容，所以先介绍Zero-shot-CoT、后介绍Few-shot-CoT。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36134627-f304-4f2c-8e2f-9b989a597e47",
   "metadata": {},
   "source": [
    "其实相比于Few-shot，Few-shot-CoT的不同之处只是在于需要在提示样本中不仅给出问题的答案、还同时需要给出问题推导的过程（即思维链），从而让模型学到思维链的推导过程，并将其应用到新的问题中。例如，围绕上述四个推理问题，第一个问题是比较好解决的，我们可以手动写一个思维链作为Few-shot的示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "cc836c4a-30fe-4b36-9bfe-ed61cef42b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q：“罗杰有五个网球，他又买了两盒网球，每盒有3个网球，请问他现在总共有多少个网球？” A：“罗杰一开始有五个网球，又购买了两盒网球，每盒3个，共购买了6个网球，因此现在总共由5+6=11个网球。因此答案是11。” '"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Q：“罗杰有五个网球，他又买了两盒网球，每盒有3个网球，请问他现在总共有多少个网球？” \\\n",
    "A：“罗杰一开始有五个网球，又购买了两盒网球，每盒3个，共购买了6个网球，因此现在总共由5+6=11个网球。因此答案是11。” '"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993f34a3-d85b-49ed-9cb5-59587034fcb9",
   "metadata": {},
   "source": [
    "当然类似这种思维链，也可以借助此前的Zero-shot-CoT来完成创建。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6b71ec-c2d8-4d28-be3a-0e59e466a6c3",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在获得了一个思维链示例后，我们即可以此作为样本进行Few-shot-CoT来解决第二个推理问题，具体执行过程如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "55949def-0e84-4991-9db0-63494ebfae16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q：“罗杰有五个网球，他又买了两盒网球，每盒有3个网球，请问他现在总共有多少个网球？”                         A：“罗杰一开始有五个网球，又购买了两盒网球，每盒3个，共购买了6个网球，因此现在总共由5+6=11个网球。因此答案是11。”                         Q：“食堂总共有23个苹果，如果他们用掉20个苹果，然后又买了6个苹果，请问现在食堂总共有多少个苹果？”                         A：'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_Few_shot_CoT2 = 'Q：“罗杰有五个网球，他又买了两盒网球，每盒有3个网球，请问他现在总共有多少个网球？” \\\n",
    "                        A：“罗杰一开始有五个网球，又购买了两盒网球，每盒3个，共购买了6个网球，因此现在总共由5+6=11个网球。因此答案是11。” \\\n",
    "                        Q：“食堂总共有23个苹果，如果他们用掉20个苹果，然后又买了6个苹果，请问现在食堂总共有多少个苹果？” \\\n",
    "                        A：'\n",
    "prompt_Few_shot_CoT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1abc27af-70c9-4acb-96e2-d9891144692d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_Few_shot_CoT2 = openai.Completion.create(\n",
    "                         model=\"text-davinci-003\",\n",
    "                         prompt=prompt_Few_shot_CoT1,\n",
    "                         max_tokens=1000,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bc0712e3-64bc-46af-a7f3-7f4f6d20c163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'“食堂最初有23个苹果，用掉20个，然后又买了6个，总共有23-20+6=9个苹果，答案是9。”'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_Few_shot_CoT2[\"choices\"][0][\"text\"].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff2b2bb-2f54-44d8-b22a-631d3a7e4107",
   "metadata": {},
   "source": [
    "能够发现，模型能够非常好的回答第二个问题，接下来我们稍微做些调整，即把每个做出成功预测的思维链都作为例子写入Few-shot-CoT中，增加大模型学习样本，从而更好的解决之后的问题。例如我们可以把前两个问题的思维链作为提示词输入，来引导模型解决第三个问题："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "77a25a0f-a18b-4d98-8b81-bf1adfd9a114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q：“罗杰有五个网球，他又买了两盒网球，每盒有3个网球，请问他现在总共有多少个网球？”                         A：“罗杰一开始有五个网球，又购买了两盒网球，每盒3个，共购买了6个网球，因此现在总共由5+6=11个网球。因此答案是11。”                         Q：“食堂总共有23个苹果，如果他们用掉20个苹果，然后又买了6个苹果，请问现在食堂总共有多少个苹果？”                         A：“食堂最初有23个苹果，用掉20个，然后又买了6个，总共有23-20+6=9个苹果，答案是9。”                         Q：“杂耍者可以杂耍16个球。其中一半的球是高尔夫球，其中一半的高尔夫球是蓝色的。请问总共有多少个蓝色高尔夫球？”                         A：'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_Few_shot_CoT3 = 'Q：“罗杰有五个网球，他又买了两盒网球，每盒有3个网球，请问他现在总共有多少个网球？” \\\n",
    "                        A：“罗杰一开始有五个网球，又购买了两盒网球，每盒3个，共购买了6个网球，因此现在总共由5+6=11个网球。因此答案是11。” \\\n",
    "                        Q：“食堂总共有23个苹果，如果他们用掉20个苹果，然后又买了6个苹果，请问现在食堂总共有多少个苹果？” \\\n",
    "                        A：“食堂最初有23个苹果，用掉20个，然后又买了6个，总共有23-20+6=9个苹果，答案是9。” \\\n",
    "                        Q：“杂耍者可以杂耍16个球。其中一半的球是高尔夫球，其中一半的高尔夫球是蓝色的。请问总共有多少个蓝色高尔夫球？” \\\n",
    "                        A：'\n",
    "prompt_Few_shot_CoT3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "13b0b39c-20bd-4542-a1cf-4c272e0bbe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_Few_shot_CoT3 = openai.Completion.create(\n",
    "                         model=\"text-davinci-003\",\n",
    "                         prompt=prompt_Few_shot_CoT3,\n",
    "                         max_tokens=1000,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "68a84657-9e0d-4575-86db-b06a710a7636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'“总共有16个球，其中一半是高尔夫球，也就是8个，其中一半是蓝色的，也就是4个，答案是4个。”'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_Few_shot_CoT3[\"choices\"][0][\"text\"].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2e191c-ed69-4fd3-91f8-1d6f13b89bab",
   "metadata": {},
   "source": [
    "能够发现第三个问题也能够被顺利解决。接下来是最后一个问题："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "30cc0df5-df46-4a10-b840-cc40e4e65e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q：“罗杰有五个网球，他又买了两盒网球，每盒有3个网球，请问他现在总共有多少个网球？”                         A：“罗杰一开始有五个网球，又购买了两盒网球，每盒3个，共购买了6个网球，因此现在总共由5+6=11个网球。因此答案是11。”                         Q：“食堂总共有23个苹果，如果他们用掉20个苹果，然后又买了6个苹果，请问现在食堂总共有多少个苹果？”                         A：“食堂最初有23个苹果，用掉20个，然后又买了6个，总共有23-20+6=9个苹果，答案是9。”                         Q：“杂耍者可以杂耍16个球。其中一半的球是高尔夫球，其中一半的高尔夫球是蓝色的。请问总共有多少个蓝色高尔夫球？”                         A：“总共有16个球，其中一半是高尔夫球，也就是8个，其中一半是蓝色的，也就是4个，答案是4个。”                         Q：“艾米需要4分钟才能爬到滑梯顶部，她花了1分钟才滑下来，水滑梯将在15分钟后关闭，请问在关闭之前她能滑多少次？”                         A：'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_Few_shot_CoT4 = 'Q：“罗杰有五个网球，他又买了两盒网球，每盒有3个网球，请问他现在总共有多少个网球？” \\\n",
    "                        A：“罗杰一开始有五个网球，又购买了两盒网球，每盒3个，共购买了6个网球，因此现在总共由5+6=11个网球。因此答案是11。” \\\n",
    "                        Q：“食堂总共有23个苹果，如果他们用掉20个苹果，然后又买了6个苹果，请问现在食堂总共有多少个苹果？” \\\n",
    "                        A：“食堂最初有23个苹果，用掉20个，然后又买了6个，总共有23-20+6=9个苹果，答案是9。” \\\n",
    "                        Q：“杂耍者可以杂耍16个球。其中一半的球是高尔夫球，其中一半的高尔夫球是蓝色的。请问总共有多少个蓝色高尔夫球？” \\\n",
    "                        A：“总共有16个球，其中一半是高尔夫球，也就是8个，其中一半是蓝色的，也就是4个，答案是4个。” \\\n",
    "                        Q：“艾米需要4分钟才能爬到滑梯顶部，她花了1分钟才滑下来，水滑梯将在15分钟后关闭，请问在关闭之前她能滑多少次？” \\\n",
    "                        A：'\n",
    "prompt_Few_shot_CoT4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "64388c28-e5cc-4557-881e-27c7d20c6a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_Few_shot_CoT4 = openai.Completion.create(\n",
    "                         model=\"text-davinci-003\",\n",
    "                         prompt=prompt_Few_shot_CoT4,\n",
    "                         max_tokens=1000,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2c8389ab-938f-462a-a285-1ee09009c5f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'“艾米需要4分钟才能爬到顶部，滑下来需要1分钟，水滑梯将在15分钟后关闭，因此她可以在15分钟内完成滑下来爬上去的循环，她能在关闭之前滑多少次就取决于在15分钟内有多少次循环，也就是(15分钟÷(4分钟+1分钟))等于2.5，答案是2.5次。”'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_Few_shot_CoT4[\"choices\"][0][\"text\"].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df1ff02-2e3a-4c98-9440-07bbd936f27f",
   "metadata": {},
   "source": [
    "能够发现，第四个问题果然还是最难的问题，哪怕输入了前三个问题的思维链作为提示词样本，第四个问题仍然无法得到正确的解答。在本次的回答中，过程正确，但模型却算错了(15分钟÷(4分钟+1分钟))，从中也能发现大语言模型的能力瓶颈——无法真正意义上理解文本和数字的含义。当然，在有限的四个推理示例中，Few-shot-CoT效果和Zero-shot-CoT准确率相同，但根据《Large Language Models are Zero-Shot Reasoners》论文中的结论，上从海量数据的测试结果来看，Few-shot-CoT比Zero-shot-CoT准确率更高。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3573da72-5415-47e7-b43c-626f7c3b595c",
   "metadata": {},
   "source": [
    "- 《Chain-of-Thought Prompting Elicits Reasoning in Large Language Models》重点结论解读"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d683f3-84d1-4cf9-8409-6211dbcd4e3a",
   "metadata": {},
   "source": [
    "&emsp;&emsp;由于《Chain-of-Thought Prompting Elicits Reasoning in Large Language Models》是思维链的开山之作，因此论文中提出了大量的关于思维链的应用场景——除了可以用于解决上述推理问题外，思维链还可以被广泛应用于复杂语义理解、符号映射、连贯文本生成等领域。论文中给出了一系列结论，用于论证思维链在这些领域应用的有效性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae40edf-815c-4edc-bbf9-6bcbf4b3f664",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202306281721637.png\" alt=\"6dca198423a3022cdc8b305829d3795\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbbbc85-680d-4a6f-87e9-d30e1c89656b",
   "metadata": {},
   "source": [
    "&emsp;&emsp;此外，论文中还重点强调了模型体量和思维链效果之间的关系，简而言之就是，模型越大、Few-shot-CoT应用效果越好。论文同样以GSM8K数据集为例进行了说明，能够看出模型效果LaMDA（137B）< GPT-3（175B） <  PaLM（540B）。和Zero-shot-CoT类似，模型越大、CoT对模型潜在能力激发效果越好。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02304f8c-95bf-4bc6-9c73-9a9fe1c562f8",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202306281840217.png\" alt=\"38ceffed0bdcb0357932f37241660cc\" style=\"zoom:40%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bcc1df-320b-416a-bed0-90a4346dde0c",
   "metadata": {},
   "source": [
    "> 这里PaLM具体得分为57分，而Prior supervised best（单独训练的最佳有监督学习模型）得分为55分。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76897f37-710d-4bd8-90f5-d4a384723a5b",
   "metadata": {},
   "source": [
    "### 3.CoT改良方法：LEAST-TO-MOST PROMPTING（LtM提示法）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c4da3a-d6f1-4e5b-8028-631334f071d3",
   "metadata": {},
   "source": [
    "#### 3.1 Least-to-Most Prompting基本概念"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983b71a2-6a48-4d86-9370-285616c386ef",
   "metadata": {},
   "source": [
    "&emsp;&emsp;就在谷歌大脑提出的CoT被实际验证能够大幅提升大语言模型的推理能力不久，来自谷歌大脑的另一个团队在此基础上发表了另一篇重量级论文《[LEAST-TO-MOST PROMPTING ENABLES COMPLEX REASONING IN LARGE LANGUAGE MODELS](https://arxiv.org/pdf/2205.10625.pdf)》，并在其中提出了一种名为Least-to-Most（LtM）的提示方法，将大语言模型的推理能力进一步提高。这种名为LtM的提示方法不仅能够将模型在GSM8K上的表现提高至62%，甚至在某些特殊语义解读场景下能够达到3倍于CoT的效果。不得不说，该方法也是截至目前围绕模型推理能力提升的最为有效的提示学习方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ffe1b3-efc5-4f53-9101-bcfbe164c61b",
   "metadata": {},
   "source": [
    "&emsp;&emsp;LtM提示方法提出的初衷是为了解决CoT提示方法泛化能力不足的问题——即通过人工编写的思维链提示样本可能并不能够很好的迁移到别的问题当中去，换而言之，就是解决问题的流程迁移能力不足，即泛化能力不够。而这种泛化能力不足则会导致“新的问题”无法使用“老的模板”进行解决。例如此前的第四个推理问题就是如此。那即然要找到更加普适的解决问题的流程会非常复杂，那能否“千人千面”让大模型自己找到解决当前问题的思维链呢？答案是肯定的，谷歌大脑基于这个思路开发了一种全新的提示流程，即先通过提示过程让模型找到解决该问题必须要分步解决哪几个问题，然后再通过依次解决这些问题来解决最原始的问题。     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977d20b4-79aa-46aa-b90a-e31f67fe25ca",
   "metadata": {},
   "source": [
    "&emsp;&emsp;不难看出整个提示过程会分为两个阶段进行，第一个阶段是自上而下的分解问题（Decompose Question into subquestion），第二个阶段是自下而上的依次解决问题（Sequentially Solve Subquestion），而整个依次回答问题的过程，其实就可以看成是CoT的过程，只不过LtM会要求模型根据每个不同的问题，单独生成解决问题的链路，以此做到解决问题流程的“千人千面”，从而能够更加精准的解决复杂推理问题。而整个过程问题的由少变多，则是LEAST-TO-MOST一词的来源。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f942b9-9109-40c8-ab52-c756f0e1a138",
   "metadata": {},
   "source": [
    "#### 3.2 Zero-shot-MtL提示过程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edf0964-4de4-4bda-9750-00a59089e7e9",
   "metadata": {},
   "source": [
    "- Least-to-Most Prompting示例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c52f28e-64cf-4bd1-a28e-5fcc018c4995",
   "metadata": {},
   "source": [
    "&emsp;&emsp;这里我们可以通过论文中提出的示例来理解LtM提示过程，具体提示过程如下。这里的例子就是此前我们尝试解决的第四个推理问题，即艾米滑水滑梯的问题，论文中通过提示模板“To solve \\_\\_, we need ti first solve:”来引导模型创建子问题。而模型则会根据原始问题提出子问题“艾米一次爬上滑梯+滑下滑梯总共用时多少”，然后先解决这个子问题，再解决原始问题，不难发现，这其实是一个非常简单的两阶段解决问题的过程——第一个阶段只额外分解了一个子问题（即总共分两个问题作答）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53845fa-d436-463c-bdc5-ffa9cdbf56de",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202306281929457.png\" alt=\"5f282682ac823817560bd7287b12107\" style=\"zoom: 40%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e981bb3f-fe3d-48fc-a5a6-3f0c9b0b5d35",
   "metadata": {},
   "source": [
    "而根据论文中给出的结果不难发现，第一阶段模型能够非常顺利的回答“艾米一次爬上滑梯+滑下滑梯总共用时多少”——5分钟，然后据此顺利回答出在滑梯关闭之前艾米还能玩三次的准确结论。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32a16c4-7406-4cce-9cbe-c656ce448f82",
   "metadata": {},
   "source": [
    "&emsp;&emsp;不过需要注意的是，第二个阶段、即Sequentially Solve Subquestion并不是简单的依次解决两个问题，而是在解决了子问题之后，将原问题、子问题和问题和答案三部分都作为prompt输入给大语言模型，让其对原始问题进行回答。所以不难发现，MtL的核心并不仅仅在于引导模型拆分问题，还在于及时将子问题的问题和答案回传给模型，以便更好的围绕原始问题进行回答。理论上整个过程会有三次调用大模型的过程，问答流程如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d19c68-c0e3-4efc-956c-fddd6661a5f6",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202306292044573.png\" alt=\"4173ae0afb29936452104fc0281a9f4\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54855214-f9bf-426b-93d3-d2b885787d02",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来我们就尝试该提示方法，借助'text-davinci-003'，观察是否能够顺利得到准确答案："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "816a8fbb-31a2-4e24-a01d-3e6fc4e6ce3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q：“艾米需要4分钟才能爬到滑梯顶部，她花了1分钟才滑下来，水滑梯将在15分钟后关闭，请问在关闭之前她能滑多少次？”                         A：为了解决“在关闭之前她能滑多少次？”这个问题，我们首先要解决的问题是'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_Zero_shot_MtL4 = 'Q：“艾米需要4分钟才能爬到滑梯顶部，她花了1分钟才滑下来，水滑梯将在15分钟后关闭，请问在关闭之前她能滑多少次？”\\\n",
    "                         A：为了解决“在关闭之前她能滑多少次？”这个问题，我们首先要解决的问题是'\n",
    "prompt_Zero_shot_MtL4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "5c5fcce9-a156-4c0d-be1d-0bf750d63e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_Zero_shot_MtL4 = openai.Completion.create(\n",
    "                          model=\"text-davinci-003\",\n",
    "                          prompt=prompt_Zero_shot_MtL4,\n",
    "                          max_tokens=1000,\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e83a6faf-a99d-47f9-b71a-50fada300a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'艾米能在多少时间内完成一次爬上去滑下来的过程，这里我们已知艾米花了4分钟爬到滑梯顶部，1分钟滑下来，所以她完成一次流程花费的时间为5分钟。15分钟内能做多少次流程都取决于5分钟能做多少次，15分钟÷5分钟=3次，所以在15分钟内艾米能滑多少次为3次。'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_Zero_shot_MtL4[\"choices\"][0][\"text\"].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9b174d-0edf-409d-b81f-6610cd3d4327",
   "metadata": {},
   "source": [
    "能够发现MtL提示过程能够非常好的解决这个推理问题。并且，在实际测试过程中，模型不仅能够拆解任务，而且还能够自动根据拆解的子问题答案回答原始问题，最终做到在一个提示语句中对原始问题进行准确回答。而正因为在一个提示中能够同时拆解任务+回答子任务+回答原始任务，才使得该提示过程能够更加便捷的使用，而不用像原始论文中展示的那样需要重复将拆分的子问题提交模型来进行回答、然后再将子问题的答案作为提示传递给模型、再围绕原始问题进行提问。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3725c5-10a2-429e-baa5-cead4384e07e",
   "metadata": {},
   "source": [
    "> 这里需要注意的是，能够一次性拆解问题和回答全部问题的能力只有text-davinci-003模型才有，原论文最开始是基于code-davinci-002模型进行的实验，code-davinci-002是gpt-3的基座模型，文本补全能力并不如text-davinci-003模型。不过code-davinci-002并未对外开放，因此目前无法在code-davinci-002进行实验。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec19722-a286-48e3-b161-def015f384ad",
   "metadata": {},
   "source": [
    "> 另外，‘为了解决“\\_\\_”这个问题，我们首先要解决的问题是\\_\\_’也是经过我们验证的、最为恰当、同时也最能够得到准确回答的提示词模板，建议经常使用，并验证其功能。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de11747-7aad-4669-8b8d-8c240a78a408",
   "metadata": {},
   "source": [
    "- Least-to-Most Prompting效果验证"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfb3f31-8de9-46a3-8d54-033d85f8c9a9",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来我们继续尝试借助MtL提示解决剩余三个推理问题："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ede18b1c-7ced-4cff-a496-68b5c6319db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q：“罗杰有五个网球，他又买了两盒网球，每盒有3个网球，请问他现在总共有多少个网球？”                         A：为了解决“罗杰总共又多少个网球？”这个问题，我们首先要解决的问题是'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_Zero_shot_MtL1 = 'Q：“罗杰有五个网球，他又买了两盒网球，每盒有3个网球，请问他现在总共有多少个网球？”\\\n",
    "                         A：为了解决“罗杰总共又多少个网球？”这个问题，我们首先要解决的问题是'\n",
    "prompt_Zero_shot_MtL1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "49602e22-21bf-47aa-8691-8f29dc89cdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_Zero_shot_MtL1 = openai.Completion.create(\n",
    "                        model=\"text-davinci-003\",\n",
    "                        prompt=prompt_Zero_shot_MtL1,\n",
    "                        max_tokens=1000,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "7f4f48b3-35d8-4f0a-bd24-0f02a7c70761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'：他最初有多少个网球？他最后又买了多少个网球？根据问题，可以得出：罗杰最初有5个网球，又买了两盒网球，每盒有3个网球，所以罗杰现在总共有11个网球。'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_Zero_shot_MtL1[\"choices\"][0][\"text\"].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f11bf2d5-ebf1-4e71-8d88-3a07951293b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_Zero_shot_MtL2 = 'Q：“食堂总共有23个苹果，如果他们用掉20个苹果，然后又买了6个苹果，请问现在食堂总共有多少个苹果？”\\\n",
    "                         A：为了解决“现在食堂总共有多少个苹果”这个问题，我们首先要解决的问题是'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "47c9e420-4116-4939-b9c8-2823397b9869",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_Zero_shot_MtL2 = openai.Completion.create(\n",
    "                        model=\"text-davinci-003\",\n",
    "                        prompt=prompt_Zero_shot_MtL2,\n",
    "                        max_tokens=1000,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "9a6876c4-5490-4705-abf7-1449e5b34d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'：20个苹果减去6个苹果之后，食堂总共剩下多少个苹果？所以答案是：食堂现在总共有23-20+6=9个苹果。'"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_Zero_shot_MtL2[\"choices\"][0][\"text\"].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "cc8b0ea4-e2ac-44c2-a377-60c100a7f555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q：“杂耍者可以杂耍16个球。其中一半的球是高尔夫球，其中一半的高尔夫球是蓝色的。请问总共有多少个蓝色高尔夫球？”                         A：为了解决“总共有多少个蓝色高尔夫球”这个问题，我们首先要解决的问题是'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_Zero_shot_MtL3 = 'Q：“杂耍者可以杂耍16个球。其中一半的球是高尔夫球，其中一半的高尔夫球是蓝色的。请问总共有多少个蓝色高尔夫球？”\\\n",
    "                         A：为了解决“总共有多少个蓝色高尔夫球”这个问题，我们首先要解决的问题是'\n",
    "prompt_Zero_shot_MtL3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "54c8d5c9-6d2e-4eaf-b45b-9f41015a1be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_Zero_shot_MtL3 = openai.Completion.create(\n",
    "                        model=\"text-davinci-003\",\n",
    "                        prompt=prompt_Zero_shot_MtL3,\n",
    "                        max_tokens=1000,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "3769027c-3ae5-4854-9cb2-958db307546a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'“总共有多少个高尔夫球”：\\n\\n由于一共有16个球，其中一半是高尔夫球，因此一共有8个高尔夫球。\\n\\n既然其中一半的高尔夫球是蓝色的，那么总共有4个蓝色高尔夫球。'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_Zero_shot_MtL3[\"choices\"][0][\"text\"].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1839b436-cf06-47d5-829c-cb24523e2f8b",
   "metadata": {},
   "source": [
    "能够发现，MtL提示过程能够非常好的帮助模型解决上述问题，这也说明MtL对大语言模型的推理能力提升效果非常显著，可以说是截至目前，我们尝试过的（解决推理问题方面）最有效的一类提示方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1420af-cd2d-4ef7-be52-ec34bf17d04f",
   "metadata": {},
   "source": [
    "&emsp;&emsp;至此，我们就完整介绍了目前最为有效的一系列用于提升模型推理能力的提示方法。下一小节我们将进一步围绕一项用于测试模型组合泛化能力的指令翻译任务进行建模，并在实战中进一步介绍嵌套提示流程设计方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef8e8a6-fcf1-4ae5-8d9e-ff68d12b5263",
   "metadata": {},
   "source": [
    "- 本节课程参考论文"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b13455-bcdf-4be7-b6a3-745b433f3be2",
   "metadata": {},
   "source": [
    "- Few-shot技术参考文献：[《Language Models are Few-Shot Learners》](https://arxiv.org/pdf/2005.14165.pdf)\n",
    "- Zero-shot-CoT参考文献：[《Large Language Models are Zero-Shot Reasoners》](https://arxiv.org/pdf/2205.11916v2.pdf)\n",
    "- Few-shot-CoT参考文献：[《Chain-of-Thought Prompting Elicits Reasoning in Large Language Models》](https://arxiv.org/pdf/2201.11903.pdf)\n",
    "- LtM方法参考文献：[《LEAST-TO-MOST PROMPTING ENABLES COMPLEX REASONING IN LARGE LANGUAGE MODELS》](https://arxiv.org/pdf/2205.10625.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
