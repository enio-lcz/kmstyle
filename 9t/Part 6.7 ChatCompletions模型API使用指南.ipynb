{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78d9fef0-2694-4d5e-9576-372c1ed7b365",
   "metadata": {},
   "source": [
    "# <center>OpenAI在线大模型调用及微调方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ef01be-7423-4e21-8ed4-f0c9cd382c23",
   "metadata": {},
   "source": [
    "## <center>Ch.7 ChatCompletions模型API使用指南"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bcb919-df0b-4d6d-8933-b5c8ced60408",
   "metadata": {},
   "source": [
    "### 1.Chat Completions模型概述"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28e76a1-3624-4494-b1c3-0b9ee8fff65b",
   "metadata": {},
   "source": [
    "#### 1.1 Chat Completions模型API基本情况介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb385c0-a363-4a6b-b3d3-d8d4e00f5224",
   "metadata": {},
   "source": [
    "&emsp;&emsp;尽管在上一小节末尾，我们尝试编写了一个可以预设风格的多轮对话函数，但实际上，相比Completions模型，Chat Completions模型（对话大模型）会更适合执行对话类任务。正如上一小节所说，Chat Completions模型是一类专门围绕对话类任务进行训练和微调的模型，截至目前，OpenAI发布的Chat Completions模型主要包括gpt-3.5和gpt-4两类模型，当然，这两个模型也是目前ChatGPT应用程序背后的对话大模型。其中，根据官网给出的说明，gpt-3.5模型是基于text-davinci-003微调的模型，而后者其实是属于gpt-3模型类，并且由code-davinci-002这一基座模型经过几轮微调后训练得到，对应的模型微调关系如下所示："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92207721-d785-447c-a46e-a1c298b7d211",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202306261634213.png\" alt=\"c604cd1f126567e50e4fc6ad2c884a3\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04d1dd9-e8ee-46bf-b6d7-187a55ea3fde",
   "metadata": {},
   "source": [
    "> 这里需要补充说明的是，由于OpenAI的模型训练方法并未公开，因此官网说明中的“improvement”是否是指微调其实并不确定。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46d0344-4fa1-4190-8914-2809221b5bdf",
   "metadata": {},
   "source": [
    "当然，gpt-4则是完全重新训练的最新一代的对话类大模型，在诸多国内外大模型评测榜单上，gpt-4也是目前（多语种）对话效果最好的一类对话类大模型。根据OpenAI7月6号的更新说明，目前gpt-4 API已针对此前支付过API费用的开发者全部开放，并且计划在7月内对全部用户开放gpt-4 API权限。鉴于此，课程中也将尽量使用gpt-4 API用于教学。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de97d8a-8aca-4f4c-9c44-77a719ada669",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/bc0440e6f31a8e331b5eecbc402c871.png\" alt=\"bc0440e6f31a8e331b5eecbc402c871\" style=\"zoom:20%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1e6f9a-1340-44df-be91-7947bd036c4a",
   "metadata": {},
   "source": [
    "截至目前，OpenAI发布的Chat Completions模型如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f306e56f-aedd-498d-87a4-6b044b51c861",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202306241505316.png\" alt=\"0ce263719c0b5d234ae3a6b8be1eef8\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f773cff8-bb11-4fb6-b023-a80710875249",
   "metadata": {},
   "source": [
    "不同于Completions模型，Chat Completions模型并未开放全部的API，对于大多数模型的长文本对话模型（即标注为32k的模型），也需要填写申请方可使用，填写地址：https://platform.openai.com/docs/guides/rate-limits/overview 。而具体当前账户能够调用哪些对话类大模型的API，可以在个人中心的Rate limits页面查看："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9273e3-1252-453e-9172-eddddb9f56b1",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202306261652051.png\" alt=\"67e8aef163e8a273b5a36115a89929d\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564eba28-893c-4e08-b206-3ed970d113df",
   "metadata": {},
   "source": [
    "#### 1.2 2023/06/13 OpenAI API updates     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be813bc-99b9-4bc1-a206-edc20d2adae8",
   "metadata": {},
   "source": [
    "&emsp;&emsp;即然介绍Chat Completions模型，不得不提的就是OpenAI在2023年6月13日发布的以Chat Completions模型为主的重磅更新。可以说，这是自gpt-4 API公布申请之后OpenAI发布的最大的模型更新，而这些围绕着Chat Completions模型进行的更新，也将是接下来课程内容学习的重点。这里我们简单总结0613更新内容如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c23ffdc-d10f-4950-b7f2-63b0e20ed306",
   "metadata": {},
   "source": [
    "- 发布了0613编号的模型，包括gpt-3.5-turbo-0613、gpt-4-turbo-0613等，相比此前的gpt-3.5和gpt-4模型，这些0613编号模型新增了函数API的调用功能，使得其可以调用一些外部工具（例如可以调用ChatGPT插件的API）来实现某些功能。毫无疑问这是一次极具革命性的创举，在此之前，大语言模型的函数API调用只能借助LangChain来完成；新增此功能之后，围绕OpenAI大语言模型的AI应用程序开发的门槛也将大幅降低；      \n",
    "- 发布了最大支持16k上下文的模型，例如gpt-3.5-turbo-16k、gpt-3.5-turbo-16k-0613等，在默认情况下gpt模型的最大上下文token限制为4k（4096个token），而16k版本的模型则将这个最大限制拓宽为16k个token（16384个token），这毫无疑问会大幅增加模型阅读长文本信息的能力和多轮对话能力；不过这里需要注意，没有标注16k的模型上下文仍然最大只支持4k；        \n",
    "- 大幅降低了部分模型API的调用，其中text-embedding-ada-002模型使用费用降低了75%，而gpt-3.5-turbo使用费用降低了25%，前者是目前最先进的Embedding模型，而后者则是目前用户调用次数最多的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2609f06-9186-4567-a012-c97c3ac82f2d",
   "metadata": {},
   "source": [
    "能够看出，对话类大语言模型既是目前使用最多的一类模型、同时也是OpenAI大力维护的一类模型。接下来，我们就从具体的对话类模型调用方法入手学习，并在本节课程的末尾为大家介绍目前工业界基于对话类大模型的应用实战案例。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ef32ea-5992-49cb-9d8e-db6c44ac3c8a",
   "metadata": {},
   "source": [
    "#### 1.3 2023/07/06 OpenAI API updates     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360be185-7050-4370-ab64-9f05dc897d11",
   "metadata": {},
   "source": [
    "&emsp;&emsp;P【penAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75185e39-9ec7-4017-a7e4-9a69ee8d9866",
   "metadata": {},
   "source": [
    "gpt-4 API全面可用，Chat模型微调即将上线"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f749668f-0d2f-4949-bfd1-832ab2b1ffd3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba50ed3-8849-4e19-b118-ecfd6339faed",
   "metadata": {},
   "source": [
    "- gpt-4团队API使用方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438942d7-9ab9-4a8d-83ab-1ebb810c1df4",
   "metadata": {},
   "source": [
    "&emsp;&emsp;若是对于此前通过提交申请获得的gpt-4 API，则需要通过团队API页面来查看gpt-4 API情况，具体方法如下，首先，我们能够在Rate limilts页面查看当前能够使用的gpt-4模型（若申请通过的话）："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f493e94-f346-4a6d-8d4c-8c77dc2f146c",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202307052112745.png\" alt=\"222508a4fa00351b2e5e96df56d454a\" style=\"zoom: 33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1acc77b-92b2-455a-a902-77ea1f41aa67",
   "metadata": {},
   "source": [
    "其次，由于gpt-4 API只针对组织（Organization）开放（注意，申请gpt-4 API时也是需要以组织身份申请），因此，若要使用gpt-4 API，则需要把当前账户切换成组织模型，点击个人头像即可切换："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727250cd-c033-46e6-a00e-b2a4c46ede1d",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202307052116563.png\" alt=\"cf091130d8d745b54f842c39386d5c5\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315c4aff-1c9e-4a72-a538-7de0a89c350b",
   "metadata": {},
   "source": [
    "然后点击API keys，并在页面下方点击选择组织，即可使用该API调用组织内可以用的模型，并计费到组织账户："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4fd905-0b62-4563-a0c0-d250c801429c",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202307052118681.png\" alt=\"5d0550ae6d9d02accfe15c7f0993b13\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13b0287-3070-4916-866b-28422afd36ca",
   "metadata": {},
   "source": [
    "这里需要注意，同一个账户下的同一个API key，是可以在个人模式和组织模式下随时切换的，如果切换成个人模式，相同的API key则会调用个人账户可以使用的模型，并在个人账户计费。而如果切换成组织模式，则可以调用组织下可以下调用的API，并且在组织账户内进行计费。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf947b2-2b8d-485f-9388-500d29f7985f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357c024f-d84b-491a-a73c-f343c309d72d",
   "metadata": {},
   "source": [
    "### 2.ChatCompletion.create API使用方法及参数解释"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63594da5-3dd2-4a05-b231-d6a6d387d2f0",
   "metadata": {},
   "source": [
    "#### 2.1 ChatCompletion.create函数使用简例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0302f8-af3c-46a5-bd17-7f4b451f5f75",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来，我们尝试调用OpenAI的Chat类模型，并详细解释模型API参数。和调用Completion模型需要使用Completion.create函数类似，若要调用Chat类大模型，则需要使用ChatCompletion.create函数。由于Chat模型本身是基于Completion模型的、专门用于处理对话类任务的模型，因此ChatCompletion.create的使用方法和Completion.create非常类似，整体函数使用流程和核心参数都非常类似，这里我们直接对Chat模型提问“什么是机器学习？”提问和获取结果流程如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ffdeddce-204d-4dcc-82c1-63f4f7407278",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "af0a695e-ac57-4563-8548-711331059b1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": \"请问，什么是机器学习？\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "316d0175-905f-4f2b-b9c3-8c551e0dfb3a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-7aMK1Zr3sFfDrvScu0rGRShzbjNsI at 0x2e70127e980> JSON: {\n",
       "  \"id\": \"chatcmpl-7aMK1Zr3sFfDrvScu0rGRShzbjNsI\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1688899969,\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"\\u673a\\u5668\\u5b66\\u4e60\\u662f\\u4e00\\u79cd\\u4eba\\u5de5\\u667a\\u80fd\\u9886\\u57df\\u7684\\u6280\\u672f\\uff0c\\u901a\\u8fc7\\u8ba9\\u8ba1\\u7b97\\u673a\\u7cfb\\u7edf\\u6839\\u636e\\u5927\\u91cf\\u6570\\u636e\\u81ea\\u52a8\\u5b66\\u4e60\\u548c\\u6539\\u8fdb\\uff0c\\u4ece\\u800c\\u5b9e\\u73b0\\u7279\\u5b9a\\u4efb\\u52a1\\u7684\\u80fd\\u529b\\u3002\\u7b80\\u800c\\u8a00\\u4e4b\\uff0c\\u673a\\u5668\\u5b66\\u4e60\\u662f\\u6307\\u8ba1\\u7b97\\u673a\\u7cfb\\u7edf\\u5229\\u7528\\u7edf\\u8ba1\\u5b66\\u548c\\u7b97\\u6cd5\\u6765\\u4f7f\\u81ea\\u8eab\\u83b7\\u5f97\\u4ece\\u6837\\u672c\\u6570\\u636e\\u4e2d\\u5b66\\u4e60\\u7684\\u80fd\\u529b\\uff0c\\u5e76\\u5229\\u7528\\u5b66\\u4e60\\u5230\\u7684\\u77e5\\u8bc6\\u8fdb\\u884c\\u9884\\u6d4b\\u3001\\u51b3\\u7b56\\u6216\\u6267\\u884c\\u7279\\u5b9a\\u4efb\\u52a1\\u3002\\u5b83\\u6d89\\u53ca\\u8bb8\\u591a\\u7b97\\u6cd5\\u548c\\u6280\\u672f\\uff0c\\u4f8b\\u5982\\u76d1\\u7763\\u5b66\\u4e60\\u3001\\u65e0\\u76d1\\u7763\\u5b66\\u4e60\\u3001\\u5f3a\\u5316\\u5b66\\u4e60\\u7b49\\u3002\\u673a\\u5668\\u5b66\\u4e60\\u5728\\u5404\\u79cd\\u9886\\u57df\\u4e2d\\u5f97\\u5230\\u4e86\\u5e7f\\u6cdb\\u5e94\\u7528\\uff0c\\u5982\\u81ea\\u7136\\u8bed\\u8a00\\u5904\\u7406\\u3001\\u56fe\\u50cf\\u8bc6\\u522b\\u3001\\u63a8\\u8350\\u7cfb\\u7edf\\u7b49\\u3002\"\n",
       "      },\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 20,\n",
       "    \"completion_tokens\": 204,\n",
       "    \"total_tokens\": 224\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45eee094-f9d2-476b-9a1a-7450fab48a7e",
   "metadata": {},
   "source": [
    "能够看出，和Completion.create非常明显的一个区别在于，ChatCompletion.create函数的调用不再需要prompt参数，而是换成了messages参数，并且，不同于prompt参数对象是以简单的字符串形式呈现，messages参数则是一个基本构成元素为字典的列表，其内每个字典都代表一条独立的消息，每个字典都包含两个键值（Key-value）对，其中第一个Key都是字符串role（角色）表示某条消息的作者，第二个key为content（内容）表示消息具体内容。可以说messages参数是ChatCompletion.create函数最重要的参数之一，能够看出比简单的prompt参数格式要更加复杂。更多关于message的参数设置方法稍后介绍，总的来看，这里的messages就可以简单理解为输入给模型的信息，而模型接收到message之后也会输出对应的回答信息，当然也是以message形式呈现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c9c2caa-0736-4173-ade8-c8fae7f18e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "openai.openai_object.OpenAIObject"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 返回对象类型和Completion.create函数返回对象类型一致\n",
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab6dd2f6-ad60-493e-8159-d8365dd2787b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<OpenAIObject at 0x2017fa89ea0> JSON: {\n",
       "   \"finish_reason\": \"stop\",\n",
       "   \"index\": 0,\n",
       "   \"message\": {\n",
       "     \"content\": \"\\u673a\\u5668\\u5b66\\u4e60\\u662f\\u4e00\\u79cd\\u4eba\\u5de5\\u667a\\u80fd\\u7684\\u5206\\u652f\\u9886\\u57df\\uff0c\\u5b83\\u7814\\u7a76\\u5982\\u4f55\\u4f7f\\u8ba1\\u7b97\\u673a\\u7cfb\\u7edf\\u6839\\u636e\\u6570\\u636e\\u548c\\u7ecf\\u9a8c\\u81ea\\u52a8\\u6539\\u5584\\u548c\\u9002\\u5e94\\uff0c\\u800c\\u65e0\\u9700\\u660e\\u786e\\u5730\\u8fdb\\u884c\\u7f16\\u7a0b\\u3002\\u673a\\u5668\\u5b66\\u4e60\\u7684\\u76ee\\u6807\\u662f\\u901a\\u8fc7\\u6784\\u5efa\\u6a21\\u578b\\u548c\\u7b97\\u6cd5\\uff0c\\u8ba9\\u8ba1\\u7b97\\u673a\\u80fd\\u591f\\u4ece\\u5927\\u91cf\\u6570\\u636e\\u4e2d\\u5b66\\u4e60\\uff0c\\u5e76\\u4e14\\u53ef\\u4ee5\\u4ece\\u4e2d\\u53d1\\u73b0\\u6a21\\u5f0f\\u3001\\u505a\\u51fa\\u9884\\u6d4b\\u548c\\u505a\\u51fa\\u76f8\\u5e94\\u7684\\u51b3\\u7b56\\u3002\\u673a\\u5668\\u5b66\\u4e60\\u6280\\u672f\\u88ab\\u5e7f\\u6cdb\\u5e94\\u7528\\u4e8e\\u56fe\\u50cf\\u548c\\u8bed\\u97f3\\u8bc6\\u522b\\u3001\\u81ea\\u7136\\u8bed\\u8a00\\u5904\\u7406\\u3001\\u63a8\\u8350\\u7cfb\\u7edf\\u3001\\u6570\\u636e\\u6316\\u6398\\u7b49\\u9886\\u57df\\uff0c\\u4ee5\\u89e3\\u51b3\\u590d\\u6742\\u95ee\\u9898\\u548c\\u6539\\u8fdb\\u4eba\\u5de5\\u667a\\u80fd\\u7cfb\\u7edf\\u7684\\u6027\\u80fd\\u3002\",\n",
       "     \"role\": \"assistant\"\n",
       "   }\n",
       " }]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 可以通过索引的方式索引出文本部分内容\n",
    "response[\"choices\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d75122d-ff56-4de6-9c64-ae7230119f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<OpenAIObject at 0x2017fa89ea0> JSON: {\n",
       "   \"finish_reason\": \"stop\",\n",
       "   \"index\": 0,\n",
       "   \"message\": {\n",
       "     \"content\": \"\\u673a\\u5668\\u5b66\\u4e60\\u662f\\u4e00\\u79cd\\u4eba\\u5de5\\u667a\\u80fd\\u7684\\u5206\\u652f\\u9886\\u57df\\uff0c\\u5b83\\u7814\\u7a76\\u5982\\u4f55\\u4f7f\\u8ba1\\u7b97\\u673a\\u7cfb\\u7edf\\u6839\\u636e\\u6570\\u636e\\u548c\\u7ecf\\u9a8c\\u81ea\\u52a8\\u6539\\u5584\\u548c\\u9002\\u5e94\\uff0c\\u800c\\u65e0\\u9700\\u660e\\u786e\\u5730\\u8fdb\\u884c\\u7f16\\u7a0b\\u3002\\u673a\\u5668\\u5b66\\u4e60\\u7684\\u76ee\\u6807\\u662f\\u901a\\u8fc7\\u6784\\u5efa\\u6a21\\u578b\\u548c\\u7b97\\u6cd5\\uff0c\\u8ba9\\u8ba1\\u7b97\\u673a\\u80fd\\u591f\\u4ece\\u5927\\u91cf\\u6570\\u636e\\u4e2d\\u5b66\\u4e60\\uff0c\\u5e76\\u4e14\\u53ef\\u4ee5\\u4ece\\u4e2d\\u53d1\\u73b0\\u6a21\\u5f0f\\u3001\\u505a\\u51fa\\u9884\\u6d4b\\u548c\\u505a\\u51fa\\u76f8\\u5e94\\u7684\\u51b3\\u7b56\\u3002\\u673a\\u5668\\u5b66\\u4e60\\u6280\\u672f\\u88ab\\u5e7f\\u6cdb\\u5e94\\u7528\\u4e8e\\u56fe\\u50cf\\u548c\\u8bed\\u97f3\\u8bc6\\u522b\\u3001\\u81ea\\u7136\\u8bed\\u8a00\\u5904\\u7406\\u3001\\u63a8\\u8350\\u7cfb\\u7edf\\u3001\\u6570\\u636e\\u6316\\u6398\\u7b49\\u9886\\u57df\\uff0c\\u4ee5\\u89e3\\u51b3\\u590d\\u6742\\u95ee\\u9898\\u548c\\u6539\\u8fdb\\u4eba\\u5de5\\u667a\\u80fd\\u7cfb\\u7edf\\u7684\\u6027\\u80fd\\u3002\",\n",
       "     \"role\": \"assistant\"\n",
       "   }\n",
       " }]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 也可以通过属性调用的方式查看choices\n",
    "response.choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2cea2115-f26c-4d98-aaf7-2cd828e6cc71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject at 0x2017fa89ea0> JSON: {\n",
       "  \"finish_reason\": \"stop\",\n",
       "  \"index\": 0,\n",
       "  \"message\": {\n",
       "    \"content\": \"\\u673a\\u5668\\u5b66\\u4e60\\u662f\\u4e00\\u79cd\\u4eba\\u5de5\\u667a\\u80fd\\u7684\\u5206\\u652f\\u9886\\u57df\\uff0c\\u5b83\\u7814\\u7a76\\u5982\\u4f55\\u4f7f\\u8ba1\\u7b97\\u673a\\u7cfb\\u7edf\\u6839\\u636e\\u6570\\u636e\\u548c\\u7ecf\\u9a8c\\u81ea\\u52a8\\u6539\\u5584\\u548c\\u9002\\u5e94\\uff0c\\u800c\\u65e0\\u9700\\u660e\\u786e\\u5730\\u8fdb\\u884c\\u7f16\\u7a0b\\u3002\\u673a\\u5668\\u5b66\\u4e60\\u7684\\u76ee\\u6807\\u662f\\u901a\\u8fc7\\u6784\\u5efa\\u6a21\\u578b\\u548c\\u7b97\\u6cd5\\uff0c\\u8ba9\\u8ba1\\u7b97\\u673a\\u80fd\\u591f\\u4ece\\u5927\\u91cf\\u6570\\u636e\\u4e2d\\u5b66\\u4e60\\uff0c\\u5e76\\u4e14\\u53ef\\u4ee5\\u4ece\\u4e2d\\u53d1\\u73b0\\u6a21\\u5f0f\\u3001\\u505a\\u51fa\\u9884\\u6d4b\\u548c\\u505a\\u51fa\\u76f8\\u5e94\\u7684\\u51b3\\u7b56\\u3002\\u673a\\u5668\\u5b66\\u4e60\\u6280\\u672f\\u88ab\\u5e7f\\u6cdb\\u5e94\\u7528\\u4e8e\\u56fe\\u50cf\\u548c\\u8bed\\u97f3\\u8bc6\\u522b\\u3001\\u81ea\\u7136\\u8bed\\u8a00\\u5904\\u7406\\u3001\\u63a8\\u8350\\u7cfb\\u7edf\\u3001\\u6570\\u636e\\u6316\\u6398\\u7b49\\u9886\\u57df\\uff0c\\u4ee5\\u89e3\\u51b3\\u590d\\u6742\\u95ee\\u9898\\u548c\\u6539\\u8fdb\\u4eba\\u5de5\\u667a\\u80fd\\u7cfb\\u7edf\\u7684\\u6027\\u80fd\\u3002\",\n",
       "    \"role\": \"assistant\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看第一个返回结果\n",
    "response.choices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29e9161d-e3ed-451f-b908-c5b271631e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'机器学习是一种人工智能的分支领域，它研究如何使计算机系统根据数据和经验自动改善和适应，而无需明确地进行编程。机器学习的目标是通过构建模型和算法，让计算机能够从大量数据中学习，并且可以从中发现模式、做出预测和做出相应的决策。机器学习技术被广泛应用于图像和语音识别、自然语言处理、推荐系统、数据挖掘等领域，以解决复杂问题和改进人工智能系统的性能。'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看第一个返回结果的message\n",
    "response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f0bfc2-1d8d-4b71-be14-a0b198ac132a",
   "metadata": {},
   "source": [
    "可以说，在获取对话结果的过程中，除了ChatCompletion.create返回结果最终是保存在message属性中（Completion.create返回结果是保存在text属性中），其他方面ChatCompletion.create的返回结果和Completion.create返回结果完全一致。而文本补全模型需要输入“prompt”，输出结果是“text”；而对话模型需要输入“message”，返回也是“message”，可以说这种文本交互形式确实非常符合人类在进行聊天时的问答习惯。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a731f94-cc10-46f2-a052-e910a8a9ff67",
   "metadata": {},
   "source": [
    "&emsp;&emsp;最后需要注意的是，和Completion模型一样，Chat模型我们同样也可以在返回结果的usage中查看本次对话所占用的token数量，其中\"prompt_tokens\"表示提示词占用token数量，\"completion_tokens\"则表示返回结果所占用token数量，而\"total_tokens\"则是二者相加，代表本次对话总共占用token数量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1b9d116d-7a06-4c77-81cd-0186d0650a19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject at 0x2e70131fb50> JSON: {\n",
       "  \"prompt_tokens\": 20,\n",
       "  \"completion_tokens\": 464,\n",
       "  \"total_tokens\": 484\n",
       "}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "821d19ba-1989-45ee-93f8-6b9daf425f7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "484"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage[\"total_tokens\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62217ac1-a209-4998-9c4c-a6795e92462f",
   "metadata": {},
   "source": [
    "#### 2.2 ChatCompletion.create函数参数解释"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57902b6c-66c5-43a0-8b31-6608eaf6c6b6",
   "metadata": {},
   "source": [
    "&emsp;&emsp;而关于ChatCompletion.create函数的详细参数解释，可以在官网相关页面查阅：https://platform.openai.com/docs/api-reference/chat/create 。能够发现，和Completion.create函数相比，ChatCompletion.create函数的参数结构发生了以下变化：     \n",
    "- 用messages参数代替了prompt参数，使之更适合能够执行对话类任务；\n",
    "- 新增functions和function_call参数，使之能够在函数内部调用其他工具的API，该功能为0613新增功能；\n",
    "- 其他核心参数完全一致，例如temperature、top_p、max_tokens、n、presence_penalty等参数的解释和使用方法都完全一致，且这些参数具体的调整策略也完全一致，例如如果希望具备更有创造力的对话，则可以调高temperature且降低presence_penalty，而如果希望获得更加严谨的问答结果，则可以降低temperature并且提高presence_penalty取值；\n",
    "- 剔除了best_of参数，即Chat模型不再支持从多个答案中选择一个最好的答案这一功能；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2aa44d8-4aa0-4077-8790-b3f20e1a16fc",
   "metadata": {},
   "source": [
    "需要注意的是，两个函数相同的参数在Ch.2的Completion.create函数参数介绍中均有详细介绍，此处不再赘述。接下来我们围绕ChatCompletion.create不同的三个参数，即messages参数、functions和function_call参数进行详细解释。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a42ee26-bbbf-429e-ad51-26d1abf1cdc2",
   "metadata": {},
   "source": [
    "### 3.messages参数详解"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f425ed-8d6f-4057-9b3a-6c8ab0b50542",
   "metadata": {},
   "source": [
    "#### 3.1 message参数结构及功能解释"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0649a6-ac84-467e-a727-d09815e4a611",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来我们来看ChatCompletion.create函数非常重要的参数——messages使用方法。总的来说，messages是一种用于描述ChatCompletion模型和用户之间通信信息的高级抽象，从表示形式上来说，一个messages是一个列表，包含多个字典，而每个字典都是一条消息，其中，一条消息由包含两个键值对（即每个字典都包含两个键值对），第一个键值对用于表示消息发送者，其中第一个Key为字符串'role'，Value为参与对话的角色名称，或者可以理解为本条消息的作者或消息发送人名称，第二个键值对表示具体消息内容，Key为字符串'content'，Value为具体的消息内容，用字符串表示。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede15182-fe0f-431b-a520-cdbc102aa8c5",
   "metadata": {},
   "source": [
    "> 实际上，根据官网的说明，更严谨的说法是role是content的作者，而content的作者并不一定是content的发送方，发送方的角色更多是用于消息传递而非消息创作。但在实际使用过程中我们发现，ChatCompletion模型的role几乎可以完全看成是消息发送方，这么理解也会更加便于我们对消息结构的掌握和解读。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4138134c-3e8f-4140-ae25-9f8c69a9218a",
   "metadata": {},
   "source": [
    "例如上述示例中的messages就总共包含一条信息，即一个一个名为user的角色发送了一条名为'请问什么是机器学习？'的消息："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bbee2065-f3f5-4018-a55c-25197be4a2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[\n",
    "    {\"role\": \"user\", \"content\": \"请问什么是机器学习？\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc459ff-da43-477a-8544-525871194bf5",
   "metadata": {},
   "source": [
    "而同时，返回的message结果也是一个“字典”，并且也包含了信息的发送方和具体信息内容，不难看出，此时返回的message发送方是一个名为'assistant'的角色，而具体内容则是一段关于什么是机器学习的描述："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fdd23a81-5b95-4fae-9c41-2c71935a2b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject at 0x2017fa89d10> JSON: {\n",
       "  \"content\": \"\\u673a\\u5668\\u5b66\\u4e60\\u662f\\u4e00\\u79cd\\u4eba\\u5de5\\u667a\\u80fd\\u7684\\u5206\\u652f\\u9886\\u57df\\uff0c\\u5b83\\u7814\\u7a76\\u5982\\u4f55\\u4f7f\\u8ba1\\u7b97\\u673a\\u7cfb\\u7edf\\u6839\\u636e\\u6570\\u636e\\u548c\\u7ecf\\u9a8c\\u81ea\\u52a8\\u6539\\u5584\\u548c\\u9002\\u5e94\\uff0c\\u800c\\u65e0\\u9700\\u660e\\u786e\\u5730\\u8fdb\\u884c\\u7f16\\u7a0b\\u3002\\u673a\\u5668\\u5b66\\u4e60\\u7684\\u76ee\\u6807\\u662f\\u901a\\u8fc7\\u6784\\u5efa\\u6a21\\u578b\\u548c\\u7b97\\u6cd5\\uff0c\\u8ba9\\u8ba1\\u7b97\\u673a\\u80fd\\u591f\\u4ece\\u5927\\u91cf\\u6570\\u636e\\u4e2d\\u5b66\\u4e60\\uff0c\\u5e76\\u4e14\\u53ef\\u4ee5\\u4ece\\u4e2d\\u53d1\\u73b0\\u6a21\\u5f0f\\u3001\\u505a\\u51fa\\u9884\\u6d4b\\u548c\\u505a\\u51fa\\u76f8\\u5e94\\u7684\\u51b3\\u7b56\\u3002\\u673a\\u5668\\u5b66\\u4e60\\u6280\\u672f\\u88ab\\u5e7f\\u6cdb\\u5e94\\u7528\\u4e8e\\u56fe\\u50cf\\u548c\\u8bed\\u97f3\\u8bc6\\u522b\\u3001\\u81ea\\u7136\\u8bed\\u8a00\\u5904\\u7406\\u3001\\u63a8\\u8350\\u7cfb\\u7edf\\u3001\\u6570\\u636e\\u6316\\u6398\\u7b49\\u9886\\u57df\\uff0c\\u4ee5\\u89e3\\u51b3\\u590d\\u6742\\u95ee\\u9898\\u548c\\u6539\\u8fdb\\u4eba\\u5de5\\u667a\\u80fd\\u7cfb\\u7edf\\u7684\\u6027\\u80fd\\u3002\",\n",
       "  \"role\": \"assistant\"\n",
       "}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e8d4eb1d-c25d-46f4-b8e0-e30ca3fc2b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'机器学习是一种人工智能的分支领域，它研究如何使计算机系统根据数据和经验自动改善和适应，而无需明确地进行编程。机器学习的目标是通过构建模型和算法，让计算机能够从大量数据中学习，并且可以从中发现模式、做出预测和做出相应的决策。机器学习技术被广泛应用于图像和语音识别、自然语言处理、推荐系统、数据挖掘等领域，以解决复杂问题和改进人工智能系统的性能。'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448e64a7-b7db-4414-a228-deadd530106a",
   "metadata": {},
   "source": [
    "由此不难看出，对话Chat模型的每个对话任务都是通过输入和输出message来完成的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a803e7f-10af-41a8-9cf9-4ed8f6ed9fb4",
   "metadata": {},
   "source": [
    "#### 3.2 messages中的角色划分"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2088e4ca-7498-41ce-8af8-d5075c083e14",
   "metadata": {},
   "source": [
    "- user role和assistant role"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1e18d6-54ad-459f-8d8a-23ef9894eaa6",
   "metadata": {},
   "source": [
    "&emsp;&emsp;那么接下来的问题就是，在实际调用Chat模型进行对话时，messages中的role应该如何设置呢？从上述极简的对话示例中能够看出，一个最简单的对话就是我们扮演user（用户）这个角色（'role':'user'），然后在content中输入我们的问题并等待模型回答。而模型在实际回答过程中，也会扮演一个名为assistant（助手）这个角色（'role':'assistant'）进行回答，这里的user和assistant是具有明确含义的字符串，即如果一条信息的role是user，则表明这是用户向模型发送的聊天信息，相当于是Completion模型中的prompt，而如果一条信息的role是assistant，则表示这是当前模型围绕某条用户信息做出的回应，相当于是相当于是Completion模型中的text。需要注意的是，在messages参数中，我们是不能给自己或者模型自定义其他名称的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad5a871-42cc-4c44-9372-0d15ca855815",
   "metadata": {},
   "source": [
    "&emsp;&emsp;很明显，基于这样的一个定义的规则，最简单的Chat模型的调用方法就是在messages参数中设置一条role为user的参数，在content中输入聊天的内容，而模型则会根据这条用户输入给模型的消息进行回答，类似于此前我们向模型提问“请问什么是机器学习？”这种提问方式:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6bd02e43-73d6-4818-8382-2e3e0b00d548",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": \"请问什么是机器学习？\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "94e2ebf1-02e6-41ac-bd73-b85a017662fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'机器学习是一种人工智能的分支，通过使用数学和统计方法来自动分析和理解数据，并使计算机能够自主学习和改进性能。它是通过从数据中学习模式和规律，而不是通过明确编程来实现任务的一种方法。机器学习可以帮助计算机系统通过从大量数据中提取规律来预测结果、进行分类、聚类、识别图像和语音、自动驾驶等。'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66843308-f32e-4000-9c64-4d73e45c1886",
   "metadata": {},
   "source": [
    "不过需要注意的是，尽管一个messages可以包含多条信息，但模型只会对于最后一条用户信息进行回答，例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e7011a2-d64c-482d-9830-7c02e4513d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": \"请问什么是机器学习？\"},\n",
    "    {\"role\": \"user\", \"content\": \"请问什么是决策树算法？\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ec603957-131c-4b41-a28e-ea2c49c39306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'决策树算法是一种用于分类和回归的机器学习算法，它基于树形结构来进行决策。决策树可以看作是一个由节点和有向边组成的树，每个节点表示一个特征属性，每条边表示一个特征属性取值或决策的结果。决策树的根节点表示最重要的特征，而叶子节点表示分类或回归结果。\\n\\n决策树算法的特点包括易于理解和解释、能够处理非线性关系、不需要对数据进行特征预处理、可以处理多输出问题等。算法的核心思想是通过反复分割数据集，使得每个子集中的样本都属于同一类别（或拥有相似的回归结果）。分割的决策依据是选择最佳的划分特征，通常使用各种不纯度指标（例如基尼系数或熵）来衡量每个特征的纯度。\\n\\n决策树算法包括很多变种和优化方法，如CART（Classification and Regression Trees）、ID3、C4.5、随机森林等。决策树算法在实际应用中广泛使用，可以用于分类问题（如垃圾邮件分类、医学诊断等）和回归问题（如房价预测、股票趋势预测等）。'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fac8d37-c3a5-424b-9dda-694234c030a3",
   "metadata": {},
   "source": [
    "也就是说，assistant消息和role消息是一一对应的，而且在一般情况下，assistant消息只会围绕messages参数中的最后一个role信息进行回答。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a1ff27-08df-4657-a3e1-427f5090ce0d",
   "metadata": {},
   "source": [
    "- system role用于身份设定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f46528-bed6-4294-9ede-6ed7b6bfcd1b",
   "metadata": {},
   "source": [
    "&emsp;&emsp;不过，值得一提的是，user和assistant的这种提问方式尽管足够清晰，但往往形式上不够丰富，例如在实践中人们发现，给聊天机器人进行一个身份设置，其实是非常有效的引导模型创作我们想要的结果的方法，例如如果我们希望获得一个关于“什么是机器学习？”更加严谨且丰富的答案，我们可以以“假设你是一名资深的计算机系大学教授”为模型进行身份设置，例如我们可以以如下方式向模型进行提问："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "76b17af3-95a6-43c9-a0c5-baa727c0f2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": \"假设你是一名资深的计算机系大学教授，请帮我回答，什么是机器学习？\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b32b220d-36ed-4e84-8d5b-ba8a24bcf605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'机器学习是一门研究如何使计算机系统通过大量数据和经验自动学习和改进性能的领域。它利用算法和数学模型，使计算机能够自动发现数据中的模式和规律，并利用这些模式来进行预测、分类、优化等任务。\\n\\n在机器学习中，计算机系统并不需要明确地编写具体规则或指令，而是通过从数据中学习，从而提高自己的性能和准确性。它依赖于大数据、统计学和计算机科学等领域的技术，包括数据预处理、特征提取、模型选择和评估等步骤。\\n\\n机器学习广泛应用于各个领域，如自然语言处理、计算机视觉、推荐系统、金融预测等。它的目标是从数据中发现隐藏的模式和知识，以提供高效的决策支持和智能化的解决方案。'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d916d481-a353-453d-a0aa-5d50c23bd073",
   "metadata": {},
   "source": [
    "不难看出，此时模型的回答就变得更加详细和严谨，更像一名“大学教授”的语气风格，也同时说明我们对模型进行的身份设定是切实有效的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d881f659-f696-4ff9-8d04-2405a0387a1e",
   "metadata": {},
   "source": [
    "&emsp;&emsp;而在ChatCompletion.create函数中，还有另外一种非常便捷的对模型进行身份设置的方法，即使用system role，即我们可以使用如下方式为模型进行“大学教授”身份设定："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "44bc4b9e-b2e0-45c5-8311-338a8ab63cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"你是一名资深的计算机系大学教授\"},\n",
    "    {\"role\": \"user\", \"content\": \"请问什么是机器学习？\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4714eb61-7e4d-471f-a54a-86a403f3df18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'机器学习是一种人工智能的分支领域，它致力于研究和开发能够从数据中自动学习和改进的算法和模型。机器学习使计算机可以通过分析大量数据并自动发现数据中隐藏的模式和规律，从而使计算机能够作出预测或做出决策。\\n\\n机器学习的主要任务包括分类、回归、聚类和推荐等。分类任务是将数据分为不同的类别，回归任务是预测数据的数值，聚类任务是将相似的数据分组，推荐任务是根据用户的个人偏好为其推荐物品。\\n\\n机器学习算法可以分为监督学习、无监督学习和强化学习。监督学习是通过已标记的训练数据进行学习，无监督学习是利用未标记的数据进行学习，而强化学习则是通过与环境的交互来进行学习。\\n\\n机器学习在许多领域中都有广泛的应用，例如图像识别、语音识别、自然语言处理、金融预测和医学诊断等。通过机器学习，计算机可以从大量的数据中学习，并提供更准确、高效的解决方案。'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed80e57-ff93-4ddf-94b8-68f51f8b77a0",
   "metadata": {},
   "source": [
    "&emsp;&emsp;能够看出，这里我们在原有消息之前，新增一条消息{\"role\": \"system\", \"content\": \"你是一名资深的计算机系大学教授\"}，也能起到设定模型身份的作用。而这条消息的实际含义是，以system的身份发送一条消息，消息内容为“你是一名资深的计算机系大学教授”。这里的system就是messages参数的role可以选取的第三个字符串，意为该消息为一条系统消息。相比用户消息，系统消息有以下几点需要注意，其一是系统消息的实际作用是给整个对话系统进行背景设置，不同的背景设置会极大程度影响后续对话过程中模型的输出结果，例如如果系统设置为“你是一位资深医学专家”，那么接下来系统在进行回答医学领域相关问题时则会引用大量医学术语，而如果系统设置为“你是一位资深喜剧演员”，那么接下来系统进行的回答则会更加风趣幽默："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "50527cc1-f1e6-4a50-80a3-eb1d1d33a852",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"你是一名资深的喜剧演员\"},\n",
    "    {\"role\": \"user\", \"content\": \"请问什么是机器学习？\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "243aa734-1bce-4181-b2fa-2498c383d13b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'哈哈，这是一个有趣的问题！机器学习是一种人工智能的分支，它通过让计算机系统自动学习和改进，而无需明确的编程指令。简单来说，机器学习是让机器具备从数据中学习和预测的能力。就像我在喜剧表演中学习和改进我的技巧一样，机器学习通过分析大量的数据，找到模式和规律，从而使机器能够做出智能的决策和预测。不过相比我，机器学习更加准确和高效！话不多说，让我们继续我的喜剧表演吧！'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcab1645-bbd7-457f-b159-123b43eb24e7",
   "metadata": {},
   "source": [
    "&emsp;&emsp;而第二方面需要注意的则是，当messages中只包含一条system消息时，系统会围绕system进行回答，只不过此时系统的assistant的应答消息则更像是一个completion的过程，即围绕system的prompt进行进一步的文本补全："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3a6befe8-d5e8-4554-9479-969a1eb8a5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"你是一名资深的喜剧演员\"},\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "94242375-c59c-40cc-8263-78a2897c6289",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject at 0x2017fa96590> JSON: {\n",
       "  \"content\": \"\\u6211\\u4f1a\\u7ed9\\u89c2\\u4f17\\u5e26\\u6765\\u6b22\\u4e50\\u548c\\u5feb\\u4e50\\u7684\\u7b11\\u58f0\\uff01\\u6211\\u64c5\\u957f\\u5851\\u9020\\u4e30\\u5bcc\\u591a\\u6837\\u7684\\u89d2\\u8272\\uff0c\\u8fd0\\u7528\\u5938\\u5f20\\u7684\\u8868\\u6f14\\u6280\\u5de7\\u548c\\u5e7d\\u9ed8\\u7684\\u53f0\\u8bcd\\uff0c\\u8ba9\\u89c2\\u4f17\\u6367\\u8179\\u5927\\u7b11\\u3002\\u6211\\u559c\\u6b22\\u6311\\u6218\\u81ea\\u5df1\\uff0c\\u5c1d\\u8bd5\\u4e0d\\u540c\\u7684\\u559c\\u5267\\u98ce\\u683c\\uff0c\\u4f8b\\u5982\\u60c5\\u666f\\u559c\\u5267\\u3001\\u559c\\u5267\\u7535\\u5f71\\u3001Stand-up\\u559c\\u5267\\u7b49\\u7b49\\u3002\\u901a\\u8fc7\\u4ee4\\u4eba\\u96be\\u5fd8\\u7684\\u8868\\u6f14\\uff0c\\u6211\\u5e0c\\u671b\\u80fd\\u591f\\u7559\\u4e0b\\u6df1\\u523b\\u7684\\u5370\\u8c61\\uff0c\\u5e76\\u8ba9\\u89c2\\u4f17\\u5fd8\\u8bb0\\u751f\\u6d3b\\u4e2d\\u7684\\u70e6\\u607c\\uff0c\\u4eab\\u53d7\\u4e00\\u6bb5\\u6b22\\u4e50\\u7684\\u65f6\\u5149\\uff01\",\n",
       "  \"role\": \"assistant\"\n",
       "}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6f088bea-b7df-4432-b13c-83d284e6478d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'我会给观众带来欢乐和快乐的笑声！我擅长塑造丰富多样的角色，运用夸张的表演技巧和幽默的台词，让观众捧腹大笑。我喜欢挑战自己，尝试不同的喜剧风格，例如情景喜剧、喜剧电影、Stand-up喜剧等等。通过令人难忘的表演，我希望能够留下深刻的印象，并让观众忘记生活中的烦恼，享受一段欢乐的时光！'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2f142fce-4138-4bb9-99b8-9214ff485674",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"你好，请问\"},\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f405e79d-16ca-4096-8e1b-cbc394f6ad4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'有什么可以帮助您的吗？'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f5ced4-8faf-40eb-9479-d825a7a2f2f4",
   "metadata": {},
   "source": [
    "当然，借助completion过程也是可以进行提问的，例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "31653e9f-9a5b-4302-b400-744acc1ba432",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"请问什么是机器学习？\"},\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5f82cfef-b63f-4d4a-be39-b01cc67aacb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'机器学习是一种人工智能的分支，它通过使用计算机算法和模型，让机器自动从数据中学习，并从中提取规律和模式，以做出预测和决策。它的主要目标是使机器能够从经验中学习，提高预测能力和自动化任务。机器学习在许多领域都有广泛应用，包括自然语言处理、图像识别、数据挖掘和智能推荐系统等。'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc28a439-aa93-4f70-b751-0790570c5398",
   "metadata": {},
   "source": [
    "不过这么做意义并不大，还是建议以user角色进行提问。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8887eb-5553-4060-bf45-25833e6e5f9c",
   "metadata": {},
   "source": [
    "&emsp;&emsp;第三方面需要注意的是，如果我们需要根据system系统信息对系统进行设置，然后再提问，那么先system消息再user消息的顺序就变得非常重要，例如还是上面的例子，还是希望以喜剧演员的身份介绍机器学习，但我们调换了system消息和user消息的顺序，那么会发现，system消息的作用就会失效："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c7225ccc-36ff-442d-870e-c03b0938eaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": \"请问什么是机器学习？\"},\n",
    "    {\"role\": \"system\", \"content\": \"你是一名资深的喜剧演员\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b905df09-227b-4147-869b-d0cd2f42e5a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'机器学习是一门人工智能领域的研究，旨在让计算机系统通过学习和改进经验，不需要明确的程序指导下，自动完成特定任务。它利用统计学和算法来使计算机能够从数据中学习并进行预测和决策。机器学习可以应用于各种领域，如图像识别、语音识别、自然语言处理、推荐系统等。通过训练模型，机器学习可以帮助计算机系统能够从数据中识别模式，做出预测，并根据反馈不断改进自己的表现。'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58177897-dea1-4975-81f6-96b39302c2dc",
   "metadata": {},
   "source": [
    "此时会发现，模型还是能解答“请问什么是机器学习？”这个问题，但却没有正确接受“你是一名资深喜剧演员”这个设定。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9436ac01-2a74-4cf5-9af0-f6946b25fc2f",
   "metadata": {},
   "source": [
    "&emsp;&emsp;最后还有一点需要注意的是，根据OpenAI官网说明，截至目前，gpt-3.5系列模型仍然无法对system提供的系统消息保持长期关注，即在多轮对话中，模型极有可能逐渐忘记自己的身份设定。根据长期使用情况来看，gpt-4模型对system设置的长期关注要好于gpt-3.5系列模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ff0fa5-ef2d-4460-a5ff-460677eb6553",
   "metadata": {},
   "source": [
    "&emsp;&emsp;对于messages中可选的role来说，除了ueser、assistant、system之外，还有一个function role，用于表示某条消息为某函数的调用指令，function role是OpenAI 0613更新中提供的新的role选项，用于Chat模型调用外部定义函数或者工具API时使用。相关用法我们会在本小节的后半部分进行介绍。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e700ef11-0c46-4b39-b826-d47c48987a33",
   "metadata": {},
   "source": [
    "### 4.messages参数应用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9141a4-961d-4c26-9492-414116918cba",
   "metadata": {},
   "source": [
    "&emsp;&emsp;对于ChatCompletion.create函数来说，通过灵活的messages参数，能够非常便捷高效的实现诸多类型的对话需求，例如基于提示词模板的提问、Few-shot提问、基于某背景知识的提问等，接下来我们进一步介绍不同场景下messages参数的设置方法，并在这个过程进一步介绍关于messages中name的设置方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fa1fd4-4755-4a51-9822-276e7d8274ae",
   "metadata": {},
   "source": [
    "&emsp;&emsp;由于我们接下来需要使用此前Ch.4中的推理问题作为示例，因此我们提前定义好四组问题的问题和答案："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8bd36349-79df-4d27-bd2e-6e8d797bb409",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = '罗杰有五个网球，他又买了两盒网球，每盒有3个网球，请问他现在总共有多少个网球？'\n",
    "A1 = '现在罗杰总共有11个网球。'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e2fe0e5f-2fc1-4cbe-bd24-cdc59ed15aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2 = '食堂总共有23个苹果，如果他们用掉20个苹果，然后又买了6个苹果，请问现在食堂总共有多少个苹果？'\n",
    "A2 = '现在食堂总共有9个苹果。'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4072d318-84bd-47ff-ac6e-fdfc63701303",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3 = '杂耍者可以杂耍16个球。其中一半的球是高尔夫球，其中一半的高尔夫球是蓝色的。请问总共有多少个蓝色高尔夫球？'\n",
    "A3 = '现在总共有4个蓝色高尔夫球。'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9ce4bc4a-239a-432f-ba26-a554c32e79d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4 = '艾米需要4分钟才能爬到滑梯顶部，她花了1分钟才滑下来，水滑梯将在15分钟后关闭，请问在关闭之前她能滑多少次？'\n",
    "A4 = '关闭之前艾米能滑3次。'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a6e1ff-4efc-40ce-ad66-a20922fbe30e",
   "metadata": {},
   "source": [
    "> 这里需要注意的是，gpt-3.5在解决推理问题上同样展示出了涌现能力——即gpt-3.5是基于对话语料进行的微调，但却展示出了比text-davinci-003更强大的推理能力，此前的四个推理问题对于gpt-3.5来说，除了最后一个问题不一定能得出正确答案外，其他问题均能在不进行额外提示的情况下进行很好的回答。而经过测试，gpt-4模型能够非常好的回答第四个推理问题。但需要注意的是，这并不代表此前的CoT和LtM技术就不再重要，面对超出模型原生能力的更加复杂的推理问题（如SCAN数据集的命令解释问题），仍然还是需要使用这些提示工程技术。当然，本节的重点是介绍messages参数设置技巧，更多的关于Chat模型的实战应用详见下一小节。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7759e905-a110-414b-a233-0fd00c11a93c",
   "metadata": {},
   "source": [
    "- 借助多轮user-assistant消息进行few-shot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4207e1b4-6644-494f-ab03-079ae4fb18b6",
   "metadata": {},
   "source": [
    "&emsp;&emsp;如果想在Chat模型中进行Few-shot，最好的办法就是在messages中设置多轮user-assistant消息，这里我们还是以Ch.4中的推理问题为例，尝试在Chat模型中进行推理并进行Few-shot，这里我们尝试以第一个问题的问题和答案作为提示示例，引导模型解答第二个问题，则可以按照如下方式设置messages："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f80ba481-c8d2-4197-be3b-425845980905",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": Q1},\n",
    "    {\"role\": \"assistant\", \"content\": A1},\n",
    "    {\"role\": \"user\", \"content\": Q2}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a6b7b218-3168-4236-be63-7ce868cbad50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'现在食堂总共有9个苹果。'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ed8cb9-9560-41a2-8851-b3e06c4244fe",
   "metadata": {},
   "source": [
    "而相比单独进行Q2的提问，经过Few-shot的提示回答的结果，会更加接近A1结果的表示格式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f58100f2-245a-4f27-8b09-e2c97d3fdd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": Q2}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "fb262740-fb72-40cd-acbf-c2eb1946307b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'食堂原本有23个苹果，用掉了20个，剩下3个苹果。\\n然后又买了6个苹果，所以现在食堂总共有3 + 6 = 9个苹果。'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b568eafe-dd03-4263-a880-a85ed2ba3281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'现在罗杰总共有11个网球。'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f0da75-a31e-4f83-9cb6-601f47cc7601",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在这个示例中，我们能够看出其实assistant消息也是可以自定义的，用于给模型提供回答的范本。并且由此可见messages参数具体呈现形式可以非常多样，不仅可以按照system-user的形式规定回答风格，而且还可以按照user-assistant-user-assistant...形式来进行Few-shot。这其实也是得益于messages高度灵活的参数构成形式——即由多条注明消息源的消息构成。messages中具体每条消息的内容以及消息序列构成形式上，有非常大的调整的空间。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760938cd-69d3-4d03-bb76-7d0b0081d576",
   "metadata": {},
   "source": [
    "- 借助system role进行Few-shot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157a3e47-edec-4e54-9583-102451dda9b7",
   "metadata": {},
   "source": [
    "&emsp;&emsp;当然，除了可以借助多轮user和assistant消息来进行Few-shot外，我们还可以把提示示例写进一条system信息中，作为当前问答的背景信息，例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f318cbb2-4aeb-44b2-bd7f-a72a3880e510",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": 'Q: ' + Q1 + 'A: ' + A1},\n",
    "    {\"role\": \"user\", \"content\": 'Q: ' + Q2 }\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ab3cc91d-a263-4546-9854-09af72026686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A: 现在食堂总共有9个苹果。'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e33c60bd-d23e-4d06-80ec-675787c18ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q: 罗杰有五个网球，他又买了两盒网球，每盒有3个网球，请问他现在总共有多少个网球？A: 现在罗杰总共有11个网球。'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Q: ' + Q1 + 'A: ' + A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5a335616-338a-4006-88b5-2d7423131861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q: 食堂总共有23个苹果，如果他们用掉20个苹果，然后又买了6个苹果，请问现在食堂总共有多少个苹果？'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Q: ' + Q2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c00605-5801-4bc9-be8a-73102847f461",
   "metadata": {},
   "source": [
    "唯一需要注意的是，此时需要在系统消息中通过Q和A的方式注明问题和回答的内容，并且在提问时添加字符串Q，便于模型理解后续的回答需要按照system中的A的方式进行回答。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b98797b-2a91-4a83-80a8-8145c66b1805",
   "metadata": {},
   "source": [
    "&emsp;&emsp;当然，这种system的设置方式还是会非常类似于prompt编写方式。那么，有没有更加简单的、借助system消息、不用单独设置Q和A的方式来完成Few-shot呢？这里有一种更为简单的方法，即设置两条system消息，此时模型会默认这两条system消息就是一次user-assistant对话消息，即可以按照如下方式完成Few-shot："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "50da864b-e666-4124-b79b-e95a9740ccf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": Q1},\n",
    "    {\"role\": \"system\", \"content\": A1},\n",
    "    {\"role\": \"user\", \"content\": Q2}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8ecf4a67-e8ac-4f4c-8032-9f31f0127211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'现在食堂总共有9个苹果。'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dbefe5-12f2-4d43-85d6-ba4e00d3b6df",
   "metadata": {},
   "source": [
    "不过这种代码形式可读性并不强，如希望通过多条system消息来模拟user-assistant多轮对话消息，则最好在system消息中添加一组额外的Key-value，相当于给这条消息额外进行备注，其中Key需要输入字符串name，而value则需要输入有助于理解这条消息定位的备注信息，例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "133f43b7-f5b2-4536-a24e-489d846b8316",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"name\":\"example_user\", \"content\": Q1},\n",
    "    {\"role\": \"system\", \"name\":\"example_assistant\", \"content\": A1},\n",
    "    {\"role\": \"user\", \"content\": Q2}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "bb0fa2ff-be93-4f11-a2c7-925b3f1a58f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'现在食堂总共有9个苹果。'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15ffc85-af00-44fc-9d10-1726bf6092a0",
   "metadata": {},
   "source": [
    "其中，前两条system消息分别输入了\"name\":\"example_user\"和\"name\":\"example_assistant\"，表示这两条消息中第一条消息用于模拟用户消息，第二条消息用于模拟助手消息。不过需要注意的是，当role为user、assistant或system时，messages参数中的字典的name参数是可选参数，且并无实际作用，并不会对模型的输出结果造成影响，name只用于标识特定的消息或对话轮次，相当于是增强代码可读性的。在很多多轮对话场景中，我们可以通过设置name参数来更好地组织和跟踪对话的不同部分。而需要注意的是，若role为function，则name参数就是必选参数，相关内容我们会在介绍function role时进行介绍。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11960f67-b7f0-4c88-b785-11db82f1e9ad",
   "metadata": {},
   "source": [
    "- 借助system role输入提示模板"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8dd7ec-2efb-4061-86b8-1ceeb33fde7f",
   "metadata": {},
   "source": [
    "&emsp;&emsp;即然system消息能够作为背景设定的基本消息并对后续的问答消息造成影响，那么很容易想到的system消息的一个应用场景就是借助system role输入提示模板，例如在Ch.4中曾介绍到，为了更好的提高模型推理能力，我们可以在每个prompt中加入一句“请一步步推理并得出结论”进而实现Zero-shot-CoT。而在Chat模型中，这种prompt模板信息是非常适合通过system role进行输入的，例如围绕第四个推理问题，我们可以通过输入一条内容为“请一步步推理并得出结论”的系统信息，来引导模型完成Zero-shot-CoT："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d9bb926d-a95b-4d58-ba73-5a3727d874cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_temp_cot = '请一步步思考并解决问题'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f1f57b80-99d1-481f-82ff-83d3f3540c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": prompt_temp_cot},\n",
    "    {\"role\": \"user\", \"content\": Q1}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "cacb7816-55a1-4f04-b16f-bbb205373068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'罗杰原本有5个网球\\n他又买了两盒网球，每盒有3个，所以一共买了2盒 × 3个/盒 = 6个网球\\n总共的网球数量为5个 + 6个 = 11个网球'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3584ef10-5aa6-4db8-88dc-39f0eb11fc34",
   "metadata": {},
   "source": [
    "能够看出，模型确实开始进行了CoT推导。接下来我们测试第四个推理问题、也是最复杂的一个推理问题："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9d5e3fba-4922-40d6-81bc-84c2e10c6cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": prompt_temp_cot},\n",
    "    {\"role\": \"user\", \"content\": Q4}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a4206406-1769-4f72-8f63-c11897d278c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'首先，我们需要弄清楚在15分钟内，艾米能够滑下来多少次。\\n\\n艾米每次从滑梯顶部滑下来需要1分钟，所以在15分钟内，她最多可以滑下来15次。\\n\\n然后，我们需要确定艾米每次滑下来后需要多少时间才能再次爬到滑梯顶部。\\n\\n艾米每次滑下来耗时1分钟，所以她需要再花4分钟才能爬到滑梯顶部。所以总共耗时为1分钟下滑时间加上4分钟爬升时间，即为5分钟。\\n\\n最后，我们可以计算出在15分钟内，艾米可以滑多少次。\\n\\n15分钟总共有多少个5分钟？答案是15/5=3个。\\n\\n艾米每次滑下来需要1分钟，所以在15分钟内，她可以滑3次。\\n\\n因此，在关闭之前，艾米可以滑3次。'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a62fbd-be61-4071-9a24-8f768812538e",
   "metadata": {},
   "source": [
    "能够看出发现在Zero-shot-CoT的情况下，gpt-3.5模型能够推导得出第四个问题的正确答案，但过程有点绕。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303f1470-2891-43a1-b3db-b6e4dbab9879",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来我们测试LtM提示法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8a87bcde-df06-4dc5-a92a-5a50a5420e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_temp_ltm = '为了解决当前这个问题，请列举我们先要解决的问题，并逐步解决原问题。'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1e145582-4f37-45be-b495-bfa6a0c8d285",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": prompt_temp_ltm},\n",
    "    {\"role\": \"user\", \"content\": Q1}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9055b680-f193-491f-908f-a6d1da0e1698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'先要解决的问题：\\n1. 罗杰原来有五个网球，他买了两盒网球，每盒有三个网球，我们需要计算他购买的网球数量。\\n\\n逐步解决：\\n1. 罗杰原来有五个网球。\\n2. 他买了两盒网球，每盒有三个网球。两盒网球总共有 2 * 3 = 6 个网球。\\n3. 罗杰原来有的五个网球加上购买的六个网球，总共有 5 + 6 = 11 个网球。 \\n\\n所以罗杰现在总共有 11 个网球。'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33211aca-3c1d-4402-8624-d18cd6a75654",
   "metadata": {},
   "source": [
    "能够发现模型确实能够按照提示模板进行逐步问题解决，并且和text-davinci-003模型类似，都能够一次性解决前置问题以及原问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76df8bca-0a7b-48bb-8002-6386ff8e7040",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来继续测试第四个问题："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "99916f5a-a55e-4053-82e2-dda94933f23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": prompt_temp_ltm},\n",
    "    {\"role\": \"user\", \"content\": Q4}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e8907a57-e90a-4e82-bda6-69e94056b2bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'要解决这个问题，我们需要考虑以下几个问题并逐步解决：\\n\\n1. 每次滑下来的时间是多少？\\n2. 在15分钟之内能滑下来多少次？\\n3. 是否需要考虑滑下来后到达滑梯顶部需要的时间？\\n\\n解决上述问题后，我们可以得到在关闭之前艾米能滑的次数。现在我们逐个解决这些问题：\\n\\n1. 每次滑下来的时间是多少？\\n已知艾米花了1分钟才滑下来，所以每次滑下来的时间是1分钟。\\n\\n2. 在15分钟之内能滑下来多少次？\\n在15分钟之内，每次滑下来的时间是1分钟，所以艾米在15分钟之内能滑的次数是15/1=15次。\\n\\n3. 是否需要考虑滑下来后到达滑梯顶部需要的时间？\\n根据题目描述，我们知道艾米需要4分钟才能爬到滑梯顶部。如果考虑滑下来后再爬上去的时间，每次滑梯的周期是5分钟（1分钟滑下来+4分钟爬上去）。\\n\\n所以，在15分钟之内，艾米能滑的次数是15/5=3次。\\n\\n所以，在关闭之前艾米能滑3次。'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e00a1b9-9d77-4e21-833d-cd01a830b7a9",
   "metadata": {},
   "source": [
    "能够发现，ltm提示方法对gpt-3.5这类Chat模型仍然有效。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48c0c59-e912-408b-b8d3-d41e7e1b0316",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1482e7-f84a-4773-b09a-efa5b83c4aed",
   "metadata": {},
   "source": [
    "- gpt-4性能测试"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2edc324-b4ab-40c3-ba1e-ee91f57c76f4",
   "metadata": {},
   "source": [
    "&emsp;&emsp;相比gpt-3.5复杂且不稳定的推导过程，gpt-4模型在相同提示策略下，会表现出更强大的推理性能。例如，同样是围绕第四个问题，对gpt-4模型进行CoT和LtM提示结果如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6761aeea-56b0-4a87-8391-e682598ec51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-4-0613\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": prompt_temp_cot},\n",
    "    {\"role\": \"user\", \"content\": Q4}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8e46c771-441c-4e3a-889d-3b66f6ba69c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'第一步，首先需要确定艾米完成一个滑梯运动需要的总时间，即爬到滑梯顶部的时间与滑下来的时间总和。在此问题中，艾米需要4分钟爬到滑梯顶部，1分钟滑下来。总共需要5分钟。\\n\\n第二步，然后我们需要计算在水滑梯关闭前，艾米可以完成多少次滑梯运动。我们已知水滑梯将在15分钟后关闭，因此我们将15分钟除以每次滑梯运动所需要的时间，得到她可以滑的次数。\\n\\n计算为：15分钟 ÷ 5分钟/次 = 3次\\n\\n所以，在水滑梯关闭之前，艾米可以滑3次。'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "fe29ab3e-5757-4c1c-a551-2c4cc70e93e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-4-0613\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": prompt_temp_ltm},\n",
    "    {\"role\": \"user\", \"content\": Q4}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e0eb9771-5baa-4150-9ab0-2952b633102c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'要解决这个问题，我们需要首先解决以下几个子问题：\\n\\n1. 确定艾米每次滑梯需要的总时间，即爬到滑梯顶部和滑下来的时间总和。\\n2. 确定在水滑梯关闭前，艾米有多少时间可以滑梯。\\n3. 使用总时间除以每次滑梯所需的时间。\\n\\n解决方案如下：\\n\\n1. 每次滑梯艾米需要的总时间是4分钟+1分钟=5分钟。\\n2. 水滑梯将在15分钟后关闭，所以艾米有15分钟的时间可以滑梯。\\n3. 艾米能滑的次数=总时间/每次滑梯所需的时间=15分钟/5分钟=3次。\\n\\n所以，艾米在水滑梯关闭前能滑3次。'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c999308a-5f22-42d5-8d7e-3deb31469024",
   "metadata": {},
   "source": [
    "能够看出，gpt-4模型展示出的推理性能要强大很多。当然，除了推理能力外，gpt-4各方面性能都属于目前大模型领域的顶流。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c803e0c-8a10-4394-b7d5-f46af3459ec5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b893308-3b1d-4749-916d-5f2d08305bed",
   "metadata": {},
   "source": [
    "- 借助system role设置聊天背景信息"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9df9bb-faeb-46c4-a322-2f1430484238",
   "metadata": {},
   "source": [
    "&emsp;&emsp;除了可以借助system消息非常便捷的进行提示模板的设计之外，还有一个非常常见的system role的使用方法，就是借助system消息进行聊天背景信息的设定，很多时候我们可以在system消息中输入一段长文本，这段长文本将在聊天开始之前输入到系统中，而在之后的聊天中，即可让assistant围绕这个长文本进行回答，这是一种最简单的实现大语言模型围绕本地知识库进行问答的方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884ecf3c-e45b-4b5d-81f7-066742509747",
   "metadata": {},
   "source": [
    "&emsp;&emsp;这里我们在system消息中输入一段关于虚拟人物“陈明”的个人简介，而在之后的提问中，user和assistant将可以自由的围绕这段输入的背景信息进行问答："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a2ab9ce-22ac-45e2-905e-dfc5d67a900e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '陈明，男，1973年7月15日出生于中国福建省厦门市。\\\n",
    "        1991年毕业于厦门大学电子科学与技术系，继而于1998年在北京大学获得信息技术博士学位。\\\n",
    "        毕业后的陈明在硅谷的一家著名科技公司工作了五年，专注于人工智能和机器学习的研发。'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d9878d6-d89f-4869-af32-f159f67d0730",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": text},\n",
    "    {\"role\": \"user\", \"content\": '请问陈明是那一年出生？'}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85d98327-f3aa-440f-bef1-bcd6e2fe97de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'陈明于1973年出生。'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e832eeac-c45a-4dc8-8893-60044e4baeaa",
   "metadata": {},
   "source": [
    "能够看出，这段背景背景信息能够被模型学习并以此进行特定问题的回答。这其实就是一种非常简单的围绕本地知识进行问答的实现形式，不过需要注意的是，system role输入的信息也算是输入给模型的信息，因此受限于大语言模型的最大输入信息长度，单独借助system role在ChatCompletion.create函数中输入背景信息并不能真正意义上实现高度定制化、超大规模文本的本地知识库问答。但是，如果围绕着超大规模本地文本知识库先进行基于滑动窗口的文本切分，以确保切分后的小文本段落满足Max tokens要求，并且配合Embedding过程进行user问题和短文本的实时匹配，再把每个user问题匹配的关联度最高的文本以system消息的形式输入到模型中，再进行回答，则可以非常高效并且准确的实现本地知识库问答。而在这个过程中，借助system role进行背景文字的输入就非常基本的技术手段。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47a9543-2743-40c7-8415-7b02bc2ba2f4",
   "metadata": {},
   "source": [
    "> 课程中将详细介绍上述本地知识库问答的高效实现方法，相关内容将在Embedding模型内容结束后进行介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c36f95-b5c3-4111-81fe-03f724bcf351",
   "metadata": {},
   "source": [
    "- 借助.append方法进行多轮对话"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36650629-b2b1-45d7-9ba5-8cf55fbe1d77",
   "metadata": {},
   "source": [
    "&emsp;&emsp;最后，除了上述通过内部参数修改来实现不同功能外，messages参数的另一个重要应用是借助append方法来高效实现多轮对话。不同于Completion模型需要将历史问答都拼接为一个字符串并输入到新的prompt中来实现历史消息的输入，对于Chat模型来说，我们只需要将模型返回的message消息+用户新的提问message拼接到模型的messages参数中，并再次向模型进行提问，即可非常便捷的实现多轮对话。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0248b9de-9188-4d76-b998-665d76cdc048",
   "metadata": {},
   "source": [
    "首先我们可以使用to_dict()方法将模型返回的message信息转化为字典类型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04053a29-05f3-48f5-bdaf-149b17225a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject at 0x1f0e62fc4f0> JSON: {\n",
       "  \"content\": \"\\u9648\\u660e\\u4e8e1973\\u5e74\\u51fa\\u751f\\u3002\",\n",
       "  \"role\": \"assistant\"\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1c44b87-90cd-421f-8b52-c33aec4a99c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "openai.openai_object.OpenAIObject"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f642f6c-f689-4c0b-b273-414739cd9013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant', 'content': '陈明于1973年出生。'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f17dd65-4e75-4106-ba9c-98b6e3652edf",
   "metadata": {},
   "source": [
    "然后单独设置messages参数，并将此前的问题+答案进行拼接："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61856133-0c21-4b59-aa2c-17d4b6ab0919",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": text},\n",
    "    {\"role\": \"user\", \"content\": '请问陈明是那一年出生？'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3bb7e57-42f0-40b9-a5f6-01a909d042c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(response.choices[0].message.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad1344f6-d475-4efd-837d-e024b68ba7eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': '陈明，男，1973年7月15日出生于中国福建省厦门市。        1991年毕业于厦门大学电子科学与技术系，继而于1998年在北京大学获得信息技术博士学位。        毕业后的陈明在硅谷的一家著名科技公司工作了五年，专注于人工智能和机器学习的研发。'},\n",
       " {'role': 'user', 'content': '请问陈明是那一年出生？'},\n",
       " {'role': 'assistant', 'content': '陈明于1973年出生。'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc32822-d236-4fad-8f3c-6d11f672d3f5",
   "metadata": {},
   "source": [
    "此时messages参数就包含了最开始的问题+问题答案。接下来我们在messages消息中添加下一个问题："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3500f4e7-f69b-4182-9457-6c48299f20e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append({'role': 'user', 'content': '请问我刚才的问题是？'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "821fbfe0-19a1-45e5-b490-7fa8fa5f6b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': '陈明，男，1973年7月15日出生于中国福建省厦门市。        1991年毕业于厦门大学电子科学与技术系，继而于1998年在北京大学获得信息技术博士学位。        毕业后的陈明在硅谷的一家著名科技公司工作了五年，专注于人工智能和机器学习的研发。'},\n",
       " {'role': 'user', 'content': '请问陈明是那一年出生？'},\n",
       " {'role': 'assistant', 'content': '陈明于1973年出生。'},\n",
       " {'role': 'user', 'content': '请问我刚才的问题是？'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a8b238-1f39-4505-9037-f4d83347b91a",
   "metadata": {},
   "source": [
    "接下来再次调用模型，并输入messages作为参数，此时模型将同时结合此前的所有消息，并围绕最后一个user信息进行回答："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a532dbe8-d2f4-423c-bd05-f64bf3ea1495",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41b05f06-5a47-40d9-808a-df75358fb214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'您刚才的问题是“请问陈明是那一年出生？”'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43867ae-7421-4230-a4ff-48196fc5dd40",
   "metadata": {},
   "source": [
    "能够发现，相比Completions模型，Chat类模型能够更加便捷的实现多轮对话。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f18ede-c1ca-49b5-9302-420b0248ec4e",
   "metadata": {},
   "source": [
    "- 代码补全"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0bb892-d686-41da-a973-5ba288310859",
   "metadata": {},
   "source": [
    "&emsp;&emsp;对于Chat模型来说，还有一个非常有趣且十分具有潜力的应用方向，那就是代码补全。通过在system message中设置好代码补全功能，然后在user message中著名代码实现的功能，例如计算斐波那契数列，则assistant message就能自动将后续代码补全："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0967587a-dfd0-4628-8b65-f55f9e165598",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": '请将用户提出的python代码进行补全。'},\n",
    "    {\"role\": \"user\", \"content\": 'def fibonacci(num):'}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0df1fd92-3689-45c9-aa07-3ce4f95dd6e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def fibonacci(num):\\n    if num <= 0:\\n        return []\\n    elif num == 1:\\n        return [0]\\n    elif num == 2:\\n        return [0, 1]\\n    else:\\n        fib = [0, 1]\\n        for i in range(2, num):\\n            fib.append(fib[i-1] + fib[i-2])\\n        return fib'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81f0171-7338-46d0-97af-5ebdebed6e46",
   "metadata": {},
   "source": [
    "将上述字符串形式展示的代码转化为python格式，得到完整代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d44a6653-8e37-480f-9abe-171b59edfef1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fibonacci(num):\n",
    "    if num <= 0:\n",
    "        return []\n",
    "    elif num == 1:\n",
    "        return [0]\n",
    "    elif num == 2:\n",
    "        return [0, 1]\n",
    "    else:\n",
    "        fib = [0, 1]\n",
    "        for i in range(2, num):\n",
    "            fib.append(fib[i-1] + fib[i-2])\n",
    "        return fib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cdc255-bf5d-42ee-80d9-05aea0a7a650",
   "metadata": {},
   "source": [
    "测试能否进行斐波那契数列计算："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f0dc1c8b-a1e9-4aaa-9ca5-294c1ace3ea1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 2, 3]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fibonacci(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d2a2fb44-7a09-42e2-855e-b63640fe513e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'斐波那契数列是一个数列，其中每个数字都是前面两个数字的和。数列的前两个数字通常定义为0和1。因此，斐波那契数列的开始部分是：0，1，1，2，3，5，8，13，21，34，55，89，144，... 以此类推。斐波那契数列在数学和计算机科学中起着重要的作用，被广泛应用于算法设计、动态规划、递归等领域。'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": '什么是斐波那契数列？'}\n",
    "  ]\n",
    ")\n",
    "response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7f2905-6700-44bd-bfef-a0f878bbbef5",
   "metadata": {},
   "source": [
    "能够发现，模型能够很好的完成斐波那契函数编写。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e5448c-4407-4f24-a899-f129553aa87c",
   "metadata": {},
   "source": [
    "&emsp;&emsp;而若要深究模型为何能够完成斐波那契函数的代码补全，非常根本的原因在于模型对字符串'def fibonacci(num):'对应的含义非常了解——即本身知道斐波那契数列、也十分清楚斐波那契数列的这一特定的python函数编写方法，因此我们可以通过上述提示在Zero-shot的情况下就引导模型编写了斐波那契函数。而如果是其他类型的函数，其功能和实现方法无法被模型“天然的理解”（不在训练语料中），那么则需要更多的描述和提示，才能够引导模型完成函数创建。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646c4593-5a0f-4458-a43e-e7985862c868",
   "metadata": {},
   "source": [
    "### 5.手动实操项目：借助gpt完成课堂知识总结与新代码代码编写"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5caaf4-6c23-4f4b-bb63-436ed52dd157",
   "metadata": {},
   "source": [
    "&emsp;&emsp;最后，尝试实现一个手动实操项目，即训练一个简易的课程内容智能助理，要求让这个智能助理能够理解本节课程内容，同时也能够围绕课程问题进行多轮对话，以辅助我们进行课程内容学习和复习。总的来看我们对于这个极简的智能助理有两方面要求，其一是熟知课程内容，其二则是能够实现多轮对话。当然，这个多轮对话的函数也是可以让模型来进行手动编写的。需要注意的是，由于gpt系列模型的知识库截止于2021年9月，因此模型本身是不知道ChatCompletion.create函数的，因此只通过模型原始的知识库是无法完成多轮对话函数编写的，因此我们需要先把课程内容输入给模型，然后再引导模型完成多轮对话函数的编写。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65a0964-8b02-4ebe-a89e-f98077758e50",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/48898b210c6c1ead2e7dcccc711374e.png\" alt=\"48898b210c6c1ead2e7dcccc711374e\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d069eb-0f67-4c4e-bb34-47c352d165c3",
   "metadata": {},
   "source": [
    "> 这里需要注意，如果我们直接在代码环境中对模型提问什么是ChatCompletion.create函数，模型会给出一组像模像样的结果，但这并不代表gpt-3.5模型有ChatCompletion.create函数相关的知识储备，模型只是根据Completion.create函数类比进行回答。而为何代码环境下gpt-3.5 API会出现幻觉而ChatGPT则能很诚实的回答“自己不知道”，猜测应该是ChatGPT在这方面带入了额外数据进行微调。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9eb71b7-f7dc-4b35-8b98-e5b7b18288cd",
   "metadata": {},
   "source": [
    "&emsp;&emsp;要将课程内容“喂”给gpt模型，首先需要将ipy文件转化为md格式文件，然后再在python环境中将md格式文件读取为字符串对象即可。这里将ipy文件转化为md格式文件的方法有很多种，既可以先通过浏览器将ipy文件转化为html再转化为md，也可以通过浏览器的打印功能将其先转化为pdf再转化为md格式文件。课程中直接提供一份经过转化之后的本节课程内容的md格式文件《Ch.7 ChatCompletions模型API使用指南.md》，尝试使用如下代码进行读取："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "43790687-9f25-4a0a-8c06-0a137adcc9ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 打开并读取Markdown文件\n",
    "with open('Ch.7 ChatCompletions模型API使用指南.md', 'r', encoding='utf-8') as f:\n",
    "    md_content = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d7a4a819-519e-437f-9df9-83774865b411",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# <center>OpenAI在线大模型调用及微调方法\\n\\n## <center>Ch.5 ChatCompletions模型API使用指南\\n\\n### 1.Chat Completions模型概述\\n\\n#### 1.1 Chat Completions模型API基本情况介绍\\n\\n&emsp;&emsp;尽管在上一小节末尾，我们尝试编写了一个可以预设风格的多轮对话函数，但实际上，相比Completions模型，Chat Completions模型（对话大模型）会更适合执行对话类任务。正如上一小节所说，Chat Completions模型是一类专门围绕对话类任务进行训练和微调的模型，截至目前，OpenAI发布的Chat Completions模型主要包括gpt-3.5和gpt-4两类模型，当然，这两个模型也是目前ChatGPT应用程序背后的对话大模型。其中，根据官网给出的说明，gpt-3.5模型是基于text-davinci-003微调的模型，而后者其实是属于gpt-3模型类，并且由code-davinci-002这一基座模型经过几轮微调后训练得到，对应的模型微调关系如下所示：\\n\\n<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202306261634213.png\" alt=\"c604cd1f126567e50e4fc6ad2c884a3\" style=\"zoom:33%;\" />\\n\\n> 这里需要补充说明的是，由于OpenAI的模型训练方法并未公开，因此官网说明中的“improvement”是否是指微调其实并不确定。\\n\\n当然，gpt-4则是完全重新训练的最新一代的对话类大模型，在诸多国内外大模型评测榜单上，gpt-4也是目前（多语种）对话效果最好的一类对话类大模型。根据OpenAI7月6号的更新说明，目前gpt-4 API已针对此前支付过API费用的开发者全部开放，并且计划在7月内对全部用户开放gpt-4 API权限。鉴于此，课程中也将尽量使用gpt-4 API用于教学。\\n\\n<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/bc0440e6f31a8e331b5eecbc402c871.png\" alt=\"bc0440e6f31a8e331b5eecbc402c871\" style=\"zoom:20%;\" />\\n\\n截至目前，OpenAI发布的Chat Completions模型如下：\\n\\n<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202306241505316.png\" alt=\"0ce263719c0b5d234ae3a6b8be1eef8\" style=\"zoom:33%;\" />\\n\\n不同于Completions模型，Chat Completions模型并未开放全部的API，对于大多数模型的长文本对话模型（即标注为32k的模型），也需要填写申请方可使用，填写地址：https://platform.openai.com/docs/guides/rate-limits/overview 。而具体当前账户能够调用哪些对话类大模型的API，可以在个人中心的Rate limits页面查看：\\n\\n<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202306261652051.png\" alt=\"67e8aef163e8a273b5a36115a89929d\" style=\"zoom:33%;\" />\\n\\n#### 1.2 2023/06/13 OpenAI API updates     \\n\\n&emsp;&emsp;即然介绍Chat Completions模型，不得不提的就是OpenAI在2023年6月13日发布的以Chat Completions模型为主的重磅更新。可以说，这是自gpt-4 API公布申请之后OpenAI发布的最大的模型更新，而这些围绕着Chat Completions模型进行的更新，也将是接下来课程内容学习的重点。这里我们简单总结0613更新内容如下：\\n\\n- 发布了0613编号的模型，包括gpt-3.5-turbo-0613、gpt-4-turbo-0613等，相比此前的gpt-3.5和gpt-4模型，这些0613编号模型新增了函数API的调用功能，使得其可以调用一些外部工具（例如可以调用ChatGPT插件的API）来实现某些功能。毫无疑问这是一次极具革命性的创举，在此之前，大语言模型的函数API调用只能借助LangChain来完成；新增此功能之后，围绕OpenAI大语言模型的AI应用程序开发的门槛也将大幅降低；      \\n- 发布了最大支持16k上下文的模型，例如gpt-3.5-turbo-16k、gpt-3.5-turbo-16k-0613等，在默认情况下gpt模型的最大上下文token限制为4k（4096个token），而16k版本的模型则将这个最大限制拓宽为16k个token（16384个token），这毫无疑问会大幅增加模型阅读长文本信息的能力和多轮对话能力；不过这里需要注意，没有标注16k的模型上下文仍然最大只支持4k；        \\n- 大幅降低了部分模型API的调用，其中text-embedding-ada-002模型使用费用降低了75%，而gpt-3.5-turbo使用费用降低了25%，前者是目前最先进的Embedding模型，而后者则是目前用户调用次数最多的模型。\\n\\n能够看出，对话类大语言模型既是目前使用最多的一类模型、同时也是OpenAI大力维护的一类模型。接下来，我们就从具体的对话类模型调用方法入手学习，并在本节课程的末尾为大家介绍目前工业界基于对话类大模型的应用实战案例。\\n\\n#### 1.3 2023/07/06 OpenAI API updates     \\n\\n&emsp;&emsp;P【penAI\\n\\ngpt-4 API全面可用，Chat模型微调即将上线\\n\\n---\\n\\n- gpt-4团队API使用方法\\n\\n&emsp;&emsp;若是对于此前通过提交申请获得的gpt-4 API，则需要通过团队API页面来查看gpt-4 API情况，具体方法如下，首先，我们能够在Rate limilts页面查看当前能够使用的gpt-4模型（若申请通过的话）：\\n\\n<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202307052112745.png\" alt=\"222508a4fa00351b2e5e96df56d454a\" style=\"zoom: 33%;\" />\\n\\n其次，由于gpt-4 API只针对组织（Organization）开放（注意，申请gpt-4 API时也是需要以组织身份申请），因此，若要使用gpt-4 API，则需要把当前账户切换成组织模型，点击个人头像即可切换：\\n\\n<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202307052116563.png\" alt=\"cf091130d8d745b54f842c39386d5c5\" style=\"zoom:33%;\" />\\n\\n然后点击API keys，并在页面下方点击选择组织，即可使用该API调用组织内可以用的模型，并计费到组织账户：\\n\\n<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202307052118681.png\" alt=\"5d0550ae6d9d02accfe15c7f0993b13\" style=\"zoom:33%;\" />\\n\\n这里需要注意，同一个账户下的同一个API key，是可以在个人模式和组织模式下随时切换的，如果切换成个人模式，相同的API key则会调用个人账户可以使用的模型，并在个人账户计费。而如果切换成组织模式，则可以调用组织下可以下调用的API，并且在组织账户内进行计费。\\n\\n---\\n\\n### 2.ChatCompletion.create API使用方法及参数解释\\n\\n#### 2.1 ChatCompletion.create函数使用简例\\n\\n&emsp;&emsp;接下来，我们尝试调用OpenAI的Chat类模型，并详细解释模型API参数。和调用Completion模型需要使用Completion.create函数类似，若要调用Chat类大模型，则需要使用ChatCompletion.create函数。由于Chat模型本身是基于Completion模型的、专门用于处理对话类任务的模型，因此ChatCompletion.create的使用方法和Completion.create非常类似，整体函数使用流程和核心参数都非常类似，这里我们直接对Chat模型提问“什么是机器学习？”提问和获取结果流程如下：\\n\\n\\n```python\\nimport os\\nimport openai\\nopenai.api_key = os.getenv(\"OPENAI_API_KEY\")\\n```\\n\\n\\n```python\\nresponse = openai.ChatCompletion.create(\\n  model=\"gpt-3.5-turbo\",\\n  messages=[\\n    {\"role\": \"user\", \"content\": \"请问，什么是机器学习？\"}\\n  ]\\n)\\n```\\n\\n\\n```python\\nresponse\\n```\\n\\n\\n\\n\\n    <OpenAIObject chat.completion id=chatcmpl-7aMK1Zr3sFfDrvScu0rGRShzbjNsI at 0x2e70127e980> JSON: {\\n      \"id\": \"chatcmpl-7aMK1Zr3sFfDrvScu0rGRShzbjNsI\",\\n      \"object\": \"chat.completion\",\\n      \"created\": 1688899969,\\n      \"model\": \"gpt-3.5-turbo-0613\",\\n      \"choices\": [\\n        {\\n          \"index\": 0,\\n          \"message\": {\\n            \"role\": \"assistant\",\\n            \"content\": \"\\\\u673a\\\\u5668\\\\u5b66\\\\u4e60\\\\u662f\\\\u4e00\\\\u79cd\\\\u4eba\\\\u5de5\\\\u667a\\\\u80fd\\\\u9886\\\\u57df\\\\u7684\\\\u6280\\\\u672f\\\\uff0c\\\\u901a\\\\u8fc7\\\\u8ba9\\\\u8ba1\\\\u7b97\\\\u673a\\\\u7cfb\\\\u7edf\\\\u6839\\\\u636e\\\\u5927\\\\u91cf\\\\u6570\\\\u636e\\\\u81ea\\\\u52a8\\\\u5b66\\\\u4e60\\\\u548c\\\\u6539\\\\u8fdb\\\\uff0c\\\\u4ece\\\\u800c\\\\u5b9e\\\\u73b0\\\\u7279\\\\u5b9a\\\\u4efb\\\\u52a1\\\\u7684\\\\u80fd\\\\u529b\\\\u3002\\\\u7b80\\\\u800c\\\\u8a00\\\\u4e4b\\\\uff0c\\\\u673a\\\\u5668\\\\u5b66\\\\u4e60\\\\u662f\\\\u6307\\\\u8ba1\\\\u7b97\\\\u673a\\\\u7cfb\\\\u7edf\\\\u5229\\\\u7528\\\\u7edf\\\\u8ba1\\\\u5b66\\\\u548c\\\\u7b97\\\\u6cd5\\\\u6765\\\\u4f7f\\\\u81ea\\\\u8eab\\\\u83b7\\\\u5f97\\\\u4ece\\\\u6837\\\\u672c\\\\u6570\\\\u636e\\\\u4e2d\\\\u5b66\\\\u4e60\\\\u7684\\\\u80fd\\\\u529b\\\\uff0c\\\\u5e76\\\\u5229\\\\u7528\\\\u5b66\\\\u4e60\\\\u5230\\\\u7684\\\\u77e5\\\\u8bc6\\\\u8fdb\\\\u884c\\\\u9884\\\\u6d4b\\\\u3001\\\\u51b3\\\\u7b56\\\\u6216\\\\u6267\\\\u884c\\\\u7279\\\\u5b9a\\\\u4efb\\\\u52a1\\\\u3002\\\\u5b83\\\\u6d89\\\\u53ca\\\\u8bb8\\\\u591a\\\\u7b97\\\\u6cd5\\\\u548c\\\\u6280\\\\u672f\\\\uff0c\\\\u4f8b\\\\u5982\\\\u76d1\\\\u7763\\\\u5b66\\\\u4e60\\\\u3001\\\\u65e0\\\\u76d1\\\\u7763\\\\u5b66\\\\u4e60\\\\u3001\\\\u5f3a\\\\u5316\\\\u5b66\\\\u4e60\\\\u7b49\\\\u3002\\\\u673a\\\\u5668\\\\u5b66\\\\u4e60\\\\u5728\\\\u5404\\\\u79cd\\\\u9886\\\\u57df\\\\u4e2d\\\\u5f97\\\\u5230\\\\u4e86\\\\u5e7f\\\\u6cdb\\\\u5e94\\\\u7528\\\\uff0c\\\\u5982\\\\u81ea\\\\u7136\\\\u8bed\\\\u8a00\\\\u5904\\\\u7406\\\\u3001\\\\u56fe\\\\u50cf\\\\u8bc6\\\\u522b\\\\u3001\\\\u63a8\\\\u8350\\\\u7cfb\\\\u7edf\\\\u7b49\\\\u3002\"\\n          },\\n          \"finish_reason\": \"stop\"\\n        }\\n      ],\\n      \"usage\": {\\n        \"prompt_tokens\": 20,\\n        \"completion_tokens\": 204,\\n        \"total_tokens\": 224\\n      }\\n    }\\n\\n\\n\\n能够看出，和Completion.create非常明显的一个区别在于，ChatCompletion.create函数的调用不再需要prompt参数，而是换成了messages参数，并且，不同于prompt参数对象是以简单的字符串形式呈现，messages参数则是一个基本构成元素为字典的列表，其内每个字典都代表一条独立的消息，每个字典都包含两个键值（Key-value）对，其中第一个Key都是字符串role（角色）表示某条消息的作者，第二个key为content（内容）表示消息具体内容。可以说messages参数是ChatCompletion.create函数最重要的参数之一，能够看出比简单的prompt参数格式要更加复杂。更多关于message的参数设置方法稍后介绍，总的来看，这里的messages就可以简单理解为输入给模型的信息，而模型接收到message之后也会输出对应的回答信息，当然也是以message形式呈现：\\n\\n\\n```python\\n# 返回对象类型和Completion.create函数返回对象类型一致\\ntype(response)\\n```\\n\\n\\n\\n\\n    openai.openai_object.OpenAIObject\\n\\n\\n\\n\\n```python\\n# 可以通过索引的方式索引出文本部分内容\\nresponse[\"choices\"]\\n```\\n\\n\\n\\n\\n    [<OpenAIObject at 0x2017fa89ea0> JSON: {\\n       \"finish_reason\": \"stop\",\\n       \"index\": 0,\\n       \"message\": {\\n         \"content\": \"\\\\u673a\\\\u5668\\\\u5b66\\\\u4e60\\\\u662f\\\\u4e00\\\\u79cd\\\\u4eba\\\\u5de5\\\\u667a\\\\u80fd\\\\u7684\\\\u5206\\\\u652f\\\\u9886\\\\u57df\\\\uff0c\\\\u5b83\\\\u7814\\\\u7a76\\\\u5982\\\\u4f55\\\\u4f7f\\\\u8ba1\\\\u7b97\\\\u673a\\\\u7cfb\\\\u7edf\\\\u6839\\\\u636e\\\\u6570\\\\u636e\\\\u548c\\\\u7ecf\\\\u9a8c\\\\u81ea\\\\u52a8\\\\u6539\\\\u5584\\\\u548c\\\\u9002\\\\u5e94\\\\uff0c\\\\u800c\\\\u65e0\\\\u9700\\\\u660e\\\\u786e\\\\u5730\\\\u8fdb\\\\u884c\\\\u7f16\\\\u7a0b\\\\u3002\\\\u673a\\\\u5668\\\\u5b66\\\\u4e60\\\\u7684\\\\u76ee\\\\u6807\\\\u662f\\\\u901a\\\\u8fc7\\\\u6784\\\\u5efa\\\\u6a21\\\\u578b\\\\u548c\\\\u7b97\\\\u6cd5\\\\uff0c\\\\u8ba9\\\\u8ba1\\\\u7b97\\\\u673a\\\\u80fd\\\\u591f\\\\u4ece\\\\u5927\\\\u91cf\\\\u6570\\\\u636e\\\\u4e2d\\\\u5b66\\\\u4e60\\\\uff0c\\\\u5e76\\\\u4e14\\\\u53ef\\\\u4ee5\\\\u4ece\\\\u4e2d\\\\u53d1\\\\u73b0\\\\u6a21\\\\u5f0f\\\\u3001\\\\u505a\\\\u51fa\\\\u9884\\\\u6d4b\\\\u548c\\\\u505a\\\\u51fa\\\\u76f8\\\\u5e94\\\\u7684\\\\u51b3\\\\u7b56\\\\u3002\\\\u673a\\\\u5668\\\\u5b66\\\\u4e60\\\\u6280\\\\u672f\\\\u88ab\\\\u5e7f\\\\u6cdb\\\\u5e94\\\\u7528\\\\u4e8e\\\\u56fe\\\\u50cf\\\\u548c\\\\u8bed\\\\u97f3\\\\u8bc6\\\\u522b\\\\u3001\\\\u81ea\\\\u7136\\\\u8bed\\\\u8a00\\\\u5904\\\\u7406\\\\u3001\\\\u63a8\\\\u8350\\\\u7cfb\\\\u7edf\\\\u3001\\\\u6570\\\\u636e\\\\u6316\\\\u6398\\\\u7b49\\\\u9886\\\\u57df\\\\uff0c\\\\u4ee5\\\\u89e3\\\\u51b3\\\\u590d\\\\u6742\\\\u95ee\\\\u9898\\\\u548c\\\\u6539\\\\u8fdb\\\\u4eba\\\\u5de5\\\\u667a\\\\u80fd\\\\u7cfb\\\\u7edf\\\\u7684\\\\u6027\\\\u80fd\\\\u3002\",\\n         \"role\": \"assistant\"\\n       }\\n     }]\\n\\n\\n\\n\\n```python\\n# 也可以通过属性调用的方式查看choices\\nresponse.choices\\n```\\n\\n\\n\\n\\n    [<OpenAIObject at 0x2017fa89ea0> JSON: {\\n       \"finish_reason\": \"stop\",\\n       \"index\": 0,\\n       \"message\": {\\n         \"content\": \"\\\\u673a\\\\u5668\\\\u5b66\\\\u4e60\\\\u662f\\\\u4e00\\\\u79cd\\\\u4eba\\\\u5de5\\\\u667a\\\\u80fd\\\\u7684\\\\u5206\\\\u652f\\\\u9886\\\\u57df\\\\uff0c\\\\u5b83\\\\u7814\\\\u7a76\\\\u5982\\\\u4f55\\\\u4f7f\\\\u8ba1\\\\u7b97\\\\u673a\\\\u7cfb\\\\u7edf\\\\u6839\\\\u636e\\\\u6570\\\\u636e\\\\u548c\\\\u7ecf\\\\u9a8c\\\\u81ea\\\\u52a8\\\\u6539\\\\u5584\\\\u548c\\\\u9002\\\\u5e94\\\\uff0c\\\\u800c\\\\u65e0\\\\u9700\\\\u660e\\\\u786e\\\\u5730\\\\u8fdb\\\\u884c\\\\u7f16\\\\u7a0b\\\\u3002\\\\u673a\\\\u5668\\\\u5b66\\\\u4e60\\\\u7684\\\\u76ee\\\\u6807\\\\u662f\\\\u901a\\\\u8fc7\\\\u6784\\\\u5efa\\\\u6a21\\\\u578b\\\\u548c\\\\u7b97\\\\u6cd5\\\\uff0c\\\\u8ba9\\\\u8ba1\\\\u7b97\\\\u673a\\\\u80fd\\\\u591f\\\\u4ece\\\\u5927\\\\u91cf\\\\u6570\\\\u636e\\\\u4e2d\\\\u5b66\\\\u4e60\\\\uff0c\\\\u5e76\\\\u4e14\\\\u53ef\\\\u4ee5\\\\u4ece\\\\u4e2d\\\\u53d1\\\\u73b0\\\\u6a21\\\\u5f0f\\\\u3001\\\\u505a\\\\u51fa\\\\u9884\\\\u6d4b\\\\u548c\\\\u505a\\\\u51fa\\\\u76f8\\\\u5e94\\\\u7684\\\\u51b3\\\\u7b56\\\\u3002\\\\u673a\\\\u5668\\\\u5b66\\\\u4e60\\\\u6280\\\\u672f\\\\u88ab\\\\u5e7f\\\\u6cdb\\\\u5e94\\\\u7528\\\\u4e8e\\\\u56fe\\\\u50cf\\\\u548c\\\\u8bed\\\\u97f3\\\\u8bc6\\\\u522b\\\\u3001\\\\u81ea\\\\u7136\\\\u8bed\\\\u8a00\\\\u5904\\\\u7406\\\\u3001\\\\u63a8\\\\u8350\\\\u7cfb\\\\u7edf\\\\u3001\\\\u6570\\\\u636e\\\\u6316\\\\u6398\\\\u7b49\\\\u9886\\\\u57df\\\\uff0c\\\\u4ee5\\\\u89e3\\\\u51b3\\\\u590d\\\\u6742\\\\u95ee\\\\u9898\\\\u548c\\\\u6539\\\\u8fdb\\\\u4eba\\\\u5de5\\\\u667a\\\\u80fd\\\\u7cfb\\\\u7edf\\\\u7684\\\\u6027\\\\u80fd\\\\u3002\",\\n         \"role\": \"assistant\"\\n       }\\n     }]\\n\\n\\n\\n\\n```python\\n# 查看第一个返回结果\\nresponse.choices[0]\\n```\\n\\n\\n\\n\\n    <OpenAIObject at 0x2017fa89ea0> JSON: {\\n      \"finish_reason\": \"stop\",\\n      \"index\": 0,\\n      \"message\": {\\n        \"content\": \"\\\\u673a\\\\u5668\\\\u5b66\\\\u4e60\\\\u662f\\\\u4e00\\\\u79cd\\\\u4eba\\\\u5de5\\\\u667a\\\\u80fd\\\\u7684\\\\u5206\\\\u652f\\\\u9886\\\\u57df\\\\uff0c\\\\u5b83\\\\u7814\\\\u7a76\\\\u5982\\\\u4f55\\\\u4f7f\\\\u8ba1\\\\u7b97\\\\u673a\\\\u7cfb\\\\u7edf\\\\u6839\\\\u636e\\\\u6570\\\\u636e\\\\u548c\\\\u7ecf\\\\u9a8c\\\\u81ea\\\\u52a8\\\\u6539\\\\u5584\\\\u548c\\\\u9002\\\\u5e94\\\\uff0c\\\\u800c\\\\u65e0\\\\u9700\\\\u660e\\\\u786e\\\\u5730\\\\u8fdb\\\\u884c\\\\u7f16\\\\u7a0b\\\\u3002\\\\u673a\\\\u5668\\\\u5b66\\\\u4e60\\\\u7684\\\\u76ee\\\\u6807\\\\u662f\\\\u901a\\\\u8fc7\\\\u6784\\\\u5efa\\\\u6a21\\\\u578b\\\\u548c\\\\u7b97\\\\u6cd5\\\\uff0c\\\\u8ba9\\\\u8ba1\\\\u7b97\\\\u673a\\\\u80fd\\\\u591f\\\\u4ece\\\\u5927\\\\u91cf\\\\u6570\\\\u636e\\\\u4e2d\\\\u5b66\\\\u4e60\\\\uff0c\\\\u5e76\\\\u4e14\\\\u53ef\\\\u4ee5\\\\u4ece\\\\u4e2d\\\\u53d1\\\\u73b0\\\\u6a21\\\\u5f0f\\\\u3001\\\\u505a\\\\u51fa\\\\u9884\\\\u6d4b\\\\u548c\\\\u505a\\\\u51fa\\\\u76f8\\\\u5e94\\\\u7684\\\\u51b3\\\\u7b56\\\\u3002\\\\u673a\\\\u5668\\\\u5b66\\\\u4e60\\\\u6280\\\\u672f\\\\u88ab\\\\u5e7f\\\\u6cdb\\\\u5e94\\\\u7528\\\\u4e8e\\\\u56fe\\\\u50cf\\\\u548c\\\\u8bed\\\\u97f3\\\\u8bc6\\\\u522b\\\\u3001\\\\u81ea\\\\u7136\\\\u8bed\\\\u8a00\\\\u5904\\\\u7406\\\\u3001\\\\u63a8\\\\u8350\\\\u7cfb\\\\u7edf\\\\u3001\\\\u6570\\\\u636e\\\\u6316\\\\u6398\\\\u7b49\\\\u9886\\\\u57df\\\\uff0c\\\\u4ee5\\\\u89e3\\\\u51b3\\\\u590d\\\\u6742\\\\u95ee\\\\u9898\\\\u548c\\\\u6539\\\\u8fdb\\\\u4eba\\\\u5de5\\\\u667a\\\\u80fd\\\\u7cfb\\\\u7edf\\\\u7684\\\\u6027\\\\u80fd\\\\u3002\",\\n        \"role\": \"assistant\"\\n      }\\n    }\\n\\n\\n\\n\\n```python\\n# 查看第一个返回结果的message\\nresponse.choices[0].message[\\'content\\']\\n```\\n\\n\\n\\n\\n    \\'机器学习是一种人工智能的分支领域，它研究如何使计算机系统根据数据和经验自动改善和适应，而无需明确地进行编程。机器学习的目标是通过构建模型和算法，让计算机能够从大量数据中学习，并且可以从中发现模式、做出预测和做出相应的决策。机器学习技术被广泛应用于图像和语音识别、自然语言处理、推荐系统、数据挖掘等领域，以解决复杂问题和改进人工智能系统的性能。\\'\\n\\n\\n\\n可以说，在获取对话结果的过程中，除了ChatCompletion.create返回结果最终是保存在message属性中（Completion.create返回结果是保存在text属性中），其他方面ChatCompletion.create的返回结果和Completion.create返回结果完全一致。而文本补全模型需要输入“prompt”，输出结果是“text”；而对话模型需要输入“message”，返回也是“message”，可以说这种文本交互形式确实非常符合人类在进行聊天时的问答习惯。\\n\\n#### 2.2 ChatCompletion.create函数参数解释\\n\\n&emsp;&emsp;而关于ChatCompletion.create函数的详细参数解释，可以在官网相关页面查阅：https://platform.openai.com/docs/api-reference/chat/create 。能够发现，和Completion.create函数相比，ChatCompletion.create函数的参数结构发生了以下变化：     \\n- 用messages参数代替了prompt参数，使之更适合能够执行对话类任务；\\n- 新增functions和function_call参数，使之能够在函数内部调用其他工具的API，该功能为0613新增功能；\\n- 其他核心参数完全一致，例如temperature、top_p、max_tokens、n、presence_penalty等参数的解释和使用方法都完全一致，且这些参数具体的调整策略也完全一致，例如如果希望具备更有创造力的对话，则可以调高temperature且降低presence_penalty，而如果希望获得更加严谨的问答结果，则可以降低temperature并且提高presence_penalty取值；\\n- 剔除了best_of参数，即Chat模型不再支持从多个答案中选择一个最好的答案这一功能；\\n\\n需要注意的是，两个函数相同的参数在Ch.2的Completion.create函数参数介绍中均有详细介绍，此处不再赘述。接下来我们围绕ChatCompletion.create不同的三个参数，即messages参数、functions和function_call参数进行详细解释。\\n\\n### 3.messages参数详解\\n\\n#### 3.1 message参数结构及功能解释\\n\\n&emsp;&emsp;接下来我们来看ChatCompletion.create函数非常重要的参数——messages使用方法。总的来说，messages是一种用于描述ChatCompletion模型和用户之间通信信息的高级抽象，从表示形式上来说，一个messages是一个列表，包含多个字典，而每个字典都是一条消息，其中，一条消息由包含两个键值对（即每个字典都包含两个键值对），第一个键值对用于表示消息发送者，其中第一个Key为字符串\\'role\\'，Value为参与对话的角色名称，或者可以理解为本条消息的作者或消息发送人名称，第二个键值对表示具体消息内容，Key为字符串\\'content\\'，Value为具体的消息内容，用字符串表示。\\n\\n> 实际上，根据官网的说明，更严谨的说法是role是content的作者，而content的作者并不一定是content的发送方，发送方的角色更多是用于消息传递而非消息创作。但在实际使用过程中我们发现，ChatCompletion模型的role几乎可以完全看成是消息发送方，这么理解也会更加便于我们对消息结构的掌握和解读。\\n\\n例如上述示例中的messages就总共包含一条信息，即一个一个名为user的角色发送了一条名为\\'请问什么是机器学习？\\'的消息：\\n\\n\\n```python\\nmessages=[\\n    {\"role\": \"user\", \"content\": \"请问什么是机器学习？\"}\\n]\\n```\\n\\n而同时，返回的message结果也是一个“字典”，并且也包含了信息的发送方和具体信息内容，不难看出，此时返回的message发送方是一个名为\\'assistant\\'的角色，而具体内容则是一段关于什么是机器学习的描述：\\n\\n\\n```python\\nresponse.choices[0].message\\n```\\n\\n\\n\\n\\n    <OpenAIObject at 0x2017fa89d10> JSON: {\\n      \"content\": \"\\\\u673a\\\\u5668\\\\u5b66\\\\u4e60\\\\u662f\\\\u4e00\\\\u79cd\\\\u4eba\\\\u5de5\\\\u667a\\\\u80fd\\\\u7684\\\\u5206\\\\u652f\\\\u9886\\\\u57df\\\\uff0c\\\\u5b83\\\\u7814\\\\u7a76\\\\u5982\\\\u4f55\\\\u4f7f\\\\u8ba1\\\\u7b97\\\\u673a\\\\u7cfb\\\\u7edf\\\\u6839\\\\u636e\\\\u6570\\\\u636e\\\\u548c\\\\u7ecf\\\\u9a8c\\\\u81ea\\\\u52a8\\\\u6539\\\\u5584\\\\u548c\\\\u9002\\\\u5e94\\\\uff0c\\\\u800c\\\\u65e0\\\\u9700\\\\u660e\\\\u786e\\\\u5730\\\\u8fdb\\\\u884c\\\\u7f16\\\\u7a0b\\\\u3002\\\\u673a\\\\u5668\\\\u5b66\\\\u4e60\\\\u7684\\\\u76ee\\\\u6807\\\\u662f\\\\u901a\\\\u8fc7\\\\u6784\\\\u5efa\\\\u6a21\\\\u578b\\\\u548c\\\\u7b97\\\\u6cd5\\\\uff0c\\\\u8ba9\\\\u8ba1\\\\u7b97\\\\u673a\\\\u80fd\\\\u591f\\\\u4ece\\\\u5927\\\\u91cf\\\\u6570\\\\u636e\\\\u4e2d\\\\u5b66\\\\u4e60\\\\uff0c\\\\u5e76\\\\u4e14\\\\u53ef\\\\u4ee5\\\\u4ece\\\\u4e2d\\\\u53d1\\\\u73b0\\\\u6a21\\\\u5f0f\\\\u3001\\\\u505a\\\\u51fa\\\\u9884\\\\u6d4b\\\\u548c\\\\u505a\\\\u51fa\\\\u76f8\\\\u5e94\\\\u7684\\\\u51b3\\\\u7b56\\\\u3002\\\\u673a\\\\u5668\\\\u5b66\\\\u4e60\\\\u6280\\\\u672f\\\\u88ab\\\\u5e7f\\\\u6cdb\\\\u5e94\\\\u7528\\\\u4e8e\\\\u56fe\\\\u50cf\\\\u548c\\\\u8bed\\\\u97f3\\\\u8bc6\\\\u522b\\\\u3001\\\\u81ea\\\\u7136\\\\u8bed\\\\u8a00\\\\u5904\\\\u7406\\\\u3001\\\\u63a8\\\\u8350\\\\u7cfb\\\\u7edf\\\\u3001\\\\u6570\\\\u636e\\\\u6316\\\\u6398\\\\u7b49\\\\u9886\\\\u57df\\\\uff0c\\\\u4ee5\\\\u89e3\\\\u51b3\\\\u590d\\\\u6742\\\\u95ee\\\\u9898\\\\u548c\\\\u6539\\\\u8fdb\\\\u4eba\\\\u5de5\\\\u667a\\\\u80fd\\\\u7cfb\\\\u7edf\\\\u7684\\\\u6027\\\\u80fd\\\\u3002\",\\n      \"role\": \"assistant\"\\n    }\\n\\n\\n\\n\\n```python\\nresponse.choices[0].message[\\'content\\']\\n```\\n\\n\\n\\n\\n    \\'机器学习是一种人工智能的分支领域，它研究如何使计算机系统根据数据和经验自动改善和适应，而无需明确地进行编程。机器学习的目标是通过构建模型和算法，让计算机能够从大量数据中学习，并且可以从中发现模式、做出预测和做出相应的决策。机器学习技术被广泛应用于图像和语音识别、自然语言处理、推荐系统、数据挖掘等领域，以解决复杂问题和改进人工智能系统的性能。\\'\\n\\n\\n\\n由此不难看出，对话Chat模型的每个对话任务都是通过输入和输出message来完成的。\\n\\n#### 3.2 messages中的角色划分\\n\\n- user role和assistant role\\n\\n&emsp;&emsp;那么接下来的问题就是，在实际调用Chat模型进行对话时，messages中的role应该如何设置呢？从上述极简的对话示例中能够看出，一个最简单的对话就是我们扮演user（用户）这个角色（\\'role\\':\\'user\\'），然后在content中输入我们的问题并等待模型回答。而模型在实际回答过程中，也会扮演一个名为assistant（助手）这个角色（\\'role\\':\\'assistant\\'）进行回答，这里的user和assistant是具有明确含义的字符串，即如果一条信息的role是user，则表明这是用户向模型发送的聊天信息，相当于是Completion模型中的prompt，而如果一条信息的role是assistant，则表示这是当前模型围绕某条用户信息做出的回应，相当于是相当于是Completion模型中的text。需要注意的是，在messages参数中，我们是不能给自己或者模型自定义其他名称的。\\n\\n&emsp;&emsp;很明显，基于这样的一个定义的规则，最简单的Chat模型的调用方法就是在messages参数中设置一条role为user的参数，在content中输入聊天的内容，而模型则会根据这条用户输入给模型的消息进行回答，类似于此前我们向模型提问“请问什么是机器学习？”这种提问方式:\\n\\n\\n```python\\nresponse = openai.ChatCompletion.create(\\n  model=\"gpt-3.5-turbo\",\\n  messages=[\\n    {\"role\": \"user\", \"content\": \"请问什么是机器学习？\"}\\n  ]\\n)\\n```\\n\\n\\n```python\\nresponse.choices[0].message[\\'content\\']\\n```\\n\\n\\n\\n\\n    \\'机器学习是一种人工智能的分支，通过使用数学和统计方法来自动分析和理解数据，并使计算机能够自主学习和改进性能。它是通过从数据中学习模式和规律，而不是通过明确编程来实现任务的一种方法。机器学习可以帮助计算机系统通过从大量数据中提取规律来预测结果、进行分类、聚类、识别图像和语音、自动驾驶等。\\'\\n\\n\\n\\n不过需要注意的是，尽管一个messages可以包含多条信息，但模型只会对于最后一条用户信息进行回答，例如：\\n\\n\\n```python\\nresponse = openai.ChatCompletion.create(\\n  model=\"gpt-3.5-turbo\",\\n  messages=[\\n    {\"role\": \"user\", \"content\": \"请问什么是机器学习？\"},\\n    {\"role\": \"user\", \"content\": \"请问什么是决策树算法？\"}\\n  ]\\n)\\n```\\n\\n\\n```python\\nresponse.choices[0].message[\\'content\\']\\n```\\n\\n\\n\\n\\n    \\'决策树算法是一种用于分类和回归的机器学习算法，它基于树形结构来进行决策。决策树可以看作是一个由节点和有向边组成的树，每个节点表示一个特征属性，每条边表示一个特征属性取值或决策的结果。决策树的根节点表示最重要的特征，而叶子节点表示分类或回归结果。\\\\n\\\\n决策树算法的特点包括易于理解和解释、能够处理非线性关系、不需要对数据进行特征预处理、可以处理多输出问题等。算法的核心思想是通过反复分割数据集，使得每个子集中的样本都属于同一类别（或拥有相似的回归结果）。分割的决策依据是选择最佳的划分特征，通常使用各种不纯度指标（例如基尼系数或熵）来衡量每个特征的纯度。\\\\n\\\\n决策树算法包括很多变种和优化方法，如CART（Classification and Regression Trees）、ID3、C4.5、随机森林等。决策树算法在实际应用中广泛使用，可以用于分类问题（如垃圾邮件分类、医学诊断等）和回归问题（如房价预测、股票趋势预测等）。\\'\\n\\n\\n\\n也就是说，assistant消息和role消息是一一对应的，而且在一般情况下，assistant消息只会围绕messages参数中的最后一个role信息进行回答。\\n\\n- system role用于身份设定\\n\\n&emsp;&emsp;不过，值得一提的是，user和assistant的这种提问方式尽管足够清晰，但往往形式上不够丰富，例如在实践中人们发现，给聊天机器人进行一个身份设置，其实是非常有效的引导模型创作我们想要的结果的方法，例如如果我们希望获得一个关于“什么是机器学习？”更加严谨且丰富的答案，我们可以以“假设你是一名资深的计算机系大学教授”为模型进行身份设置，例如我们可以以如下方式向模型进行提问：\\n\\n\\n```python\\nresponse = openai.ChatCompletion.create(\\n  model=\"gpt-3.5-turbo\",\\n  messages=[\\n    {\"role\": \"user\", \"content\": \"假设你是一名资深的计算机系大学教授，请帮我回答，什么是机器学习？\"}\\n  ]\\n)\\n```\\n\\n\\n```python\\nresponse.choices[0].message[\\'content\\']\\n```\\n\\n\\n\\n\\n    \\'机器学习是一门研究如何使计算机系统通过大量数据和经验自动学习和改进性能的领域。它利用算法和数学模型，使计算机能够自动发现数据中的模式和规律，并利用这些模式来进行预测、分类、优化等任务。\\\\n\\\\n在机器学习中，计算机系统并不需要明确地编写具体规则或指令，而是通过从数据中学习，从而提高自己的性能和准确性。它依赖于大数据、统计学和计算机科学等领域的技术，包括数据预处理、特征提取、模型选择和评估等步骤。\\\\n\\\\n机器学习广泛应用于各个领域，如自然语言处理、计算机视觉、推荐系统、金融预测等。它的目标是从数据中发现隐藏的模式和知识，以提供高效的决策支持和智能化的解决方案。\\'\\n\\n\\n\\n不难看出，此时模型的回答就变得更加详细和严谨，更像一名“大学教授”的语气风格，也同时说明我们对模型进行的身份设定是切实有效的。\\n\\n&emsp;&emsp;而在ChatCompletion.create函数中，还有另外一种非常便捷的对模型进行身份设置的方法，即使用system role，即我们可以使用如下方式为模型进行“大学教授”身份设定：\\n\\n\\n```python\\nresponse = openai.ChatCompletion.create(\\n  model=\"gpt-3.5-turbo\",\\n  messages=[\\n    {\"role\": \"system\", \"content\": \"你是一名资深的计算机系大学教授\"},\\n    {\"role\": \"user\", \"content\": \"请问什么是机器学习？\"}\\n  ]\\n)\\n```\\n\\n\\n```python\\nresponse.choices[0].message[\\'content\\']\\n```\\n\\n\\n\\n\\n    \\'机器学习是一种人工智能的分支领域，它致力于研究和开发能够从数据中自动学习和改进的算法和模型。机器学习使计算机可以通过分析大量数据并自动发现数据中隐藏的模式和规律，从而使计算机能够作出预测或做出决策。\\\\n\\\\n机器学习的主要任务包括分类、回归、聚类和推荐等。分类任务是将数据分为不同的类别，回归任务是预测数据的数值，聚类任务是将相似的数据分组，推荐任务是根据用户的个人偏好为其推荐物品。\\\\n\\\\n机器学习算法可以分为监督学习、无监督学习和强化学习。监督学习是通过已标记的训练数据进行学习，无监督学习是利用未标记的数据进行学习，而强化学习则是通过与环境的交互来进行学习。\\\\n\\\\n机器学习在许多领域中都有广泛的应用，例如图像识别、语音识别、自然语言处理、金融预测和医学诊断等。通过机器学习，计算机可以从大量的数据中学习，并提供更准确、高效的解决方案。\\'\\n\\n\\n\\n&emsp;&emsp;能够看出，这里我们在原有消息之前，新增一条消息{\"role\": \"system\", \"content\": \"你是一名资深的计算机系大学教授\"}，也能起到设定模型身份的作用。而这条消息的实际含义是，以system的身份发送一条消息，消息内容为“你是一名资深的计算机系大学教授”。这里的system就是messages参数的role可以选取的第三个字符串，意为该消息为一条系统消息。相比用户消息，系统消息有以下几点需要注意，其一是系统消息的实际作用是给整个对话系统进行背景设置，不同的背景设置会极大程度影响后续对话过程中模型的输出结果，例如如果系统设置为“你是一位资深医学专家”，那么接下来系统在进行回答医学领域相关问题时则会引用大量医学术语，而如果系统设置为“你是一位资深喜剧演员”，那么接下来系统进行的回答则会更加风趣幽默：\\n\\n\\n```python\\nresponse = openai.ChatCompletion.create(\\n  model=\"gpt-3.5-turbo\",\\n  messages=[\\n    {\"role\": \"system\", \"content\": \"你是一名资深的喜剧演员\"},\\n    {\"role\": \"user\", \"content\": \"请问什么是机器学习？\"}\\n  ]\\n)\\n```\\n\\n\\n```python\\nresponse.choices[0].message[\\'content\\']\\n```\\n\\n\\n\\n\\n    \\'哈哈，这是一个有趣的问题！机器学习是一种人工智能的分支，它通过让计算机系统自动学习和改进，而无需明确的编程指令。简单来说，机器学习是让机器具备从数据中学习和预测的能力。就像我在喜剧表演中学习和改进我的技巧一样，机器学习通过分析大量的数据，找到模式和规律，从而使机器能够做出智能的决策和预测。不过相比我，机器学习更加准确和高效！话不多说，让我们继续我的喜剧表演吧！\\'\\n\\n\\n\\n&emsp;&emsp;而第二方面需要注意的则是，当messages中只包含一条system消息时，系统会围绕system进行回答，只不过此时系统的assistant的应答消息则更像是一个completion的过程，即围绕system的prompt进行进一步的文本补全：\\n\\n\\n```python\\nresponse = openai.ChatCompletion.create(\\n  model=\"gpt-3.5-turbo\",\\n  messages=[\\n    {\"role\": \"system\", \"content\": \"你是一名资深的喜剧演员\"},\\n  ]\\n)\\n```\\n\\n\\n```python\\nresponse.choices[0].message\\n```\\n\\n\\n\\n\\n    <OpenAIObject at 0x2017fa96590> JSON: {\\n      \"content\": \"\\\\u6211\\\\u4f1a\\\\u7ed9\\\\u89c2\\\\u4f17\\\\u5e26\\\\u6765\\\\u6b22\\\\u4e50\\\\u548c\\\\u5feb\\\\u4e50\\\\u7684\\\\u7b11\\\\u58f0\\\\uff01\\\\u6211\\\\u64c5\\\\u957f\\\\u5851\\\\u9020\\\\u4e30\\\\u5bcc\\\\u591a\\\\u6837\\\\u7684\\\\u89d2\\\\u8272\\\\uff0c\\\\u8fd0\\\\u7528\\\\u5938\\\\u5f20\\\\u7684\\\\u8868\\\\u6f14\\\\u6280\\\\u5de7\\\\u548c\\\\u5e7d\\\\u9ed8\\\\u7684\\\\u53f0\\\\u8bcd\\\\uff0c\\\\u8ba9\\\\u89c2\\\\u4f17\\\\u6367\\\\u8179\\\\u5927\\\\u7b11\\\\u3002\\\\u6211\\\\u559c\\\\u6b22\\\\u6311\\\\u6218\\\\u81ea\\\\u5df1\\\\uff0c\\\\u5c1d\\\\u8bd5\\\\u4e0d\\\\u540c\\\\u7684\\\\u559c\\\\u5267\\\\u98ce\\\\u683c\\\\uff0c\\\\u4f8b\\\\u5982\\\\u60c5\\\\u666f\\\\u559c\\\\u5267\\\\u3001\\\\u559c\\\\u5267\\\\u7535\\\\u5f71\\\\u3001Stand-up\\\\u559c\\\\u5267\\\\u7b49\\\\u7b49\\\\u3002\\\\u901a\\\\u8fc7\\\\u4ee4\\\\u4eba\\\\u96be\\\\u5fd8\\\\u7684\\\\u8868\\\\u6f14\\\\uff0c\\\\u6211\\\\u5e0c\\\\u671b\\\\u80fd\\\\u591f\\\\u7559\\\\u4e0b\\\\u6df1\\\\u523b\\\\u7684\\\\u5370\\\\u8c61\\\\uff0c\\\\u5e76\\\\u8ba9\\\\u89c2\\\\u4f17\\\\u5fd8\\\\u8bb0\\\\u751f\\\\u6d3b\\\\u4e2d\\\\u7684\\\\u70e6\\\\u607c\\\\uff0c\\\\u4eab\\\\u53d7\\\\u4e00\\\\u6bb5\\\\u6b22\\\\u4e50\\\\u7684\\\\u65f6\\\\u5149\\\\uff01\",\\n      \"role\": \"assistant\"\\n    }\\n\\n\\n\\n\\n```python\\nresponse.choices[0].message[\\'content\\']\\n```\\n\\n\\n\\n\\n    \\'我会给观众带来欢乐和快乐的笑声！我擅长塑造丰富多样的角色，运用夸张的表演技巧和幽默的台词，让观众捧腹大笑。我喜欢挑战自己，尝试不同的喜剧风格，例如情景喜剧、喜剧电影、Stand-up喜剧等等。通过令人难忘的表演，我希望能够留下深刻的印象，并让观众忘记生活中的烦恼，享受一段欢乐的时光！\\'\\n\\n\\n\\n\\n```python\\nresponse = openai.ChatCompletion.create(\\n  model=\"gpt-3.5-turbo\",\\n  messages=[\\n    {\"role\": \"system\", \"content\": \"你好，请问\"},\\n  ]\\n)\\n```\\n\\n\\n```python\\nresponse.choices[0].message[\\'content\\']\\n```\\n\\n\\n\\n\\n    \\'有什么可以帮助您的吗？\\'\\n\\n\\n\\n当然，借助completion过程也是可以进行提问的，例如：\\n\\n\\n```python\\nresponse = openai.ChatCompletion.create(\\n  model=\"gpt-3.5-turbo\",\\n  messages=[\\n    {\"role\": \"system\", \"content\": \"请问什么是机器学习？\"},\\n  ]\\n)\\n```\\n\\n\\n```python\\nresponse.choices[0].message[\\'content\\']\\n```\\n\\n\\n\\n\\n    \\'机器学习是一种人工智能的分支，它通过使用计算机算法和模型，让机器自动从数据中学习，并从中提取规律和模式，以做出预测和决策。它的主要目标是使机器能够从经验中学习，提高预测能力和自动化任务。机器学习在许多领域都有广泛应用，包括自然语言处理、图像识别、数据挖掘和智能推荐系统等。\\'\\n\\n\\n\\n不过这么做意义并不大，还是建议以user角色进行提问。\\n\\n&emsp;&emsp;第三方面需要注意的是，如果我们需要根据system系统信息对系统进行设置，然后再提问，那么先system消息再user消息的顺序就变得非常重要，例如还是上面的例子，还是希望以喜剧演员的身份介绍机器学习，但我们调换了system消息和user消息的顺序，那么会发现，system消息的作用就会失效：\\n\\n\\n```python\\nresponse = openai.ChatCompletion.create(\\n  model=\"gpt-3.5-turbo\",\\n  messages=[\\n    {\"role\": \"user\", \"content\": \"请问什么是机器学习？\"},\\n    {\"role\": \"system\", \"content\": \"你是一名资深的喜剧演员\"}\\n  ]\\n)\\n```\\n\\n\\n```python\\nresponse.choices[0].message[\\'content\\']\\n```\\n\\n\\n\\n\\n    \\'机器学习是一门人工智能领域的研究，旨在让计算机系统通过学习和改进经验，不需要明确的程序指导下，自动完成特定任务。它利用统计学和算法来使计算机能够从数据中学习并进行预测和决策。机器学习可以应用于各种领域，如图像识别、语音识别、自然语言处理、推荐系统等。通过训练模型，机器学习可以帮助计算机系统能够从数据中识别模式，做出预测，并根据反馈不断改进自己的表现。\\'\\n\\n\\n\\n此时会发现，模型还是能解答“请问什么是机器学习？”这个问题，但却没有正确接受“你是一名资深喜剧演员”这个设定。\\n\\n&emsp;&emsp;最后还有一点需要注意的是，根据OpenAI官网说明，截至目前，gpt-3.5系列模型仍然无法对system提供的系统消息保持长期关注，即在多轮对话中，模型极有可能逐渐忘记自己的身份设定。根据长期使用情况来看，gpt-4模型对system设置的长期关注要好于gpt-3.5系列模型。\\n\\n&emsp;&emsp;对于messages中可选的role来说，除了ueser、assistant、system之外，还有一个function role，用于表示某条消息为某函数的调用指令，function role是OpenAI 0613更新中提供的新的role选项，用于Chat模型调用外部定义函数或者工具API时使用。相关用法我们会在本小节的后半部分进行介绍。\\n\\n### 4.messages参数应用\\n\\n&emsp;&emsp;对于ChatCompletion.create函数来说，通过灵活的messages参数，能够非常便捷高效的实现诸多类型的对话需求，例如基于提示词模板的提问、Few-shot提问、基于某背景知识的提问等，接下来我们进一步介绍不同场景下messages参数的设置方法，并在这个过程进一步介绍关于messages中name的设置方法。\\n\\n&emsp;&emsp;由于我们接下来需要使用此前Ch.4中的推理问题作为示例，因此我们提前定义好四组问题的问题和答案：\\n\\n\\n```python\\nQ1 = \\'罗杰有五个网球，他又买了两盒网球，每盒有3个网球，请问他现在总共有多少个网球？\\'\\nA1 = \\'现在罗杰总共有11个网球。\\'\\n```\\n\\n\\n```python\\nQ2 = \\'食堂总共有23个苹果，如果他们用掉20个苹果，然后又买了6个苹果，请问现在食堂总共有多少个苹果？\\'\\nA2 = \\'现在食堂总共有9个苹果。\\'\\n```\\n\\n\\n```python\\nQ3 = \\'杂耍者可以杂耍16个球。其中一半的球是高尔夫球，其中一半的高尔夫球是蓝色的。请问总共有多少个蓝色高尔夫球？\\'\\nA3 = \\'现在总共有4个蓝色高尔夫球。\\'\\n```\\n\\n\\n```python\\nQ4 = \\'艾米需要4分钟才能爬到滑梯顶部，她花了1分钟才滑下来，水滑梯将在15分钟后关闭，请问在关闭之前她能滑多少次？\\'\\nA4 = \\'关闭之前艾米能滑3次。\\'\\n```\\n\\n> 这里需要注意的是，gpt-3.5在解决推理问题上同样展示出了涌现能力——即gpt-3.5是基于对话语料进行的微调，但却展示出了比text-davinci-003更强大的推理能力，此前的四个推理问题对于gpt-3.5来说，除了最后一个问题不一定能得出正确答案外，其他问题均能在不进行额外提示的情况下进行很好的回答。而经过测试，gpt-4模型能够非常好的回答第四个推理问题。但需要注意的是，这并不代表此前的CoT和LtM技术就不再重要，面对超出模型原生能力的更加复杂的推理问题（如SCAN数据集的命令解释问题），仍然还是需要使用这些提示工程技术。当然，本节的重点是介绍messages参数设置技巧，更多的关于Chat模型的实战应用详见下一小节。\\n\\n- 借助多轮user-assistant消息进行few-shot\\n\\n&emsp;&emsp;如果想在Chat模型中进行Few-shot，最好的办法就是在messages中设置多轮user-assistant消息，这里我们还是以Ch.4中的推理问题为例，尝试在Chat模型中进行推理并进行Few-shot，这里我们尝试以第一个问题的问题和答案作为提示示例，引导模型解答第二个问题，则可以按照如下方式设置messages：\\n\\n\\n```python\\nresponse = openai.ChatCompletion.create(\\n  model=\"gpt-3.5-turbo\",\\n  messages=[\\n    {\"role\": \"user\", \"content\": Q1},\\n    {\"role\": \"assistant\", \"content\": A1},\\n    {\"role\": \"user\", \"content\": Q2}\\n  ]\\n)\\n```\\n\\n\\n```python\\nresponse.choices[0].message[\\'content\\']\\n```\\n\\n\\n\\n\\n    \\'现在食堂总共有9个苹果。\\'\\n\\n\\n\\n而相比单独进行Q2的提问，经过Few-shot的提示回答的结果，会更加接近A1结果的表示格式：\\n\\n\\n```python\\nresponse = openai.ChatCompletion.create(\\n  model=\"gpt-3.5-turbo\",\\n  messages=[\\n    {\"role\": \"user\", \"content\": Q2}\\n  ]\\n)\\n```\\n\\n\\n```python\\nresponse.choices[0].message[\\'content\\']\\n```\\n\\n\\n\\n\\n    \\'食堂原本有23个苹果，用掉了20个，剩下3个苹果。\\\\n然后又买了6个苹果，所以现在食堂总共有3 + 6 = 9个苹果。\\'\\n\\n\\n\\n\\n```python\\nA1\\n```\\n\\n\\n\\n\\n    \\'现在罗杰总共有11个网球。\\'\\n\\n\\n\\n&emsp;&emsp;在这个示例中，我们能够看出其实assistant消息也是可以自定义的，用于给模型提供回答的范本。并且由此可见messages参数具体呈现形式可以非常多样，不仅可以按照system-user的形式规定回答风格，而且还可以按照user-assistant-user-assistant...形式来进行Few-shot。这其实也是得益于messages高度灵活的参数构成形式——即由多条注明消息源的消息构成。messages中具体每条消息的内容以及消息序列构成形式上，有非常大的调整的空间。\\n\\n- 借助system role进行Few-shot\\n\\n&emsp;&emsp;当然，除了可以借助多轮user和assistant消息来进行Few-shot外，我们还可以把提示示例写进一条system信息中，作为当前问答的背景信息，例如：\\n\\n\\n```python\\nresponse = openai.ChatCompletion.create(\\n  model=\"gpt-3.5-turbo\",\\n  messages=[\\n    {\"role\": \"system\", \"content\": \\'Q: \\' + Q1 + \\'A: \\' + A1},\\n    {\"role\": \"user\", \"content\": \\'Q: \\' + Q2 }\\n  ]\\n)\\n```\\n\\n\\n```python\\nresponse.choices[0].message[\\'content\\']\\n```\\n\\n\\n\\n\\n    \\'A: 现在食堂总共有9个苹果。\\'\\n\\n\\n\\n\\n```python\\n\\'Q: \\' + Q1 + \\'A: \\' + A1\\n```\\n\\n\\n\\n\\n    \\'Q: 罗杰有五个网球，他又买了两盒网球，每盒有3个网球，请问他现在总共有多少个网球？A: 现在罗杰总共有11个网球。\\'\\n\\n\\n\\n\\n```python\\n\\'Q: \\' + Q2 \\n```\\n\\n\\n\\n\\n    \\'Q: 食堂总共有23个苹果，如果他们用掉20个苹果，然后又买了6个苹果，请问现在食堂总共有多少个苹果？\\'\\n\\n\\n\\n唯一需要注意的是，此时需要在系统消息中通过Q和A的方式注明问题和回答的内容，并且在提问时添加字符串Q，便于模型理解后续的回答需要按照system中的A的方式进行回答。\\n\\n&emsp;&emsp;当然，这种system的设置方式还是会非常类似于prompt编写方式。那么，有没有更加简单的、借助system消息、不用单独设置Q和A的方式来完成Few-shot呢？这里有一种更为简单的方法，即设置两条system消息，此时模型会默认这两条system消息就是一次user-assistant对话消息，即可以按照如下方式完成Few-shot：\\n\\n\\n```python\\nresponse = openai.ChatCompletion.create(\\n  model=\"gpt-3.5-turbo\",\\n  messages=[\\n    {\"role\": \"system\", \"content\": Q1},\\n    {\"role\": \"system\", \"content\": A1},\\n    {\"role\": \"user\", \"content\": Q2}\\n  ]\\n)\\n```\\n\\n\\n```python\\nresponse.choices[0].message[\\'content\\']\\n```\\n\\n\\n\\n\\n    \\'现在食堂总共有9个苹果。\\'\\n\\n\\n\\n不过这种代码形式可读性并不强，如希望通过多条system消息来模拟user-assistant多轮对话消息，则最好在system消息中添加一组额外的Key-value，相当于给这条消息额外进行备注，其中Key需要输入字符串name，而value则需要输入有助于理解这条消息定位的备注信息，例如：\\n\\n\\n```python\\nresponse = openai.ChatCompletion.create(\\n  model=\"gpt-3.5-turbo\",\\n  messages=[\\n    {\"role\": \"system\", \"name\":\"example_user\", \"content\": Q1},\\n    {\"role\": \"system\", \"name\":\"example_assistant\", \"content\": A1},\\n    {\"role\": \"user\", \"content\": Q2}\\n  ]\\n)\\n```\\n\\n\\n```python\\nresponse.choices[0].message[\\'content\\']\\n```\\n\\n\\n\\n\\n    \\'现在食堂总共有9个苹果。\\'\\n\\n\\n\\n其中，前两条system消息分别输入了\"name\":\"example_user\"和\"name\":\"example_assistant\"，表示这两条消息中第一条消息用于模拟用户消息，第二条消息用于模拟助手消息。不过需要注意的是，当role为user、assistant或system时，messages参数中的字典的name参数是可选参数，且并无实际作用，并不会对模型的输出结果造成影响，name只用于标识特定的消息或对话轮次，相当于是增强代码可读性的。在很多多轮对话场景中，我们可以通过设置name参数来更好地组织和跟踪对话的不同部分。而需要注意的是，若role为function，则name参数就是必选参数，相关内容我们会在介绍function role时进行介绍。\\n\\n- 借助system role输入提示模板\\n\\n&emsp;&emsp;即然system消息能够作为背景设定的基本消息并对后续的问答消息造成影响，那么很容易想到的system消息的一个应用场景就是借助system role输入提示模板，例如在Ch.4中曾介绍到，为了更好的提高模型推理能力，我们可以在每个prompt中加入一句“请一步步推理并得出结论”进而实现Zero-shot-CoT。而在Chat模型中，这种prompt模板信息是非常适合通过system role进行输入的，例如围绕第四个推理问题，我们可以通过输入一条内容为“请一步步推理并得出结论”的系统信息，来引导模型完成Zero-shot-CoT：\\n\\n\\n```python\\nprompt_temp_cot = \\'请一步步思考并解决问题\\'\\n```\\n\\n\\n```python\\nresponse = openai.ChatCompletion.create(\\n  model=\"gpt-3.5-turbo\",\\n  messages=[\\n    {\"role\": \"system\", \"content\": prompt_temp_cot},\\n    {\"role\": \"user\", \"content\": Q1}\\n  ]\\n)\\n```\\n\\n\\n```python\\nresponse.choices[0].message[\\'content\\']\\n```\\n\\n\\n\\n\\n    \\'罗杰原本有5个网球\\\\n他又买了两盒网球，每盒有3个，所以一共买了2盒 × 3个/盒 = 6个网球\\\\n总共的网球数量为5个 + 6个 = 11个网球\\'\\n\\n\\n\\n能够看出，模型确实开始进行了CoT推导。接下来我们测试第四个推理问题、也是最复杂的一个推理问题：\\n\\n\\n```python\\nresponse = openai.ChatCompletion.create(\\n  model=\"gpt-3.5-turbo\",\\n  messages=[\\n    {\"role\": \"system\", \"content\": prompt_temp_cot},\\n    {\"role\": \"user\", \"content\": Q4}\\n  ]\\n)\\n```\\n\\n\\n```python\\nresponse.choices[0].message[\\'content\\']\\n```\\n\\n\\n\\n\\n    \\'首先，我们需要弄清楚在15分钟内，艾米能够滑下来多少次。\\\\n\\\\n艾米每次从滑梯顶部滑下来需要1分钟，所以在15分钟内，她最多可以滑下来15次。\\\\n\\\\n然后，我们需要确定艾米每次滑下来后需要多少时间才能再次爬到滑梯顶部。\\\\n\\\\n艾米每次滑下来耗时1分钟，所以她需要再花4分钟才能爬到滑梯顶部。所以总共耗时为1分钟下滑时间加上4分钟爬升时间，即为5分钟。\\\\n\\\\n最后，我们可以计算出在15分钟内，艾米可以滑多少次。\\\\n\\\\n15分钟总共有多少个5分钟？答案是15/5=3个。\\\\n\\\\n艾米每次滑下来需要1分钟，所以在15分钟内，她可以滑3次。\\\\n\\\\n因此，在关闭之前，艾米可以滑3次。\\'\\n\\n\\n\\n能够看出发现在Zero-shot-CoT的情况下，gpt-3.5模型能够推导得出第四个问题的正确答案，但过程有点绕。\\n\\n&emsp;&emsp;接下来我们测试LtM提示法：\\n\\n\\n```python\\nprompt_temp_ltm = \\'为了解决当前这个问题，请列举我们先要解决的问题，并逐步解决原问题。\\'\\n```\\n\\n\\n```python\\nresponse = openai.ChatCompletion.create(\\n  model=\"gpt-3.5-turbo\",\\n  messages=[\\n    {\"role\": \"system\", \"content\": prompt_temp_ltm},\\n    {\"role\": \"user\", \"content\": Q1}\\n  ]\\n)\\n```\\n\\n\\n```python\\nresponse.choices[0].message[\\'content\\']\\n```\\n\\n\\n\\n\\n    \\'先要解决的问题：\\\\n1. 罗杰原来有五个网球，他买了两盒网球，每盒有三个网球，我们需要计算他购买的网球数量。\\\\n\\\\n逐步解决：\\\\n1. 罗杰原来有五个网球。\\\\n2. 他买了两盒网球，每盒有三个网球。两盒网球总共有 2 * 3 = 6 个网球。\\\\n3. 罗杰原来有的五个网球加上购买的六个网球，总共有 5 + 6 = 11 个网球。 \\\\n\\\\n所以罗杰现在总共有 11 个网球。\\'\\n\\n\\n\\n能够发现模型确实能够按照提示模板进行逐步问题解决，并且和text-davinci-003模型类似，都能够一次性解决前置问题以及原问题。\\n\\n&emsp;&emsp;接下来继续测试第四个问题：\\n\\n\\n```python\\nresponse = openai.ChatCompletion.create(\\n  model=\"gpt-3.5-turbo\",\\n  messages=[\\n    {\"role\": \"system\", \"content\": prompt_temp_ltm},\\n    {\"role\": \"user\", \"content\": Q4}\\n  ]\\n)\\n```\\n\\n\\n```python\\nresponse.choices[0].message[\\'content\\']\\n```\\n\\n\\n\\n\\n    \\'要解决这个问题，我们需要考虑以下几个问题并逐步解决：\\\\n\\\\n1. 每次滑下来的时间是多少？\\\\n2. 在15分钟之内能滑下来多少次？\\\\n3. 是否需要考虑滑下来后到达滑梯顶部需要的时间？\\\\n\\\\n解决上述问题后，我们可以得到在关闭之前艾米能滑的次数。现在我们逐个解决这些问题：\\\\n\\\\n1. 每次滑下来的时间是多少？\\\\n已知艾米花了1分钟才滑下来，所以每次滑下来的时间是1分钟。\\\\n\\\\n2. 在15分钟之内能滑下来多少次？\\\\n在15分钟之内，每次滑下来的时间是1分钟，所以艾米在15分钟之内能滑的次数是15/1=15次。\\\\n\\\\n3. 是否需要考虑滑下来后到达滑梯顶部需要的时间？\\\\n根据题目描述，我们知道艾米需要4分钟才能爬到滑梯顶部。如果考虑滑下来后再爬上去的时间，每次滑梯的周期是5分钟（1分钟滑下来+4分钟爬上去）。\\\\n\\\\n所以，在15分钟之内，艾米能滑的次数是15/5=3次。\\\\n\\\\n所以，在关闭之前艾米能滑3次。\\'\\n\\n\\n\\n能够发现，ltm提示方法对gpt-3.5这类Chat模型仍然有效。\\n\\n---\\n\\n- gpt-4性能测试\\n\\n&emsp;&emsp;相比gpt-3.5复杂且不稳定的推导过程，gpt-4模型在相同提示策略下，会表现出更强大的推理性能。例如，同样是围绕第四个问题，对gpt-4模型进行CoT和LtM提示结果如下：\\n\\n\\n```python\\nresponse = openai.ChatCompletion.create(\\n  model=\"gpt-4-0613\",\\n  messages=[\\n    {\"role\": \"system\", \"content\": prompt_temp_cot},\\n    {\"role\": \"user\", \"content\": Q4}\\n  ]\\n)\\n```\\n\\n\\n```python\\nresponse.choices[0].message[\\'content\\']\\n```\\n\\n\\n\\n\\n    \\'第一步，首先需要确定艾米完成一个滑梯运动需要的总时间，即爬到滑梯顶部的时间与滑下来的时间总和。在此问题中，艾米需要4分钟爬到滑梯顶部，1分钟滑下来。总共需要5分钟。\\\\n\\\\n第二步，然后我们需要计算在水滑梯关闭前，艾米可以完成多少次滑梯运动。我们已知水滑梯将在15分钟后关闭，因此我们将15分钟除以每次滑梯运动所需要的时间，得到她可以滑的次数。\\\\n\\\\n计算为：15分钟 ÷ 5分钟/次 = 3次\\\\n\\\\n所以，在水滑梯关闭之前，艾米可以滑3次。\\'\\n\\n\\n\\n\\n```python\\nresponse = openai.ChatCompletion.create(\\n  model=\"gpt-4-0613\",\\n  messages=[\\n    {\"role\": \"system\", \"content\": prompt_temp_ltm},\\n    {\"role\": \"user\", \"content\": Q4}\\n  ]\\n)\\n```\\n\\n\\n```python\\nresponse.choices[0].message[\\'content\\']\\n```\\n\\n\\n\\n\\n    \\'要解决这个问题，我们需要首先解决以下几个子问题：\\\\n\\\\n1. 确定艾米每次滑梯需要的总时间，即爬到滑梯顶部和滑下来的时间总和。\\\\n2. 确定在水滑梯关闭前，艾米有多少时间可以滑梯。\\\\n3. 使用总时间除以每次滑梯所需的时间。\\\\n\\\\n解决方案如下：\\\\n\\\\n1. 每次滑梯艾米需要的总时间是4分钟+1分钟=5分钟。\\\\n2. 水滑梯将在15分钟后关闭，所以艾米有15分钟的时间可以滑梯。\\\\n3. 艾米能滑的次数=总时间/每次滑梯所需的时间=15分钟/5分钟=3次。\\\\n\\\\n所以，艾米在水滑梯关闭前能滑3次。\\'\\n\\n\\n\\n能够看出，gpt-4模型展示出的推理性能要强大很多。当然，除了推理能力外，gpt-4各方面性能都属于目前大模型领域的顶流。\\n\\n---\\n\\n- 借助system role设置聊天背景信息\\n\\n&emsp;&emsp;除了可以借助system消息非常便捷的进行提示模板的设计之外，还有一个非常常见的system role的使用方法，就是借助system消息进行聊天背景信息的设定，很多时候我们可以在system消息中输入一段长文本，这段长文本将在聊天开始之前输入到系统中，而在之后的聊天中，即可让assistant围绕这个长文本进行回答，这是一种最简单的实现大语言模型围绕本地知识库进行问答的方法。\\n\\n&emsp;&emsp;这里我们在system消息中输入一段关于虚拟人物“陈明”的个人简介，而在之后的提问中，user和assistant将可以自由的围绕这段输入的背景信息进行问答：\\n\\n\\n```python\\ntext = \\'陈明，男，1973年7月15日出生于中国福建省厦门市。\\\\\\n        1991年毕业于厦门大学电子科学与技术系，继而于1998年在北京大学获得信息技术博士学位。\\\\\\n        毕业后的陈明在硅谷的一家著名科技公司工作了五年，专注于人工智能和机器学习的研发。\\'\\n```\\n\\n\\n```python\\nresponse = openai.ChatCompletion.create(\\n  model=\"gpt-3.5-turbo\",\\n  messages=[\\n    {\"role\": \"system\", \"content\": text},\\n    {\"role\": \"user\", \"content\": \\'请问陈明是那一年出生？\\'}\\n  ]\\n)\\n```\\n\\n\\n```python\\nresponse.choices[0].message[\\'content\\']\\n```\\n\\n\\n\\n\\n    \\'陈明于1973年出生。\\'\\n\\n\\n\\n能够看出，这段背景背景信息能够被模型学习并以此进行特定问题的回答。这其实就是一种非常简单的围绕本地知识进行问答的实现形式，不过需要注意的是，system role输入的信息也算是输入给模型的信息，因此受限于大语言模型的最大输入信息长度，单独借助system role在ChatCompletion.create函数中输入背景信息并不能真正意义上实现高度定制化、超大规模文本的本地知识库问答。但是，如果围绕着超大规模本地文本知识库先进行基于滑动窗口的文本切分，以确保切分后的小文本段落满足Max tokens要求，并且配合Embedding过程进行user问题和短文本的实时匹配，再把每个user问题匹配的关联度最高的文本以system消息的形式输入到模型中，再进行回答，则可以非常高效并且准确的实现本地知识库问答。而在这个过程中，借助system role进行背景文字的输入就非常基本的技术手段。\\n\\n> 课程中将详细介绍上述本地知识库问答的高效实现方法，相关内容将在Embedding模型内容结束后进行介绍\\n\\n- 借助.append方法进行多轮对话\\n\\n&emsp;&emsp;最后，除了上述通过内部参数修改来实现不同功能外，messages参数的另一个重要应用是借助append方法来高效实现多轮对话。不同于Completion模型需要将历史问答都拼接为一个字符串并输入到新的prompt中来实现历史消息的输入，对于Chat模型来说，我们只需要将模型返回的message消息+用户新的提问message拼接到模型的messages参数中，并再次向模型进行提问，即可非常便捷的实现多轮对话。\\n\\n首先我们可以使用to_dict()方法将模型返回的message信息转化为字典类型：\\n\\n\\n```python\\nresponse.choices[0].message\\n```\\n\\n\\n\\n\\n    <OpenAIObject at 0x1f0e62fc4f0> JSON: {\\n      \"content\": \"\\\\u9648\\\\u660e\\\\u4e8e1973\\\\u5e74\\\\u51fa\\\\u751f\\\\u3002\",\\n      \"role\": \"assistant\"\\n    }\\n\\n\\n\\n\\n```python\\ntype(response.choices[0].message)\\n```\\n\\n\\n\\n\\n    openai.openai_object.OpenAIObject\\n\\n\\n\\n\\n```python\\nresponse.choices[0].message.to_dict()\\n```\\n\\n\\n\\n\\n    {\\'role\\': \\'assistant\\', \\'content\\': \\'陈明于1973年出生。\\'}\\n\\n\\n\\n然后单独设置messages参数，并将此前的问题+答案进行拼接：\\n\\n\\n```python\\nmessages=[\\n    {\"role\": \"system\", \"content\": text},\\n    {\"role\": \"user\", \"content\": \\'请问陈明是那一年出生？\\'}\\n]\\n```\\n\\n\\n```python\\nmessages.append(response.choices[0].message.to_dict())\\n```\\n\\n\\n```python\\nmessages\\n```\\n\\n\\n\\n\\n    [{\\'role\\': \\'system\\',\\n      \\'content\\': \\'陈明，男，1973年7月15日出生于中国福建省厦门市。        1991年毕业于厦门大学电子科学与技术系，继而于1998年在北京大学获得信息技术博士学位。        毕业后的陈明在硅谷的一家著名科技公司工作了五年，专注于人工智能和机器学习的研发。\\'},\\n     {\\'role\\': \\'user\\', \\'content\\': \\'请问陈明是那一年出生？\\'},\\n     {\\'role\\': \\'assistant\\', \\'content\\': \\'陈明于1973年出生。\\'}]\\n\\n\\n\\n此时messages参数就包含了最开始的问题+问题答案。接下来我们在messages消息中添加下一个问题：\\n\\n\\n```python\\nmessages.append({\\'role\\': \\'user\\', \\'content\\': \\'请问我刚才的问题是？\\'})\\n```\\n\\n\\n```python\\nmessages\\n```\\n\\n\\n\\n\\n    [{\\'role\\': \\'system\\',\\n      \\'content\\': \\'陈明，男，1973年7月15日出生于中国福建省厦门市。        1991年毕业于厦门大学电子科学与技术系，继而于1998年在北京大学获得信息技术博士学位。        毕业后的陈明在硅谷的一家著名科技公司工作了五年，专注于人工智能和机器学习的研发。\\'},\\n     {\\'role\\': \\'user\\', \\'content\\': \\'请问陈明是那一年出生？\\'},\\n     {\\'role\\': \\'assistant\\', \\'content\\': \\'陈明于1973年出生。\\'},\\n     {\\'role\\': \\'user\\', \\'content\\': \\'请问我刚才的问题是？\\'}]\\n\\n\\n\\n接下来再次调用模型，并输入messages作为参数，此时模型将同时结合此前的所有消息，并围绕最后一个user信息进行回答：\\n\\n\\n```python\\nresponse = openai.ChatCompletion.create(\\n  model=\"gpt-3.5-turbo\",\\n  messages=messages\\n)\\n```\\n\\n\\n```python\\nresponse.choices[0].message[\\'content\\']\\n```\\n\\n\\n\\n\\n    \\'您刚才的问题是“请问陈明是那一年出生？”\\'\\n\\n\\n\\n能够发现，相比Completions模型，Chat类模型能够更加便捷的实现多轮对话。\\n\\n- 代码补全\\n\\n\\n```python\\nresponse = openai.ChatCompletion.create(\\n  model=\"gpt-3.5-turbo\",\\n  messages=[\\n    {\"role\": \"system\", \"content\": \\'请将用户提出的python代码进行补全。\\'},\\n    {\"role\": \"user\", \"content\": \\'def fibonacci(num):\\'}\\n  ]\\n)\\n```\\n\\n\\n```python\\nresponse.choices[0].message[\\'content\\']\\n```\\n\\n\\n\\n\\n    \\'def fibonacci(num):\\\\n    if num <= 0:\\\\n        return []\\\\n    elif num == 1:\\\\n        return [0]\\\\n    elif num == 2:\\\\n        return [0, 1]\\\\n    else:\\\\n        fib = [0, 1]\\\\n        for i in range(2, num):\\\\n            fib.append(fib[i-1] + fib[i-2])\\\\n        return fib\\'\\n\\n\\n\\n\\n```python\\ndef fibonacci(num):\\n    if num <= 0:\\n        return []\\n    elif num == 1:\\n        return [0]\\n    elif num == 2:\\n        return [0, 1]\\n    else:\\n        fib = [0, 1]\\n        for i in range(2, num):\\n            fib.append(fib[i-1] + fib[i-2])\\n        return fib\\n```\\n\\n\\n```python\\nfibonacci(5)\\n```\\n\\n\\n\\n\\n    [0, 1, 1, 2, 3]\\n\\n\\n\\n\\n```python\\nresponse = openai.ChatCompletion.create(\\n  model=\"gpt-3.5-turbo\",\\n  messages=[\\n    {\"role\": \"user\", \"content\": \\'什么是斐波那契数列？\\'}\\n  ]\\n)\\nresponse.choices[0].message[\\'content\\']\\n```\\n\\n\\n\\n\\n    \\'斐波那契数列是一个数列，其中每个数字都是前面两个数字的和。数列的前两个数字通常定义为0和1。因此，斐波那契数列的开始部分是：0，1，1，2，3，5，8，13，21，34，55，89，144，... 以此类推。斐波那契数列在数学和计算机科学中起着重要的作用，被广泛应用于算法设计、动态规划、递归等领域。\\'\\n\\n\\n\\n### 5.手动实操项目：借助gpt-4完成知识总结与代码编写\\n\\n\\n```python\\n\\n```\\n\\n\\n```python\\n\\n```\\n\\n\\n```python\\n\\n```\\n\\n\\n```python\\n\\n```\\n\\n- 代码补全\\n\\n\\n```python\\n\\n```\\n\\n\\n```python\\n\\n```\\n\\n&emsp;&emsp;接下来，我们仿造Ch.2中多轮对话\\n\\ntokens计算数量\\n\\n\\n```python\\n\\n```\\n\\n\\n```python\\n\\n```\\n\\n\\n```python\\n\\n```\\n\\n\\n```python\\nmessages.append(response.choices[0].message)\\n```\\n\\n\\n```python\\nmessages\\n```\\n\\n\\n\\n\\n    [{\\'role\\': \\'system\\',\\n      \\'content\\': \\'陈明，男，1973年7月15日出生于中国福建省厦门市。        1991年毕业于厦门大学电子科学与技术系，继而于1998年在北京大学获得信息技术博士学位。        毕业后的陈明在硅谷的一家著名科技公司工作了五年，专注于人工智能和机器学习的研发。\\'},\\n     {\\'role\\': \\'user\\', \\'content\\': \\'请问陈明是那一年出生？\\'},\\n     <OpenAIObject at 0x2017fa7cc70> JSON: {\\n       \"content\": \"\\\\u9648\\\\u660e\\\\u4e8e1973\\\\u5e74\\\\u51fa\\\\u751f\\\\u3002\",\\n       \"role\": \"assistant\"\\n     },\\n     {\\'role\\': \\'user\\', \\'content\\': \\'请问陈明博士毕业于哪所院校？\\'},\\n     <OpenAIObject at 0x2017fa7c9a0> JSON: {\\n       \"content\": \"\\\\u9648\\\\u660e\\\\u535a\\\\u58eb\\\\u4e8e\\\\u5317\\\\u4eac\\\\u5927\\\\u5b66\\\\u83b7\\\\u5f97\\\\u5b66\\\\u4f4d\\\\u3002\",\\n       \"role\": \"assistant\"\\n     }]\\n\\n\\n\\n\\n```python\\nmessages.append({\\'role\\': \\'user\\', \\'content\\': \\'请问我的上一个问题是什么？\\'})\\n```\\n\\n\\n```python\\nresponse = openai.ChatCompletion.create(\\n  model=\"gpt-3.5-turbo\",\\n  messages=messages\\n)\\n```\\n\\n\\n```python\\nresponse.choices[0].message[\\'content\\']\\n```\\n\\n\\n\\n\\n    \\'您上一个问题是\"请问陈明博士毕业于哪所院校？\"\\'\\n\\n\\n\\n\\n```python\\n\\n```\\n\\n\\n```python\\n\\n```\\n\\n\\n```python\\nmessages.append(response.choices[0].message)\\n```\\n\\n\\n```python\\nmessages\\n```\\n\\n\\n\\n\\n    [{\\'role\\': \\'system\\',\\n      \\'content\\': \\'陈明，男，1973年7月15日出生于中国福建省厦门市。        1991年毕业于厦门大学电子科学与技术系，继而于1998年在北京大学获得信息技术博士学位。        毕业后的陈明在硅谷的一家著名科技公司工作了五年，专注于人工智能和机器学习的研发。\\'},\\n     {\\'role\\': \\'user\\', \\'content\\': \\'请问陈明是那一年出生？\\'},\\n     <OpenAIObject at 0x2017fa7cc70> JSON: {\\n       \"content\": \"\\\\u9648\\\\u660e\\\\u4e8e1973\\\\u5e74\\\\u51fa\\\\u751f\\\\u3002\",\\n       \"role\": \"assistant\"\\n     },\\n     {\\'role\\': \\'user\\', \\'content\\': \\'请问陈明博士毕业于哪所院校？\\'},\\n     <OpenAIObject at 0x2017fa7c9a0> JSON: {\\n       \"content\": \"\\\\u9648\\\\u660e\\\\u535a\\\\u58eb\\\\u4e8e\\\\u5317\\\\u4eac\\\\u5927\\\\u5b66\\\\u83b7\\\\u5f97\\\\u5b66\\\\u4f4d\\\\u3002\",\\n       \"role\": \"assistant\"\\n     }]\\n\\n\\n\\n\\n```python\\nmessages.append({\\'role\\': \\'user\\', \\'content\\': \\'请问我的上一个问题的答案是什么？\\'})\\n```\\n\\n\\n```python\\nresponse = openai.ChatCompletion.create(\\n  model=\"gpt-3.5-turbo\",\\n  messages=messages\\n)\\n```\\n\\n\\n```python\\nresponse.choices[0].message[\\'content\\']\\n```\\n\\n\\n\\n\\n    \\'你上一个问题的答案是 \"陈明博士毕业于北京大学\"。\\'\\n\\n\\n\\n\\n```python\\nresponse.choices[0].message.to_dict()\\n```\\n\\n\\n\\n\\n    {\\'role\\': \\'assistant\\', \\'content\\': \\'你上一个问题的答案是 \"陈明博士毕业于北京大学\"。\\'}\\n\\n\\n\\n\\n```python\\n\\n```\\n\\n\\n```python\\n\\n```\\n\\n&emsp;&emsp;在这条消息中，我们以\\n\\n\\n```python\\n\\n```\\n\\n> 其实所有的函数参数设置，也都是根据技术应用发展变化而不断调整，例如丰富的提示工程方法的诞生，催生了system role，而以Auto-GPT和LangChain为代表的更加自动化的大模型应用项目，则催生了function role。更多关于function role的内容稍后会进行介绍。\\n\\n\\n```python\\n\\n```\\n\\n\\n```python\\n\\n```\\n\\n\\n```python\\n\\n```\\n\\n\\n```python\\n\\n```\\n\\n首先需要说明的是，每一条message中的Key：\\'content\\'对应的Value（消息内容）都是自定义的或者模型生成的，而Key：\\'role\\'对应的Value（消息发放角色）则只能够在字符串\\'system\\'（系统）、\\'user\\'（用户）、\\'assistant\\'（助手）和\\'function\\'（函数）四个选项中进行选择。关于function角色的相关功能稍后介绍，此处先重点介绍关于\\'system\\'（系统）、\\'user\\'（用户）、\\'assistant\\'（助手）三个角色设置方法。\\n\\n\\n```python\\n\\n```\\n\\n> 注意，\\'function\\'这个role的选项也是在OpenAI的6月13号更新中新加入的功能选项，专门用于Chat模型调用函数时为函数传输的信息注明身份。\\n\\n&emsp;&emsp;需要重点注意的是，不同消息发放角色其实也代表着消息性质（或消息作用），例如，如果一条消息的role（消息的发送方）为\\'system\\'，则表示这是一条系统消息，而系统消息的实际作用是给整个对话系统进行背景设置，例如如果系统消息的内容为“You are a helpful assistant.”，那么就相当于是将“A helpful assistant”作为系统基本设置，即让模型扮演好一个“有力的助手”这一角色、或者以“有力的助手”这一身份完成后续的问答，注意，这种对聊天系统的身份设置也是可以自定义的，例如你可以将系统身份设置为“你是一位资深医学专家”，那么接下来系统在进行回答医学领域相关问题时则会引用大量医学术语，而如果系统设置为“你是一位资深喜剧演员”，那么接下来系统进行的回答则会更加风趣幽默。\\n\\n> 由于系统消息本身是作用于系统本身，所以也可以理解为系统消息的接收者也是系统，即系统是系统消息的发送方，同时也是接收方。\\n\\n> 另外，需要注意的是，尽管系统消息的作者（role）是系统，但实际上，系统消息是需要由用户来自定义的。\\n\\n&emsp;&emsp;相比之下，\\'user\\'（用户）、\\'assistant\\'（助手）的概念就会简单很多，如果一条消息的role是user，则代表这条消息是用户发送的信息，即我们和大模型进行对话时我们发送给模型的消息，相当于是Completion模型中的prompt（当然是更加符合对话风格的prompt），而如果某条消息的role是assistant，则代表这条消息是模型返回给我们的消息，相当于是Completion中的text。需要注意的是，在一个正常的问答流程中，在不考虑role为function的情况下，每条用户发送的消息都会有一条对应的系统返回的消息，且用户只能向助手进行提问，用户并不能直接和系统进行互动。\\n\\n\\n```python\\ncompletion = openai.ChatCompletion.create(\\n  model=\"gpt-3.5-turbo\",\\n  messages=[\\n    {\"role\": \"user\", \"content\": \"Hello!\"}\\n  ]\\n)\\n\\nprint(completion.choices[0].message)\\n```\\n\\n    {\\n      \"content\": \"Hi there! How can I assist you today?\",\\n      \"role\": \"assistant\"\\n    }\\n    \\n\\n\\n```python\\ncompletion = openai.ChatCompletion.create(\\n  model=\"gpt-3.5-turbo\",\\n  messages=[\\n    {\"role\": \"user\", \"content\": \"请问什么是机器学习？\"}\\n  ]\\n)\\n\\nprint(completion.choices[0].message)\\n```\\n\\n    {\\n      \"content\": \"\\\\u673a\\\\u5668\\\\u5b66\\\\u4e60\\\\u662f\\\\u4e00\\\\u79cd\\\\u4eba\\\\u5de5\\\\u667a\\\\u80fd\\\\u6280\\\\u672f\\\\uff0c\\\\u901a\\\\u8fc7\\\\u4ece\\\\u7ecf\\\\u9a8c\\\\u4e2d\\\\u5b66\\\\u4e60\\\\u548c\\\\u6539\\\\u5584\\\\u81ea\\\\u8eab\\\\u7684\\\\u80fd\\\\u529b\\\\uff0c\\\\u4f7f\\\\u8ba1\\\\u7b97\\\\u673a\\\\u80fd\\\\u591f\\\\u4ece\\\\u6570\\\\u636e\\\\u4e2d\\\\u5b66\\\\u4e60\\\\uff0c\\\\u8bc6\\\\u522b\\\\u6a21\\\\u5f0f\\\\u548c\\\\u8fdb\\\\u884c\\\\u9884\\\\u6d4b\\\\uff0c\\\\u800c\\\\u65e0\\\\u9700\\\\u660e\\\\u786e\\\\u7684\\\\u7f16\\\\u7a0b\\\\u6307\\\\u4ee4\\\\u3002\\\\u673a\\\\u5668\\\\u5b66\\\\u4e60\\\\u91c7\\\\u7528\\\\u7b97\\\\u6cd5\\\\u548c\\\\u6a21\\\\u578b\\\\u6765\\\\u5206\\\\u6790\\\\u5927\\\\u91cf\\\\u6570\\\\u636e\\\\uff0c\\\\u5e76\\\\u4ece\\\\u4e2d\\\\u53d1\\\\u73b0\\\\u89c4\\\\u5f8b\\\\u548c\\\\u8d8b\\\\u52bf\\\\uff0c\\\\u4ee5\\\\u4fbf\\\\u505a\\\\u51fa\\\\u667a\\\\u80fd\\\\u51b3\\\\u7b56\\\\u6216\\\\u9884\\\\u6d4b\\\\u672a\\\\u6765\\\\u4e8b\\\\u4ef6\\\\u3002\\\\u901a\\\\u8fc7\\\\u4e0d\\\\u65ad\\\\u5730\\\\u4e0e\\\\u65b0\\\\u6570\\\\u636e\\\\u8fdb\\\\u884c\\\\u4ea4\\\\u4e92\\\\u548c\\\\u5b66\\\\u4e60\\\\uff0c\\\\u673a\\\\u5668\\\\u5b66\\\\u4e60\\\\u6a21\\\\u578b\\\\u53ef\\\\u4ee5\\\\u9010\\\\u6e10\\\\u4f18\\\\u5316\\\\u81ea\\\\u8eab\\\\u7684\\\\u6027\\\\u80fd\\\\u3002\\\\u673a\\\\u5668\\\\u5b66\\\\u4e60\\\\u5728\\\\u8bb8\\\\u591a\\\\u9886\\\\u57df\\\\u4e2d\\\\u90fd\\\\u6709\\\\u5e94\\\\u7528\\\\uff0c\\\\u5305\\\\u62ec\\\\u56fe\\\\u50cf\\\\u8bc6\\\\u522b\\\\u3001\\\\u81ea\\\\u7136\\\\u8bed\\\\u8a00\\\\u5904\\\\u7406\\\\u3001\\\\u63a8\\\\u8350\\\\u7cfb\\\\u7edf\\\\u3001\\\\u91d1\\\\u878d\\\\u9884\\\\u6d4b\\\\u7b49\\\\u3002\",\\n      \"role\": \"assistant\"\\n    }\\n    \\n\\n\\n```python\\ncompletion.choices[0].message[\"content\"]\\n```\\n\\n\\n\\n\\n    \\'机器学习是一种人工智能技术，通过从经验中学习和改善自身的能力，使计算机能够从数据中学习，识别模式和进行预测，而无需明确的编程指令。机器学习采用算法和模型来分析大量数据，并从中发现规律和趋势，以便做出智能决策或预测未来事件。通过不断地与新数据进行交互和学习，机器学习模型可以逐渐优化自身的性能。机器学习在许多领域中都有应用，包括图像识别、自然语言处理、推荐系统、金融预测等。\\'\\n\\n\\n\\n\\n```python\\ncompletion = openai.ChatCompletion.create(\\n  model=\"gpt-4-0613\",\\n  messages=[\\n    {\"role\": \"user\", \"content\": \"请问什么是机器学习？\"}\\n  ]\\n)\\n\\nprint(completion.choices[0].message)\\n```\\n\\n    {\\n      \"content\": \"\\\\u673a\\\\u5668\\\\u5b66\\\\u4e60\\\\u662f\\\\u4eba\\\\u5de5\\\\u667a\\\\u80fd\\\\u7684\\\\u4e00\\\\u4e2a\\\\u5206\\\\u652f\\\\uff0c\\\\u5b83\\\\u5141\\\\u8bb8\\\\u8ba1\\\\u7b97\\\\u673a\\\\u7cfb\\\\u7edf\\\\u901a\\\\u8fc7\\\\u7ecf\\\\u9a8c\\\\u6765\\\\u5b66\\\\u4e60\\\\u3002\\\\u673a\\\\u5668\\\\u5b66\\\\u4e60\\\\u4f7f\\\\u7528\\\\u5404\\\\u79cd\\\\u7b97\\\\u6cd5\\\\uff0c\\\\u8fd9\\\\u4e9b\\\\u7b97\\\\u6cd5\\\\u901a\\\\u8fc7\\\\u5efa\\\\u7acb\\\\u6570\\\\u5b66\\\\u6a21\\\\u578b\\\\u57fa\\\\u4e8e\\\\u8bad\\\\u7ec3\\\\u6570\\\\u636e\\\\u8fdb\\\\u884c\\\\u9884\\\\u6d4b\\\\u6216\\\\u51b3\\\\u7b56\\\\uff0c\\\\u800c\\\\u65e0\\\\u9700\\\\u8fdb\\\\u884c\\\\u660e\\\\u786e\\\\u7684\\\\u7f16\\\\u7a0b\\\\u3002\\\\u4e5f\\\\u5c31\\\\u662f\\\\u8bf4\\\\uff0c\\\\u673a\\\\u5668\\\\u5b66\\\\u4e60\\\\u53ef\\\\u4ee5\\\\u57fa\\\\u4e8e\\\\u5927\\\\u91cf\\\\u7684\\\\u6570\\\\u636e\\\\uff0c\\\\u81ea\\\\u52a8\\\\u5bf9\\\\u6a21\\\\u578b\\\\u8fdb\\\\u884c\\\\u6539\\\\u8fdb\\\\u548c\\\\u8c03\\\\u6574\\\\uff0c\\\\u4ece\\\\u4e2d\\\\\"\\\\u5b66\\\\u4e60\\\\\"\\\\u5e76\\\\u4f18\\\\u5316\\\\u4efb\\\\u52a1\\\\u7684\\\\u6267\\\\u884c\\\\u6548\\\\u679c\\\\u3002\\\\u6bd4\\\\u5982\\\\uff0c\\\\u7528\\\\u4e8e\\\\u7535\\\\u5b50\\\\u90ae\\\\u4ef6\\\\u8fc7\\\\u6ee4\\\\u3001\\\\u91d1\\\\u878d\\\\u6b3a\\\\u8bc8\\\\u68c0\\\\u6d4b\\\\u3001\\\\u7f51\\\\u9875\\\\u63a8\\\\u8350\\\\u3001\\\\u81ea\\\\u52a8\\\\u9a7e\\\\u9a76\\\\u7b49\\\\u65b9\\\\u9762\\\\u7684\\\\u5e94\\\\u7528\\\\u3002\\\\u56e0\\\\u6b64\\\\uff0c\\\\u968f\\\\u7740\\\\u5927\\\\u6570\\\\u636e\\\\u7684\\\\u53d1\\\\u5c55\\\\uff0c\\\\u673a\\\\u5668\\\\u5b66\\\\u4e60\\\\u7684\\\\u5e94\\\\u7528\\\\u4e5f\\\\u8d8a\\\\u6765\\\\u8d8a\\\\u5e7f\\\\u6cdb\\\\u3002\",\\n      \"role\": \"assistant\"\\n    }\\n    \\n\\n\\n```python\\ncompletion.choices[0].message[\"content\"]\\n```\\n\\n\\n\\n\\n    \\'机器学习是人工智能的一个分支，它允许计算机系统通过经验来学习。机器学习使用各种算法，这些算法通过建立数学模型基于训练数据进行预测或决策，而无需进行明确的编程。也就是说，机器学习可以基于大量的数据，自动对模型进行改进和调整，从中\"学习\"并优化任务的执行效果。比如，用于电子邮件过滤、金融欺诈检测、网页推荐、自动驾驶等方面的应用。因此，随着大数据的发展，机器学习的应用也越来越广泛。\\'\\n\\n\\n\\n\\n```python\\n\\n```\\n\\n\\n```python\\n\\n```\\n\\n\\n```python\\n\\n```\\n\\n\\n\\n\\n首先，作为Completion模型的升级模型、同时也是专门用于进行对话类文本创建的模型，ChatCompletion模型首先围绕一次对话任务中参与对话的角色进行了分类，分别是system（系统）、user（用户）和assistant（助手），其中system和user都可以给assistant发送消息\\n\\n\\n\\n三种不同角色在对话任务中承担不同的任务，例如上述例子中，message如下：\\n\\n\\n```python\\n\\n```\\n\\n\\n```python\\n\\n```\\n\\n其中第一个字典{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}，表示\\'system\\'系统输出了\\'You are a helpful assistant.\\'一段内容，该内容的输出对象是\\n\\n> 这里需要注意，根据官网的说明，role表示消息作者，并没有明确表明role就一定是消息输出方。但在实际使用过程中我们发现，其实role几乎可以完全看成是消息发送方，这么理解也便于我们对消息结构的掌握和解读。\\n\\n\\n```python\\n\\n```\\n'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc60a43-b9cb-4499-aaf7-df0e5d9d9ec6",
   "metadata": {},
   "source": [
    "读取之后尝试将其作为system message输入给模型，然后要求模型根据本节内容编写一个能够实现多轮对话的函数，我们可以先通过如下message测试模型是否已经学习到ChatCompletion.create相关信息："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bf16e2d1-6cfd-42d6-b6b7-3f2685e371c9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "This model's maximum context length is 4097 tokens. However, your messages resulted in 24606 tokens. Please reduce the length of the messages.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m  \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m  \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd_content\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m请帮我介绍下openai.ChatCompletion.create这个函数\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m  \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\openai\\api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    279\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    287\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    288\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[0;32m    289\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[0;32m    290\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[0;32m    297\u001b[0m     )\n\u001b[1;32m--> 298\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\openai\\api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    693\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    694\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    695\u001b[0m         )\n\u001b[0;32m    696\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[0;32m    697\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 700\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    706\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    707\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\openai\\api_requestor.py:763\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    761\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 763\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[0;32m    764\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[0;32m    765\u001b[0m     )\n\u001b[0;32m    766\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mInvalidRequestError\u001b[0m: This model's maximum context length is 4097 tokens. However, your messages resulted in 24606 tokens. Please reduce the length of the messages."
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": md_content},\n",
    "    {\"role\": \"user\", \"content\": '请帮我介绍下openai.ChatCompletion.create这个函数'}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3492e8-b99d-4acc-b958-666159359ea9",
   "metadata": {},
   "source": [
    "不过在测试的过程中我们发现，token数量超出了模型的最大token接受范围，因此无法进行阅读和输出。而为了避免后续经常出现token数量超出范围的问题，我们可以借助OpenAI官方开源的tiktoken工具来进行token的计算，tiktoken安装和使用过程如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aab1f47-0016-4163-811a-53ec57069421",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "39529c07-2b09-48df-af6a-05192b027eac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d65aff-e2d0-43ed-8b31-c99cd8fa0d92",
   "metadata": {},
   "source": [
    "这里不同模型对于token的计算规则不同，因此我们需要先对模型进行预编码，然后再计算文本的token长度："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d8741cde-9992-47a9-b5a3-3123e2d649a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fb05d5d7-6f4c-4e65-9f84-39a7b6655ae3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24579"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoding.encode(md_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169baff5-6c9f-418c-bdaf-2ec7e95aad95",
   "metadata": {},
   "source": [
    "对于超出token数量的问题，截止课程到目前为主，我们只能考虑删除部分内容。这里我们可以考虑删除和openai.ChatCompletion.create函数无关的信息，保留函数相关信息，以更好的让模型能够学习函数规则，并进行多轮对话函数的编写。删除之后的ipy文件为text.ipy，然后我们将其转化为text.md，并计算token数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fdb67dec-b726-45df-b77b-60586c0e4048",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10591"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 打开并读取Markdown文件\n",
    "with open('text.md', 'r', encoding='utf-8') as f:\n",
    "    md_content = f.read()\n",
    "    \n",
    "len(encoding.encode(md_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e97efa1-a997-4ab9-9774-7e8f06d69022",
   "metadata": {},
   "source": [
    "然后再将其带入16k模型测试效果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cb0ed05d-28af-4e47-9256-143183f856b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo-16k-0613\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": md_content},\n",
    "    {\"role\": \"user\", \"content\": '请帮我介绍下openai.ChatCompletion.create这个函数'}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ff053044-41f8-4f9b-9764-ee5ca8ef53ab",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'openai.ChatCompletion.create函数是用于调用OpenAI的Chat模型的API函数之一。它用于发起对话式任务，可以向模型提问一个问题，并获取模型的回答。\\n\\n函数的基本使用方法如下：\\n```\\nresponse = openai.ChatCompletion.create(\\n  model=\"gpt-3.5-turbo\",\\n  messages=[\\n    {\"role\": \"user\", \"content\": \"请问，什么是机器学习？\"}\\n  ]\\n)\\n```\\n其中，有几个重要的参数需要说明：\\n- model参数表示要使用的模型，这里使用的是\"gpt-3.5-turbo\"，这是最新版本的Chat模型。\\n- messages参数用于指定对话过程中的消息，它是一个包含多个字典的列表。每个字典代表一条消息，其中包含两个键值对：role表示消息的发送方角色，可以是\"user\"或\"assistant\"；content表示具体的消息内容。\\n- 函数返回一个包含模型回答的response对象。\\n\\n需要注意的是，Chat模型适用于聊天对话类的任务，而非简单的文本补全。在使用Chat模型时，通过对话中的系统消息（system role）可以为模型设定角色和场景，从而影响模型的回答风格和内容。\\n\\n这就是openai.ChatCompletion.create函数的基本使用方法和参数解释。更详细的参数和功能介绍可以参考OpenAI官方文档。'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af28d001-5716-4da6-b3b2-764c747a2ee3",
   "metadata": {},
   "source": [
    "此时模型已经能够了解openai.ChatCompletion.create函数使用方法与基本规则，接下来我们尝试令其编写一个多轮对话函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0e67ba19-ec6c-4629-8f02-9c17aa67fae1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo-16k-0613\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": md_content},\n",
    "    {\"role\": \"user\", \"content\": '请帮编写一个基于openai.ChatCompletion.create这个函数的能够实现多轮对话的函数'}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f5336b7e-b2f0-4e8b-b2e8-b7c023bec69e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'当然可以，以下是一个简单的示例函数，用于实现多轮对话的功能：\\n\\n```python\\ndef chat_with_model(prompt, model=\"gpt-3.5-turbo\"):\\n    messages = [\\n        {\"role\": \"system\", \"content\": \"您是一位客户\"},\\n        {\"role\": \"user\", \"content\": prompt}\\n    ]\\n    \\n    while True:\\n        response = openai.ChatCompletion.create(\\n            model=model,\\n            messages=messages\\n        )\\n        \\n        # 获取模型回答\\n        answer = response.choices[0].message[\\'content\\']\\n        print(f\"模型回答: {answer}\")\\n\\n        # 询问用户是否还有其他问题\\n        user_input = input(\"您还有其他问题吗？(输入退出以结束对话): \")\\n        if user_input == \"退出\":\\n            break\\n\\n        # 记录用户回答\\n        messages.append({\"role\": \"user\", \"content\": user_input})\\n\\nchat_with_model(\"请问，什么是机器学习？\")\\n```\\n\\n在该示例函数中，用户可以连续地进行提问，并通过输入\"退出\"来结束对话。每一轮对话中，用户与模型的交互都会被记录在`messages`列表中，并传递给`ChatCompletion.create`函数进行模型回答。模型的回答会打印在控制台上，并循环询问用户是否还有其他问题。\\n\\n请注意，由于目前 gpt-3.5 系列模型对于system消息的长期关注性较低，在多轮对话时可能会出现由于上下文的丢失导致模型回答的问题。'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef7f537-3715-4aff-8c33-a2e4ddbeb6e9",
   "metadata": {},
   "source": [
    "然后将编写结果转化为markdown格式，并写入本地："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2574af10-f76a-471d-9b65-830fd37be4c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('example.md', 'a', encoding='utf-8') as f:\n",
    "    f.write(response.choices[0].message['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9f45b9-a8ec-4bb2-8162-bca4fd336e4f",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/1688901226289.png\" alt=\"1688901226289\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac43b12-9864-4a1f-be1d-201462226b7e",
   "metadata": {},
   "source": [
    "接下来我们尝试运行这个函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b6f08ab3-364b-4df5-97bb-b0d4a3134c82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def chat_with_model(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"您是一位客户\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    \n",
    "    while True:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=messages\n",
    "        )\n",
    "        \n",
    "        # 获取模型回答\n",
    "        answer = response.choices[0].message['content']\n",
    "        print(f\"模型回答: {answer}\")\n",
    "\n",
    "        # 询问用户是否还有其他问题\n",
    "        user_input = input(\"您还有其他问题吗？(输入退出以结束对话): \")\n",
    "        if user_input == \"退出\":\n",
    "            break\n",
    "\n",
    "        # 记录用户回答\n",
    "        messages.append({\"role\": \"user\", \"content\": user_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c0fa57a1-750f-4221-9c85-a0a6146ca43d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型回答: 机器学习是人工智能（AI）的一个分支，它通过使用算法和统计模型，使计算机能够从数据中学习并做出预测和决策，而无需明确的编程。简单来说，机器学习是使计算机具备通过数据学习和改进自身性能的能力。它涉及到收集和分析大量数据，训练模型来识别模式和趋势，从而做出准确的预测和决策。机器学习在许多领域中都有广泛应用，包括图像识别、语音识别、自然语言处理、金融预测、医学诊断等。\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "您还有其他问题吗？(输入退出以结束对话):  机器学习是如何进行预测的呢？\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型回答: 机器学习是一种人工智能的分支，通过训练模型来使机器能够自动学习和改进，而不需要显式地编程指令。它利用统计学和数据分析的方法，让计算机能够从大量的数据中寻找规律和模式，并根据这些规律进行预测和决策。\n",
      "\n",
      "机器学习的预测过程通常包括以下几个步骤：\n",
      "\n",
      "1. 收集数据：首先，需要收集并整理相关的数据集，包括输入特征（例如温度、湿度、时间等）和对应的输出标签（例如房价、销售量等）。\n",
      "\n",
      "2. 数据预处理：对收集的数据进行预处理，包括数据清洗、缺失值处理、特征选择、特征缩放等操作，以便于模型的正确训练和预测。\n",
      "\n",
      "3. 选择算法：选择适合任务的机器学习算法，如决策树、支持向量机、神经网络等。不同的算法具有不同的特性和适用场景，需要根据情况选择合适的算法。\n",
      "\n",
      "4. 模型训练：使用训练数据集来训练选择的机器学习模型。在这一步骤中，模型会根据数据集中的样本进行学习，并根据预设的指标（如准确率、均方误差等）进行参数调整和优化，以使模型能够更好地拟合数据。\n",
      "\n",
      "5. 模型评估：使用测试数据集对训练好的模型进行评估，以了解模型在实际情况下的性能表现。评估指标可以是准确率、召回率、精确度等。\n",
      "\n",
      "6. 预测和应用：一旦模型经过评估达到满意的效果，就可以将其应用到实际问题中，使用新的数据输入进模型，进行预测和决策。\n",
      "\n",
      "需要注意的是，预测的准确性和可靠性取决于数据质量、特征选择、训练数据集的大小和多样性以及算法的选择等多个因素。因此，在进行机器学习预测时，需要综合考虑这些因素，进行必要的优化和调整，以获得更好的预测结果。\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "您还有其他问题吗？(输入退出以结束对话):  退出\n"
     ]
    }
   ],
   "source": [
    "chat_with_model(\"请问，什么是机器学习？\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8568ca-733b-416d-8906-0be4baa6adc0",
   "metadata": {},
   "source": [
    "发现函数能够顺利运行，至此，我们就成功尝试了将课程内容输入到模型中，然后借助模型完成Chat模型多轮对话的编写需求。当然，再这里，我们其实可以更进一步将一部分课程内容作为system message进行输入，即可完成围绕课程问题的问答机器人："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0308899a-cbca-4106-a8da-90a0c40794fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def chat_with_model(prompt, model=\"gpt-3.5-turbo-16k-0613\"):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": md_content},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    \n",
    "    while True:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=messages\n",
    "        )\n",
    "        \n",
    "        # 获取模型回答\n",
    "        answer = response.choices[0].message['content']\n",
    "        print(f\"模型回答: {answer}\")\n",
    "\n",
    "        # 询问用户是否还有其他问题\n",
    "        user_input = input(\"您还有其他问题吗？(输入退出以结束对话): \")\n",
    "        if user_input == \"退出\":\n",
    "            break\n",
    "\n",
    "        # 记录用户回答\n",
    "        messages.append({\"role\": \"user\", \"content\": user_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ec8a6ac0-add2-4cba-9738-842c1ee75471",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型回答: 机器学习是一种人工智能的分支领域，它研究如何使计算机系统根据数据和经验自动改善和适应，而无需明确地进行编程。机器学习的目标是通过构建模型和算法，让计算机能够从大量数据中学习，并且可以从中发现模式、做出预测和做出相应的决策。机器学习技术被广泛应用于图像和语音识别、自然语言处理、推荐系统、数据挖掘等领域，以解决复杂问题和改进人工智能系统的性能。\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "您还有其他问题吗？(输入退出以结束对话):  请问message参数有哪些用法？\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型回答: message参数是ChatCompletion.create函数中非常重要的参数之一，用于描述对话模型和用户之间的通信信息。下面是message参数的一些常见用法：\n",
      "\n",
      "1. 单条消息：当只有一条消息时，可以直接使用字典表示，例如：\n",
      "```python\n",
      "messages = [{\"role\": \"user\", \"content\": \"请问，什么是机器学习？\"}]\n",
      "```\n",
      "\n",
      "2. 多条消息：可以通过列表传递多条消息，模型会按照顺序依次处理，例如：\n",
      "```python\n",
      "messages = [\n",
      "    {\"role\": \"user\", \"content\": \"我对机器学习很感兴趣\"},\n",
      "    {\"role\": \"assistant\", \"content\": \"机器学习是一门研究如何使计算机从经验中学习的领域\"},\n",
      "    {\"role\": \"user\", \"content\": \"能给我举个例子吗？\"}\n",
      "]\n",
      "```\n",
      "\n",
      "3. 系统消息：可以使用role为\"system\"的消息设定模型的角色或身份，例如：\n",
      "```python\n",
      "messages = [\n",
      "    {\"role\": \"system\", \"content\": \"你是一位资深的计算机科学家\"},\n",
      "    {\"role\": \"user\", \"content\": \"请问，机器学习的应用有哪些？\"}\n",
      "]\n",
      "```\n",
      "\n",
      "需要注意的是，消息的顺序非常重要，模型会根据消息的顺序进行逐条回应。对于多轮对话，模型会根据之前的消息进行回应，因此要确保消息的正确顺序。\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "您还有其他问题吗？(输入退出以结束对话):  退出\n"
     ]
    }
   ],
   "source": [
    "chat_with_model(\"请问，什么是机器学习？\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
